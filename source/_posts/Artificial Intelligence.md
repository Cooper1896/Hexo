---
title: AI是什么？
date: 2025-10-24
description: '聊聊ai'
image: ''
tags: AI/Artificial Intelligence
type: '杂谈'
top_img: false
---

想了很久，终于有时间来讲讲AI了，些许错误，多多包容

---

### I. 人工智能 (Artificial Intelligence,AI)

大家都听过的词语，依照维基百科的解释:  [人工智能（AI）](https://www.wikiwand.com/en/articles/Artificial_intelligence.com)是指计算系统执行通常与人类智能相关任务的能力，例如学习、推理、解决问题、感知和决策。

而AI分为 **强AI** 和 **弱AI**：

##### **弱AI(ANI - Artificial Narrow Intelligence）**

被设计用来 ****解决特定的任务****（如下棋、人脸识别、写代码）。如AlphaGo, Copilot, Siri 均属此类。

##### **强 AI (AGI - Artificial General Intelligence):**

理论上的“通用人工智能”，拥有与人类同等或超越人类的、跨领域的思考和学习能力。类似于天网、终结者的存在，或者说目标，目前尚未实现。

随着AI的不断发展，也发展出了不同的发展方向，主要是:**机器学习（ML）与专家系统（Expert Systems）**

---

#### **专家系统**

专家系统是人工智能发展早期出现的一种 **方法**，它属于基于规则的 AI，与现代的机器学习驱动的 AI 有着十分鲜明对比。

###### **核心思想与定义**

专家系统旨在模拟人类领域专家（如医生、金融分析师）的决策能力和推理过程，通过将人类的专业知识进行形式化编码，来解决复杂、专业性的问题。本质上是一个由程序员编写的，十分庞大，嵌套极深的 `if-else` 抉择树。

###### 结构

一个典型的专家系统由三个关键组成部分构成：

###### **1. 知识库 (Knowledge Base)**

这是专家系统的信息来源，存储了领域专家的所有专业知识。这些知识通常以两种形式存在：

- **事实 (Facts):** 关于领域的基本信息（例如：“水在100°C 沸腾”）。

- **规则 (Rules):** **条件-行动 (IF-THEN)** 语句，代表专家的经验和推理逻辑。
  
  - *示例规则：* `IF (病人有发烧) AND (病人有咳嗽) THEN (推断患有呼吸道感染)`

##### **2. 推理机 (Inference Engine)**

顾名思义，它负责根据用户输入的信息和知识库中的规则进行逻辑推理，得出结论。主要的推理方法有两种：

- **正向链 (Forward Chaining):** **数据驱动**。从已知事实开始，不断应用规则，直到达到目标或所有规则都被应用。
  
  - *逻辑：* 如果 $A$ 且 $B$ 为真，而我们知道 $A$ 和 $B$ 是真，则 $C$ 为真。

- **反向链 (Backward Chaining):** **目标驱动**。从目标（假设的结论）开始，向后寻找支持该结论的必要事实或子目标。
  
  - *逻辑：* 要证明 $C$，需要 $A$ 和 $B$。那么，先证明 $A$，再证明 $B$。

##### **3. 用户界面 (User Interface)**

用于与用户交互,来接收你输入资讯的地方

相当直观的一种结构，但是简单的代价是会有两个限制和问题：

- **极其脆弱**：遇到规则之外的情况就崩溃。因此，相关模型多用于特定的领域，如医疗，金融等..

- **无法学习**:你必须手动更新模型的规则以及知识库，维护的成本也大大增加

---

### II. 机器学习 (Machine Learning, ML)

ML 的本质在于，它不再要求开发者为机器硬编码规则，而是让机器从海量数据中**自动学习**（或“拟合”）出最优的映射函数 $f$。

##### 一. 严谨的定义与三要素 (T, E, P)

机器学习最被认可的定义来自于计算机科学家 Tom M. Mitchell。他指出，一个程序从经验中学习，必须满足三个要素：

| **要素**                       | **解释**                       | **案例：垃圾邮件过滤器**                                                |
| ---------------------------- | ---------------------------- | ------------------------------------------------------------- |
| **任务 ($T$ - Task)**          | 机器需要完成的具体工作，通常是预测或推断。        | **分类任务**：将邮件内容 $X$ 分类到 $Y=\{\text{“垃圾邮件”}, \text{“非垃圾邮件”}\}$。 |
| **经验 ($E$ - Experience)**    | 模型用于学习的观测数据。                 | **数据集**：100 万封邮件，其中每封邮件都已人工标注了正确的标签。                          |
| **性能度量 ($P$ - Performance)** | 量化模型表现的指标，衡量其预测结果与真实标签的匹配程度。 | **准确率 (Accuracy)**：模型正确分类的邮件占总邮件数的百分比。                        |

这也是机器学习与专家系统的最大不同。专家系统是输入`数据`+`规则`，输出`答案`；而机器学习则是输入`数据`+`答案`，输出`规则`。

##### 二. 特征工程 (Feature Engineering)

这是将原始数据（如图像像素、原始文本）转换成算法可以理解的、具有信息价值的特征向量的过程，或许能称为“学习”？

1. 优化与统计

机器学习的过程，在数学上被定义为一个**最优化问题**。 (读M2震怒 。学习的目标是找到一组最优参数 $\theta$，使得模型的**损失函数 ($L$)** 最小化。损失函数度量了模型预测 $\hat{Y}$ 与真实值 $Y$ 之间的差异：

$$f^* = \underset{f}{\operatorname{argmin}} L(f(X), Y)$$

- $f$: 代表模型（如神经网络、决策树）。

- $L(f(X), Y)$: **损失函数**，用于度量模型的预测 $f(X)$ 与真实标签 $Y$ 之间的差异。最小化损失是学习的驱动力。

- $\operatorname{argmin}$: **最优化操作**，寻找使损失函数 $L$ 达到最小值的模型参数集 $\theta$。
2. 核心算法：梯度下降 (Gradient Descent)

大多数 ML 模型（尤其是深度学习）使用梯度下降 (Gradient Descent)及其变种（如 SGD, Adam）来执行优化。大概就是一种数学的计算方式，我不会。

<blockquote style="border-left: 4px solid #ff6b6b; background: #ffe0e0; padding: 15px; margin: 15px 0;">
看看得了
</blockquote>

**举个栗子**

例子1：银行贷款违约风险预测

| **原始特征 (Raw Data)** | **领域知识应用（工程操作）** | **构造的新特征 (Engineered Feature)**         | **价值**                            |
| ------------------- | ---------------- | --------------------------------------- | --------------------------------- |
| `年龄`                | 分箱（Binning）      | `年龄段` (例如：[18-25], [26-40], [41-60]...) | 将连续变量转化为离散变量，捕捉不同年龄段客户的风险特性。      |
| `信用卡额度`、`已用额度`      | 运算/比率            | `使用率` ($\text{已用额度} / \text{总额度}$)      | 这是比两个独立数值更有力的违约风险信号。高使用率通常意味着高风险。 |
| `过去 12 个月的交易笔数`     | 统计               | `最近 3 个月的平均交易额增长率`                      | 捕捉客户近期消费行为的趋势变化，而非简单的总量。          |
| `居住城市` (类别)         | 编码               | `城市风险评分` (基于该城市历史违约率)                   | 将高维度的类别特征转化为具有预测意义的数值特征。          |

案例 2：情绪分析

客户评论：“这个应用太卡了，但设计很漂亮。”

| **原始特征** | **领域知识应用（工程操作）**                     | **构造的新特征**             | **价值**                           |
| -------- | ------------------------------------ | ---------------------- | -------------------------------- |
| 原始句子     | **词袋模型 (Bag-of-Words)** 或 **TF-IDF** | `“卡”的频率`, `“漂亮”的权重`    | 将不定长的文本转化为固定长度的数值向量。             |
| 词语       | **N-gram 构造**                        | `“太卡了”` (三元词组)         | 捕捉词语的局部顺序和语义，“太卡了”比单独的“卡”更有负面情感。 |
| 情感词典     | **计数**                               | `负面词汇数量`, `正面词汇数量`     | 捕捉评论的**情感极性**和**强度**。            |
| 连词       | **结构分析**                             | `是否存在转折连词 (“但”, “可是”)` | “卡但漂亮”表示复杂情绪，模型应区别于“卡且丑陋”。       |

##### 三、 机器学习的主要任务类型

机器学习任务通常根据训练数据的性质和模型目标被划分为三大类：

###### 1. 监督学习 (Supervised Learning)

监督学习是目前应用最广泛的 ML 类型，类似于有老师手把手教你，即训练数据中的每一个输入 $X$ 都对应一个已知的、正确的输出标签 $Y$。这类算法的目的是学习和逼近输入 $X$ 到输出 $Y$ 的映射函数 $f$，使得对于任何新的输入 $X_{\text{new}}$，模型能够准确预测其对应的 $\hat{Y}_{\text{new}}$。

<blockquote style="border-left: 4px solid #4dabf7; background: #e7f5ff; padding: 15px; margin: 15px 0;">
金融预测： 输入经济指标和历史数据，输出连续的未来某商品价格。

住房预测： 输入房屋面积、地理位置等，输出具体的房价数值。

</blockquote>

###### 2.无监督学习 (Unsupervised Learning)

无监督学习就像是让学生自主探索。模型接收的训练数据**只有输入 $X$**，没有标签 $Y$。在此类算法中，模型必须自主地探索数据，找出隐藏在数据中的统计结构、分布等。它不进行预测，而是进行描述和组织。

<blockquote style="border-left: 4px solid #4dabf7; background: #e7f5ff; padding: 15px; margin: 15px 0;">
购物分析：发现“如果客户购买了牛奶 (A)，那么他们有 80% 的概率也会购买面包 (B)”。
</blockquote>

###### 3.[强化学习 (Reinforcement Learning, RL)](https://www.wikiwand.com/en/articles/Reinforcement_learning)

![https://assets.wikiwand.com/_next/image?url=https://upload.wikimedia.org/wikipedia/commons/thumb/1/1b/Reinforcement_learning_diagram.svg/1100px-Reinforcement_learning_diagram.svg.png&w=828&q=70](https://assets.wikiwand.com/_next/image?url=https://upload.wikimedia.org/wikipedia/commons/thumb/1/1b/Reinforcement_learning_diagram.svg/1100px-Reinforcement_learning_diagram.svg.png&w=828&q=70)

强化学习与前两者完全不同，它是一种**基于试错 (Trial-and-Error)** 的学习方法，灵感来源于心理学中的行为主义。

如果你想让你家的狗学会坐下或叼飞盘，你不会像人类一样让它看书，而是使用**奖励**和**惩罚**来塑造它的行为，这也是强化学习的逻辑。训练机器狗的过程是一个永不停止的、基于**马尔可夫决策过程 (MDP)** 的循环：

#### 步骤 1：观察

机器狗环顾四周，确定它在哪里（**状态 $S$**）。

- *例如：* 机器狗知道它在 $(5, 5)$ 位置，并且闻到了前方有食物的气味。

#### 步骤 2：行动

机器狗根据它**当前的策略 $\pi$**（行为准则），决定下一步做什么（**行动 $A$**）。

- *例如：* 机器狗的策略是“闻到食物，就前进”。它执行了“前进”的动作。

#### 步骤 3：反馈与奖励

机器狗执行动作后，环境发生变化，并返回反馈：

- **新状态 $S'$：** 机器狗移动到了 $(6, 5)$ 位置。

- **奖励 $R$：**
  
  - 如果它吃到了食物：$+100$ (奖励)
  
  - 如果它撞到了墙：$-10$ (惩罚)
  
  - 如果它踩到了地雷：$-1000$ (巨大惩罚)
  
  - 如果只是普通移动：$-1$ (微小惩罚)

#### 步骤 4：更新策略

机器狗利用这个反馈（奖励 $R$）来**评估**它刚才的行动好不好，并**调整它的策略 $\pi$**。

- **如果 $R$ 为正：** 它知道这个行动是好的，下次在类似状态下会倾向于重复这个行动。

- **如果 $R$ 为负：** 它知道这个行动是坏的，下次在类似状态下会避免这个行动。

这个循环会重复数百万次，机器狗从随机的试错开始，逐步搭建一套最优策略，即：如何避开地雷，并以最快的速度找到最多的食物。

---

### III 深度学习 (Deep Learning,DL)

深度学习属于机器学习的其中一种，是实现机器学习的一种技术。它特指使用一种名为**深度神经网络 (Deep Neural Networks, DNN)** 的特定模型结构来完成学习任务。

##### 说文解字

“深”，意为深度，有点像是层级化的特征学习

- **传统 ML：** 高度依赖人类专家手动设计特征。例如，要识别一张图片中的人脸，你可能需要手动编写代码来检测“眼睛的形状”、“鼻子的比例”、“肤色分布”等特征。

- **深度学习：** 实现了自动化的特征学习。您只需将原始数据（如图像的原始像素）喂给模型，模型会自动在它的“深度”结构中学习到最优特征。

这种叫做**层级化特征学习**

##### 举个栗子

以图像识别的CNN为例:

- **Layer 1 (浅层):** 神经网络的第一层会自动学习到最基础的特征，如`边缘`、`角落`、简单的`颜色块`。

- **Layer 2 (中层):** 这一层会组合第一层的简单特征，自动学习到更复杂的形状和纹理，如`圆形`、`网格状`、`毛发纹理`。

- **Layer 3 (深层):** 这一层会组合中层的形状，自动学习到物体的部件，如`眼睛`、`鼻子`、`汽车轮胎`。

- **Output Layer (顶层):** 最终，顶层会组合这些部件，做出最终的分类判断：“这是一张人脸”或“这是一辆汽车”

**深度** 指的就是这种特征抽象的层级数量。因为模型会自动学习这些特征，所以它能发现人类工程师难以想到的更优、更抽象的东西。

##### 构成

一个**深度神经网络** 由三个部分组成：

1. **输入层 (Input Layer):** 接收原始数据（如图像像素、词向量）。

2. **隐藏层 (Hidden Layers):** 这是模型的核心。DNN 至少有两个或更多的隐藏层（通常是几十到几百层）。每一层都由许多**神经元** 组成，每个神经元都会对其输入进行**加权求和**并应用**激活函数**来引入非线性。

3. **输出层 (Output Layer):** 生成最终的预测结果（如分类的概率）。

##### 主要架构

| **架构**          | **全称**                                       | **核心机制**                                   | **擅长领域**                                  |
| --------------- | -------------------------------------------- | ------------------------------------------ | ----------------------------------------- |
| **CNN**         | **卷积神经网络**<br>(Convolutional Neural Network) | **卷积核 (Filters)** 与 **参数共享**。              | **网格状数据（如图像）**：图像识别、医学影像分析、目标检测。          |
| **RNN**         | **循环神经网络**<br>(Recurrent Neural Network)     | **隐藏状态 (Hidden State)** 的循环，用于处理序列。        | **序列数据（如文本、时间序列）**：自然语言处理、语音识别。           |
| **LSTM**        | **长短期记忆网络**<br>(Long Short-Term Memory)      | RNN 的变体，使用“门控”机制来解决 RNN 的  **长距离依赖（遗忘**问题。 | 复杂的序列任务。                                  |
| **Transformer** | (无特定全称)                                      | **自注意力机制 (Self-Attention)**。               | **现代 NLP 的基石**：GPT-4、BERT 等大型语言模型，以及机器翻译。 |

<blockquote style="border-left: 4px solid #ff6b6b; background: #ffe0e0; padding: 15px; margin: 15px 0;">
以上内容看看得了
</blockquote>

看不懂是正常的，我们来举个栗子

让我们把**深度神经网络 (DNN)** 想象为一家公司

---

### 第一部分：DNN 的结构 — 公司的层级

#### 1. 输入层 — 前台接待员

这是公司的前台。当客户（数据）上门时，前台接待员（输入神经元）负责接收最原始、最琐碎的信息。

- **事件：** 客户给了一张图片。

- **接待员的工作：** 他们不会思考，只是把图片拆解成最基本的信息（比如，每个像素点的颜色值）。
  
  - “接待员 1：左上角像素，红色值 255。”
  
  - “接待员 2：左上角像素，绿色值 100。”
  
  - ...

- 输入层只负责**接收原始数据**，并将其传递给下一层。

#### 2. 隐藏层 — 工作团队

深度一词的由来。想象每一家公司有很多部门。

- 假设每一层都是一个部门。

- **工作流程：**
  
  - **层级 1 (部门A)：** 他们从所有“接待员”那里拿到原始像素数据。他们的工作是**识别最简单的模式**。
    
    - 员工 A：“我发现了一些横向边缘。”
    
    - 员工 B：”我发现了一些垂直线条。”
    
    - 员工 C：“我发现了一块毛茸茸的纹理。”
  
  - **层级 2 (部门B)：** 他们不看原始数据，只看部门A的报告。他们的工作是**组合简单模式，形成复杂形状**。
    
    - 员工 X：”我把`边缘 A`和`纹理 C`组合起来，这看起来像一个`耳朵`的轮廓。”
    
    - 员工 Y：“我把`线条 B`和另一条线组合，这像`胡须`。”
  
  - **隐藏层 3 (部门C)：** 他们继续组合先前部门的所有报告，形成更复杂的概念。
    
    - 员工 P：”我拿到了`耳朵`、`胡须`和`眼睛`的报告，我认为这构成了一张`动物的脸`。”

**...... 以此类推**

#### 3. 权重— 经理的偏好

每个经理在看下属的报告时，都有自己的**偏好（权重）**。

- 在部门A的经理看来：
  
  - 下属 A (边缘) 的报告**非常重要** (权重 = 0.9)。
  
  - 下属 B (线条) 的报告**不太重要** (权重 = 0.1)。
  
  - 下属 C (纹理) 的报告**中等重要** (权重 = 0.5)。

- 经理会把所有报告的**重要性**加权求和，形成自己的最终判断。

#### 4. 输出层 — 老板

这是一家公司的最高层

- 老板不看任何琐碎细节，只看各部门的最终报告。

- **决策：**
  
  - A 报告：“我 95% 确定这是一张‘动物的脸’。”
  
  - B 报告：“我 80% 确定这是‘猫的身体’。”
  
  - X 报告：“我20%确定是‘狗的身体’。”

- 老板综合所有最高层的信息，做出最终的、唯一的决策：“**我宣布，这是猫**。”

### 第二部分：反向传播 — 秋后算账

这时候，身为正常人的你下楼一看，糟糕了：

- 老板：“这是猫！”

- 你：“？？？这不是狗吗？”

现在，公司必须从这个巨大的错误中学习。这就是**反向传播 (Backpropagation)** 的开始，它是一个**追责**和**纠正**的过程。

生气的你冲到老板面前，一招大荒囚天指技惊四座。

“你个蠢货，那是只狗！”

##### 反向追责 (Backward Pass)

这个“追责”的过程是**从老板开始，一层一层往下**的：

- **第 1 站：老板 (输出层)**
  
  - **你问老板：** “你为什么判断是猫？”
  
  - **老板回答：** “因为我的 A 报告 (动物的脸) 和 B 报告 (猫的身体) 都给了充足的论证。我的偏好是更相信 B(猫的身体)。”
  
  - **你的指示 (梯度)：** “你（老板）的 **判断** 错了！下次 B (猫的身体) 报告时，你**必须降低对它的信任度** (降低权重)。同时，X (狗的身体) 的报告，你**必须提高信任度** (提高权重)。”

- **第 2 站：部门经理 (隐藏层 N)**
  
  - **老板跑去问经理：** “你为什么说那是‘猫的身体’？害我被骂！”
  
  - **经理回答：** “因为我的员工的分析，让我更偏向于相信是猫的身体。”
  
  - **总教练指示 (梯度)：** “你**判断** 也错了！下次报告时，你**必须降低对它的信任度**。同时，你要更关注狗爪子的报告！”
  
  **...... 以此类推，直至最底层**

#### 3. 链式法则 (Chain Rule)

你注意到了吗？**错误的“责任”从顶层传递到了底层。**

- 老板的错误，导致了对经理的“指责”。

- 经理的错误，导致了对员工的“指责”。

- ...

- 这个**指责**的**具体数值（你应该调整多少？）**，在数学上就是**梯度 (Gradient)**。

- 这种**逐层反向传递责任**的数学工具，就是**链式法则 (Chain Rule)**。

#### 4. 全员调整 (Weight Update)

经过这一次秋后算账，公司里的**每一个经理，一直到底层员工（所有神经元）**，都收到了一个具体的“调整指令”：

> “你之前对下属 X 的报告‘偏好’（权重）太高了，下次把它调低 0.05%。”
> “你之前对下属 Y 的报告‘偏好’太低了，下次把它调高 0.02%。”

**这个过程（决策 -> 犯错 -> 反向追责 -> 全员微调）会重复数百万次。**

最终，这家公司的所有经理都学会了一套极其复杂且精妙的“偏好”（权重），使得他们在下次看到一张“狗”的图片时，能从前台开始，一路正确地传递信息，最终让老板做出正确的决策：“这是狗！”

---

### IV 注意力的革命

在 GPT 出现之前，处理序列数据（如文本、语音）的主流模型是 **RNN (循环神经网络)** 及其变体 **LSTM**。

RNN 的设计很直观：它像人一样，一个词一个词地阅读。它有一个“记忆单元”（Hidden State），在阅读句子:'The cat sat on the floor.'时，在读完“The cat”后，会把'The cat'的信息编码到记忆里，再去读下一个词‘sat’。

但这种设计存在两个致命问题。**首先是长距离依赖和梯度消失**：当句子很长时（“我昨天...（省略50个词）...那只猫”），到处理“猫”时，关于“昨天”的信息（梯度）在“记忆”中已经极其微弱，模型“忘记”了。**其次是串行计算瓶颈**：你必须处理完 `word[n]` 才能处理 `word[n+1]`。这在 GPU 时代是灾难性的，因为 GPU 最擅长的是**并行计算**（同时处理 1000 个 `word`），而 RNN 的设计使其无法利用这一点。

直到 2017 年，一篇论文[《Attention Is All You Need》](https://proceedings.neurips.cc/paper_files/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf)彻底改变了这一切。**Transformer** 模型登场，它做的第一件事就是：**彻底抛弃 RNN 的“循环”结构**。

Transformer 的核心是**自注意力机制 (Self-Attention)**。它的核心思想是：一个句子中的词，其含义不是孤立的，而是由它和句子中所有其他词的关系共同决定的。

> 例子：“The **animal** didn't cross the street because **it** was too tired.”

当模型处理 "it" 时，"it" 指的是 "animal" 还是 "street"？RNN 必须依赖其摇摇欲坠的“短期记忆”。而 Self-Attention 允许 "it" *直接“看”向* 句子中的所有其他词，并计算一个“注意力得分”。它会发现 "it" 和 "animal" 的关联性远高于 "street"。

那么，Self-Attention 在技术上是如何做到这一点的呢？它为句子中的 每个词 都生成三个不同的向量：

- **Query (Q) 向量：** 代表当前词作为“查询者”的身份。可以理解为：“**我** (it) 是谁？我正在寻找和我相关的东西。”

- **Key (K) 向量：** 代表该词可被“索引”的标签。可以理解为：“我是“animal”，一个可以被指代的名词。”

- **Value (V) 向量：** 代表该词的“真正含义”或“内容”。

整个过程如下（以‘it’为例）：

**首先是打分(Scoring)**：拿 "it" 的 **Q 向量**，去和 **句子中所有词**（包括 "it" 自己）的 **K** 向量进行**点积** (Dot-Product)。这个点积的结果，就是**相关性得分**。（如果 "it" 的 Q 和 "animal" 的 K 很接近，得分就高）。

**接着是归一化(Softmax)**：将这些原始得分通过一个 Softmax 函数，将其转换为总和为 1 的“注意力权重”（例如：{ "The": 0.05, "animal": **0.85**, ..., "it": 0.05, ...}）。

**最后是加权求和(Weighted Sum)**：用这些**注意力权重**，去对 句子中所有词 的 **V** 向量进行加权求和。

`Output_for_it = (0.05 * V_The) + (0.85 * V_animal) + ...`

最终的结果是： "it" 的原始 V 向量（它自己的含义）被“注入”了 85% 的 "animal" 的 V 向量（含义）。模型在这一层就明确知道了 "it" 指向 "animal"。

Transformer 的革命性在于两个方面。**第一是并行化**：整个 Q-K-V 计算是纯粹的矩阵乘法。GPU 可以 *同时* 计算句子中所有词的 Q/K/V 和注意力得分。这充分运用了设备的算力，使得训练千亿（甚至万亿）参数的巨型模型（LLM）成为可能。**第二是全局依赖**：任何两个词（无论相隔多远）的“距离”都为 1。模型可以轻易捕捉长距离依赖，彻底解决了 RNN 的“遗忘”问题。

---

东拼西凑的一个月，终于完成了🙌
