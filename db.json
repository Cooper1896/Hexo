{"meta":{"version":1,"warehouse":"6.0.0"},"models":{"Asset":[{"_id":"source/CNAME","path":"CNAME","modified":1,"renderable":0},{"_id":"source/image/link-default.png","path":"image/link-default.png","modified":1,"renderable":0},{"_id":"themes/anzhiyu/source/favicon.ico","path":"favicon.ico","modified":1,"renderable":1},{"_id":"themes/anzhiyu/source/css/index.styl","path":"css/index.styl","modified":1,"renderable":1},{"_id":"themes/anzhiyu/source/css/var.styl","path":"css/var.styl","modified":1,"renderable":1},{"_id":"themes/anzhiyu/source/img/404.jpg","path":"img/404.jpg","modified":1,"renderable":1},{"_id":"themes/anzhiyu/source/img/512.png","path":"img/512.png","modified":1,"renderable":1},{"_id":"themes/anzhiyu/source/img/comment_bg.png","path":"img/comment_bg.png","modified":1,"renderable":1},{"_id":"themes/anzhiyu/source/img/default_cover.jpg","path":"img/default_cover.jpg","modified":1,"renderable":1},{"_id":"themes/anzhiyu/source/img/algolia.svg","path":"img/algolia.svg","modified":1,"renderable":1},{"_id":"themes/anzhiyu/source/img/favicon.ico","path":"img/favicon.ico","modified":1,"renderable":1},{"_id":"themes/anzhiyu/source/img/friend_404.gif","path":"img/friend_404.gif","modified":1,"renderable":1},{"_id":"themes/anzhiyu/source/img/loading.gif","path":"img/loading.gif","modified":1,"renderable":1},{"_id":"themes/anzhiyu/source/js/main.js","path":"js/main.js","modified":1,"renderable":1},{"_id":"themes/anzhiyu/source/js/tw_cn.js","path":"js/tw_cn.js","modified":1,"renderable":1},{"_id":"themes/anzhiyu/source/js/utils.js","path":"js/utils.js","modified":1,"renderable":1},{"_id":"themes/anzhiyu/source/img/siteicon/16.png","path":"img/siteicon/16.png","modified":1,"renderable":1},{"_id":"themes/anzhiyu/source/img/siteicon/32.png","path":"img/siteicon/32.png","modified":1,"renderable":1},{"_id":"themes/anzhiyu/source/img/siteicon/apple-icon-180.png","path":"img/siteicon/apple-icon-180.png","modified":1,"renderable":1},{"_id":"themes/anzhiyu/source/img/siteicon/manifest-icon-192.maskable.png","path":"img/siteicon/manifest-icon-192.maskable.png","modified":1,"renderable":1},{"_id":"themes/anzhiyu/source/js/anzhiyu/ai_abstract.js","path":"js/anzhiyu/ai_abstract.js","modified":1,"renderable":1},{"_id":"themes/anzhiyu/source/img/siteicon/manifest-icon-512.maskable.png","path":"img/siteicon/manifest-icon-512.maskable.png","modified":1,"renderable":1},{"_id":"themes/anzhiyu/source/js/anzhiyu/comment_barrage.js","path":"js/anzhiyu/comment_barrage.js","modified":1,"renderable":1},{"_id":"themes/anzhiyu/source/js/anzhiyu/people.js","path":"js/anzhiyu/people.js","modified":1,"renderable":1},{"_id":"themes/anzhiyu/source/js/anzhiyu/random_friends_post.js","path":"js/anzhiyu/random_friends_post.js","modified":1,"renderable":1},{"_id":"themes/anzhiyu/source/js/anzhiyu/right_click_menu.js","path":"js/anzhiyu/right_click_menu.js","modified":1,"renderable":1},{"_id":"themes/anzhiyu/source/js/search/algolia.js","path":"js/search/algolia.js","modified":1,"renderable":1},{"_id":"themes/anzhiyu/source/js/search/local-search.js","path":"js/search/local-search.js","modified":1,"renderable":1}],"Cache":[{"_id":"source/CNAME","hash":"29689324354a6ac3103301beae3a7fc0a4f001b6","modified":1764087813956},{"_id":"source/_data/essay.yml","hash":"df903c7b5ecd1e5c186512ea91fb6f92ba5e7f36","modified":1764079402955},{"_id":"source/about/index.md","hash":"8b79572b16aea94ee52ab48c49949212f101d0a5","modified":1764000679797},{"_id":"source/css/link_custom.css","hash":"723a2c11181beb2c8d66b491fff09c94d87fd220","modified":1764086165414},{"_id":"source/_posts/hello-world.md","hash":"e0c53e31ef4f59a92256b1cc1cda66de83949d18","modified":1764164520477},{"_id":"source/_posts/Artificial Intelligence.md","hash":"5ec0a5bf17ec2c8176d52d36db336adb1405395b","modified":1764163555684},{"_id":"source/_posts/unlocked_bl_sh.md","hash":"ec1e47abdf8efa3f42d9a066b2a09762583d99cf","modified":1764163555684},{"_id":"source/_posts/Twikko.md","hash":"7a82cb03af9b9bec2af777da8034303febe18f26","modified":1764165021587},{"_id":"source/image/link-default.png","hash":"c0a35159baa46102c6f01f535f44b279fd87c3bd","modified":1764074692350},{"_id":"source/essay/index.md","hash":"ae68ba8e9b4d0b9a207249ccde321326f65062f0","modified":1764079056513},{"_id":"source/js/header-gradient.js","hash":"178c7d49421bf0afeaa628e84978f392289cf7c5","modified":1764086165414},{"_id":"source/js/imgloaded.js","hash":"3ed4dc523e31ad9ee449faa8cc26d519074d29ee","modified":1764076575203},{"_id":"source/js/home-typed-init.js","hash":"cdd415e1986a079cff1ad0adbdb4bf72b20284a5","modified":1764082777924},{"_id":"source/js/music.json","hash":"02d2c39f1935703f057e5c9b87338449d6b9ba07","modified":1764069105960},{"_id":"source/music/index.md","hash":"d7b058eeccceaf4125d4869b07f8608094baae9d","modified":1764001234462},{"_id":"themes/anzhiyu/source/css/_extra/home_top/random-banner.css","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1764161572052},{"_id":"themes/anzhiyu/.gitignore","hash":"d507747699b68b0ec536b91d8be526c71ccf5c74","modified":1764161571973},{"_id":"themes/anzhiyu/LICENSE","hash":"31a3d460bb3c7d98845187c716a30db81c44b615","modified":1764161571973},{"_id":"themes/anzhiyu/README_EN.md","hash":"3b27231432adf2bd180857fc6d3de646dfd444bf","modified":1764161571974},{"_id":"themes/anzhiyu/README.md","hash":"46c4c8c308bd18c813da6b37356c7953f0d2e4af","modified":1764161571974},{"_id":"themes/anzhiyu/package.json","hash":"b1bd6fd513cd4d1a98a904b37c6cd28296af7ee7","modified":1764161572021},{"_id":"themes/anzhiyu/_config.yml","hash":"89c266c5199ab10c5cdb32136bdf5d56042bf07e","modified":1764165018721},{"_id":"themes/anzhiyu/sw-rules.js","hash":"0dc0fbe4d5e9acad4fffe69355830dcd41f89da6","modified":1764161572102},{"_id":"themes/anzhiyu/plugins.yml","hash":"23296290f36523e41926e22888f3d87b236dfbf0","modified":1764161572021},{"_id":"themes/anzhiyu/layout/archive.pug","hash":"b8778e55f1aab2431daa4a64cba991ef40e33224","modified":1764161571977},{"_id":"themes/anzhiyu/layout/index.pug","hash":"cf1b756e06864a47352bb9890519eafcf5d0340d","modified":1764161572020},{"_id":"themes/anzhiyu/layout/category.pug","hash":"1d55b22a50675d1ecfb95d031ea011245c7c6511","modified":1764161571977},{"_id":"themes/anzhiyu/layout/tag.pug","hash":"354b85519feab71c0233eb240655d0e0ec67021c","modified":1764161572020},{"_id":"themes/anzhiyu/layout/page.pug","hash":"98e81d10e6caab2ff79b4a2788d2312acded36ef","modified":1764161572020},{"_id":"themes/anzhiyu/languages/default.yml","hash":"be22c8d1730408a2ac3ec9a57406e297fc1f7ce6","modified":1764161571976},{"_id":"themes/anzhiyu/languages/en.yml","hash":"4c46ef35360b8322269417bcae68e609ca8f85be","modified":1764161571976},{"_id":"themes/anzhiyu/layout/post.pug","hash":"0d8d8cfd31e97053c908dac3ee19072825a6a2dc","modified":1764161572020},{"_id":"themes/anzhiyu/languages/zh-CN.yml","hash":"dbd5b387322693ed53df84eab709bf04ffeb8b81","modified":1764161571976},{"_id":"themes/anzhiyu/source/favicon.ico","hash":"14310db268ea8d3b2096f434c6e293fc207f5f09","modified":1764161572084},{"_id":"themes/anzhiyu/.github/ISSUE_TEMPLATE/bug_report.yml","hash":"3978be1ecdd21be564aa590b17eda6f03cd77e19","modified":1764161571967},{"_id":"themes/anzhiyu/languages/zh-TW.yml","hash":"0e0b432912390e3de9d99bc54add99e4d265d3d1","modified":1764161571977},{"_id":"themes/anzhiyu/.github/ISSUE_TEMPLATE/config.yml","hash":"a23b745378bc745b15f2dfefcc6a203d5d1d5fcd","modified":1764161571967},{"_id":"themes/anzhiyu/.github/workflows/issue_close_question.yml","hash":"a7f1bf4578faa6092898a9a44bfd467cbb1788dd","modified":1764161571969},{"_id":"themes/anzhiyu/.github/ISSUE_TEMPLATE/feature_request.yml","hash":"53260c55a97ed93e6a1f9acc23b9d21193cae6ef","modified":1764161571969},{"_id":"themes/anzhiyu/.github/workflows/issue_close_stale.yml","hash":"6151bdec23ded908adf01ba5ecdf3c0da573449d","modified":1764161571971},{"_id":"themes/anzhiyu/.github/workflows/issue_duplicate.yml","hash":"42a8e022434604081fe443d416bd443efd887015","modified":1764161571971},{"_id":"themes/anzhiyu/.github/workflows/issue_question.yml","hash":"72ce6e36847f20952d8f8742e4fd1969cd086320","modified":1764161571972},{"_id":"themes/anzhiyu/.github/workflows/issue_invalid.yml","hash":"8cdde230c8f9330cc7cd5c149ea5fc258ffb0b8b","modified":1764161571971},{"_id":"themes/anzhiyu/.github/workflows/publish.yml","hash":"05857c2f265246d8de00e31037f2720709540c09","modified":1764161571972},{"_id":"themes/anzhiyu/.github/workflows/issue_wontfix.yml","hash":"3b498c22281bb454f8ee1135a4becee0adc5b9ae","modified":1764161571972},{"_id":"themes/anzhiyu/.github/workflows/stale.yml","hash":"ac62b989b5550c756e1986fcc68f243170705383","modified":1764161571972},{"_id":"themes/anzhiyu/layout/includes/404.pug","hash":"aa158d5a661aa2fab4737b9460ce34f6784fdee5","modified":1764161571978},{"_id":"themes/anzhiyu/layout/includes/additional-js.pug","hash":"d7e42261a79651ce13ff2213947ecb3e4c41ee81","modified":1764161571978},{"_id":"themes/anzhiyu/layout/includes/categoryGroup.pug","hash":"243f63820db5f3241e682ae8f3baffd6501df3de","modified":1764161571981},{"_id":"themes/anzhiyu/layout/includes/footer.pug","hash":"50131aa8ad85fd6c08d8e1cb2d3dcfceb5964abe","modified":1764161571981},{"_id":"themes/anzhiyu/layout/includes/head.pug","hash":"8db5b7382011745f53b99b5b5577ae28140068e2","modified":1764161571982},{"_id":"themes/anzhiyu/layout/includes/bbTimeList.pug","hash":"0a0c4cdf69314c3a9ecb078f4213c76129a9ac06","modified":1764161571980},{"_id":"themes/anzhiyu/layout/includes/layout.pug","hash":"3bc51657414be0c94bd27752616cc7f7d54f20cd","modified":1764161571988},{"_id":"themes/anzhiyu/layout/includes/music.pug","hash":"163f5bbeadbe481a809652e6ce453022db26694a","modified":1764161571990},{"_id":"themes/anzhiyu/layout/includes/mourn.pug","hash":"d114b9493fbe6551b0c4ad1c1d8886b7f98a0d60","modified":1764161571990},{"_id":"themes/anzhiyu/layout/includes/pagination.pug","hash":"1e0be343f9bdc6cefc5ff0dd3c2936ed91d5be86","modified":1764161571994},{"_id":"themes/anzhiyu/layout/includes/shortcutKey.pug","hash":"dcf8fb7bbddd4a64626f4fcf2523ace2dfce879f","modified":1764161571996},{"_id":"themes/anzhiyu/layout/includes/sidebar.pug","hash":"fd6d7873df74994ed6a36bd07a438c427db97e18","modified":1764161571996},{"_id":"themes/anzhiyu/scripts/events/cdn.js","hash":"39aaf1d4fed1382c85776581225747285b7b388c","modified":1764161572022},{"_id":"themes/anzhiyu/scripts/events/comment.js","hash":"a3d1f417965ca20253c36f9e93429f3df6268856","modified":1764161572023},{"_id":"themes/anzhiyu/scripts/events/merge_config.js","hash":"4bc10659ac9b483032a13bd3d7bce9094fd7c58b","modified":1764161572023},{"_id":"themes/anzhiyu/scripts/events/init.js","hash":"006401bd6f4bb3fc8756e752d6ab93bf770bb77f","modified":1764161572023},{"_id":"themes/anzhiyu/scripts/events/welcome.js","hash":"3177e070519a10fff904595e152a329115d22c61","modified":1764161572024},{"_id":"themes/anzhiyu/scripts/events/stylus.js","hash":"675eee74f9efcbc846b89eb9ba41f130a95310ee","modified":1764161572024},{"_id":"themes/anzhiyu/scripts/filters/post_lazyload.js","hash":"61f06b25c09434340e81c8c3dbbd1a0d58406652","modified":1764161572024},{"_id":"themes/anzhiyu/scripts/filters/random_cover.js","hash":"98275d777b3c388345de3ee8caf5d16900388925","modified":1764161572026},{"_id":"themes/anzhiyu/layout/includes/rightside.pug","hash":"d865835bc5432d8ec15fd0cb168643f3e9b77a18","modified":1764161571996},{"_id":"themes/anzhiyu/scripts/helpers/aside_archives.js","hash":"ca03ba2a0a7f2132ac5d3f66cb1bbd9e078aed3f","modified":1764161572026},{"_id":"themes/anzhiyu/scripts/helpers/aside_categories.js","hash":"19244d6a9e42c34b9df2250be2467c352fa5fd41","modified":1764161572026},{"_id":"themes/anzhiyu/scripts/helpers/catalog_list.js","hash":"aa38fd791d58df3fd518adf144578f160073d06e","modified":1764161572027},{"_id":"themes/anzhiyu/scripts/helpers/findArchiveLength.js","hash":"d8aa1a4824ba6b0df911af563ae5fb361257a88a","modified":1764161572027},{"_id":"themes/anzhiyu/scripts/helpers/get_version.js","hash":"f2b7364706fc4d039da4a486e133baf7accf6836","modified":1764161572027},{"_id":"themes/anzhiyu/scripts/helpers/inject_head_js.js","hash":"847bc24452bc23dfc860b219588cfb2bff84cfbf","modified":1764161572028},{"_id":"themes/anzhiyu/scripts/helpers/page.js","hash":"dff1124a8825479606e45e69e329a3ad1903ec87","modified":1764161572028},{"_id":"themes/anzhiyu/scripts/helpers/tags_page_list.js","hash":"35d71c025a3289be188371cc56320c563213c4af","modified":1764161572029},{"_id":"themes/anzhiyu/scripts/helpers/random.js","hash":"d659d1d05c919d1abba2dc55439749e6e5b6e707","modified":1764161572028},{"_id":"themes/anzhiyu/scripts/helpers/related_post.js","hash":"c5f70efdbfd733f4dfec0ca8fe4aded0eec394cf","modified":1764161572029},{"_id":"themes/anzhiyu/scripts/helpers/year.js","hash":"94f15ddba7d29cdcc4dd52ed6c35c9c29cc19d37","modified":1764161572029},{"_id":"themes/anzhiyu/scripts/helpers/sort_attr_post.js","hash":"6b6e9fb0d0dc38e8d7136dc7720c70f0c29619ab","modified":1764161572029},{"_id":"themes/anzhiyu/scripts/tag/btns.js","hash":"200e1ce72f335caa71dc8423f5c5e2aba1195b61","modified":1764161572030},{"_id":"themes/anzhiyu/scripts/tag/Introduction-card.js","hash":"61a55f9b1f5f576e6900d2900cb42754575a4cb7","modified":1764161572030},{"_id":"themes/anzhiyu/scripts/tag/bilibili.js","hash":"085e033cb359e8f109968748cedbd0079515e7c6","modified":1764161572030},{"_id":"themes/anzhiyu/scripts/tag/checkbox.js","hash":"fa93b169fe74bced502b0d16fe3d6bd17434b8f3","modified":1764161572031},{"_id":"themes/anzhiyu/scripts/tag/dogeplayer.js","hash":"e9b0d88e38d3caf88b66ea39ca704d45c643ba51","modified":1764161572032},{"_id":"themes/anzhiyu/scripts/tag/flink.js","hash":"5b0086d1b726d1068b3d8ee0563ae31485896c4b","modified":1764161572033},{"_id":"themes/anzhiyu/scripts/events/404.js","hash":"170e72e851257365468024557c767360c3deafbf","modified":1764161572022},{"_id":"themes/anzhiyu/scripts/tag/button.js","hash":"430c31584930bc5407811c3dbc01be92473cfcbf","modified":1764161572031},{"_id":"themes/anzhiyu/scripts/tag/folding.js","hash":"dc4e409eabebf5769b50c12c9e8c66b749d0ae85","modified":1764161572033},{"_id":"themes/anzhiyu/scripts/tag/gallery.js","hash":"0364b021f2519a937464e585a7e2cbdde57ca412","modified":1764161572033},{"_id":"themes/anzhiyu/scripts/tag/image.js","hash":"0b7051574af6cf28c378db65f6c6dab722a8e118","modified":1764161572035},{"_id":"themes/anzhiyu/scripts/tag/hide.js","hash":"37b81ff46d104554b9a5934bfd434dbfd6a84958","modified":1764161572033},{"_id":"themes/anzhiyu/scripts/tag/inline-labels.js","hash":"08fbdc0ea622270e1236a28778f875c8ad2e5516","modified":1764161572035},{"_id":"themes/anzhiyu/scripts/tag/label.js","hash":"87acd7d5615dd8034c51ba28d4964992d2ffed37","modified":1764161572035},{"_id":"themes/anzhiyu/scripts/tag/link.js","hash":"a5d49f1d0e4602b0fce158efd0b1ec02c0bfd3e3","modified":1764164635567},{"_id":"themes/anzhiyu/scripts/tag/inlineImg.js","hash":"a43ee2c7871bdd93cb6beb804429e404570f7929","modified":1764161572035},{"_id":"themes/anzhiyu/scripts/tag/iconfont.js","hash":"ea983f7c8dd060ed411044df1c10aa6b72dec34f","modified":1764161572033},{"_id":"themes/anzhiyu/scripts/tag/media.js","hash":"76efb072e0716e55deedb044fed1ad585871335b","modified":1764161572036},{"_id":"themes/anzhiyu/scripts/tag/mermaid.js","hash":"d3d6c8a23ddfecac35f7022eecd4ffc6171a37fa","modified":1764161572036},{"_id":"themes/anzhiyu/scripts/tag/note.js","hash":"d51812b43924f1bbf413c67499510dd125022005","modified":1764161572036},{"_id":"themes/anzhiyu/scripts/tag/site.js","hash":"bc34bfab53f520bec33d273ee599de5905ca19a9","modified":1764161572036},{"_id":"themes/anzhiyu/scripts/tag/span.js","hash":"0a2188be1e3ee6ed183c0f16d24795ef31116e10","modified":1764161572037},{"_id":"themes/anzhiyu/scripts/tag/tabs.js","hash":"dea5cd52bb9fd658bc03074b2388d91ea528fc2b","modified":1764161572037},{"_id":"themes/anzhiyu/scripts/tag/timeline.js","hash":"300eb779588bf35a1b687d9f829d866074b707e3","modified":1764161572037},{"_id":"themes/anzhiyu/source/css/index.styl","hash":"ddded5cd1da248fdc30556a33877579ff8379a48","modified":1764161572084},{"_id":"themes/anzhiyu/source/css/var.styl","hash":"7bdedada1176e55d5fb72e3cc9f46e01d03b704a","modified":1764161572084},{"_id":"themes/anzhiyu/scripts/tag/tip.js","hash":"e45a0955439dfbe6c0b4d27f8403896a0fb1d33b","modified":1764161572038},{"_id":"themes/anzhiyu/source/img/512.png","hash":"6988b23a31304d9de45b95a1e7c05dd42024e560","modified":1764161572086},{"_id":"themes/anzhiyu/source/img/comment_bg.png","hash":"91612a887446fb436e9151981e2289f2a426a3e5","modified":1764161572087},{"_id":"themes/anzhiyu/source/img/default_cover.jpg","hash":"455fa65e2736f61ac36360dd4f76fc1ab6a1cdd5","modified":1764161572087},{"_id":"themes/anzhiyu/source/img/algolia.svg","hash":"45eeea0b5fba833e21e38ea10ed5ab385ceb4f01","modified":1764161572086},{"_id":"themes/anzhiyu/source/img/favicon.ico","hash":"14310db268ea8d3b2096f434c6e293fc207f5f09","modified":1764161572087},{"_id":"themes/anzhiyu/source/js/main.js","hash":"888563ad7324e565e6f5060ca126d69c7309bef1","modified":1764164627306},{"_id":"themes/anzhiyu/source/js/tw_cn.js","hash":"6cbec565e98cbd49aa75e6161d8fa996ae3be91a","modified":1764161572102},{"_id":"themes/anzhiyu/source/js/utils.js","hash":"68e7f87c38365ef1271b69943395aa5fdb5417ea","modified":1764161572102},{"_id":"themes/anzhiyu/layout/includes/anzhiyu/tags-group-all.pug","hash":"bc16fa91883895544273161cc8672bfe5c010e5e","modified":1764161571980},{"_id":"themes/anzhiyu/layout/includes/anzhiyu/clock.pug","hash":"c13b21cdcbc5280deb26537c58af5443cb66c62f","modified":1764161571979},{"_id":"themes/anzhiyu/layout/includes/anzhiyu/rightmenu.pug","hash":"2747252c6337d8fb7ba773cdb466611607f9a23b","modified":1764161571980},{"_id":"themes/anzhiyu/layout/includes/anzhiyu/ai-info.pug","hash":"0c2e9e58069880c0617208840cf2f0712339ddf0","modified":1764161571979},{"_id":"themes/anzhiyu/layout/includes/anzhiyu/log-js.pug","hash":"a44b4f89f39d1e32889849c3dd1403dffa2786a4","modified":1764161571979},{"_id":"themes/anzhiyu/layout/includes/head/Open_Graph.pug","hash":"dff5b967a641f385c4661fe66ad62d53cabf857a","modified":1764161571982},{"_id":"themes/anzhiyu/layout/includes/bili-banner/index.pug","hash":"8cb1c404adc6fe188bdceca3c09d3f215048e9bd","modified":1764161571981},{"_id":"themes/anzhiyu/layout/includes/anzhiyu/console.pug","hash":"d46c93a7a22129795cc856045967b0e07c5e53c2","modified":1764161571979},{"_id":"themes/anzhiyu/layout/includes/head/analytics.pug","hash":"15530d9ac59c576d79af75dd687efe71e8d261b0","modified":1764161571982},{"_id":"themes/anzhiyu/layout/includes/head/config.pug","hash":"068b2fe70e7f26cdd1f0ee6c75d79266ceed89dd","modified":1764161571983},{"_id":"themes/anzhiyu/layout/includes/head/google_adsense.pug","hash":"95a37e92b39c44bcbea4be7e29ddb3921c5b8220","modified":1764161571983},{"_id":"themes/anzhiyu/layout/includes/head/config_site.pug","hash":"3038adec24b17f019bdd7d6aa15ebe091b11397d","modified":1764161571983},{"_id":"themes/anzhiyu/layout/includes/head/noscript.pug","hash":"d16ad2ee0ff5751fd7f8a5ce1b83935518674977","modified":1764161571983},{"_id":"themes/anzhiyu/layout/includes/head/preconnect.pug","hash":"56ef61e74598cf60551d363a15fc53842b8dc41b","modified":1764161571983},{"_id":"themes/anzhiyu/layout/includes/head/pwa.pug","hash":"a4cc65381275e09f3f54f6e958d359c89c7b2c4e","modified":1764161571983},{"_id":"themes/anzhiyu/layout/includes/head/site_verification.pug","hash":"e2e8d681f183f00ce5ee239c42d2e36b3744daad","modified":1764161571985},{"_id":"themes/anzhiyu/layout/includes/header/index.pug","hash":"c865d51436cfd5413df6c691a7ab1f0eb600e79c","modified":1764161571985},{"_id":"themes/anzhiyu/layout/includes/header/post-info.pug","hash":"0f1503c88d05ada69919e0bdbbf7b2ea1603d20b","modified":1764161571986},{"_id":"themes/anzhiyu/layout/includes/header/menu_item.pug","hash":"4537154b8830310ce5dff3c9cfd558f0ec1311a5","modified":1764161571986},{"_id":"themes/anzhiyu/layout/includes/header/social.pug","hash":"2185b69eb54656ed9e401bc47ca3cd9905b022f3","modified":1764161571988},{"_id":"themes/anzhiyu/layout/includes/loading/fullpage-loading.pug","hash":"39977280dd32f1435a97f285a75f2a02902472d6","modified":1764161571989},{"_id":"themes/anzhiyu/layout/includes/loading/index.pug","hash":"f86b0c45874ae1335ab575c29d4f9c8ea09ab92a","modified":1764161571989},{"_id":"themes/anzhiyu/layout/includes/header/nav.pug","hash":"e567624b78d723346193a9b0d28032031997b865","modified":1764161571986},{"_id":"themes/anzhiyu/layout/includes/mixins/post-ui.pug","hash":"80858e19caf57c275cb7d6acf3bfff7d0c90c774","modified":1764161571990},{"_id":"themes/anzhiyu/layout/includes/loading/pace.pug","hash":"7f04cabd68f75d7f953503283316e1594bbec45f","modified":1764161571989},{"_id":"themes/anzhiyu/layout/includes/page/album.pug","hash":"0ca70f1ec4757d6127048d71762752dabf1af2ea","modified":1764161571991},{"_id":"themes/anzhiyu/layout/includes/mixins/article-sort.pug","hash":"7a06f5f24f8e32b3025cf43474db9519d48517e5","modified":1764161571990},{"_id":"themes/anzhiyu/layout/includes/page/about.pug","hash":"fa529ca6b5ab9001822668697f410cc3020980ad","modified":1764161571991},{"_id":"themes/anzhiyu/layout/includes/page/categories.pug","hash":"f23d074ef6875311e74169da7592ecf667539775","modified":1764161571992},{"_id":"themes/anzhiyu/layout/includes/page/album_detail.pug","hash":"c735533f7671905d06bae5645306cd08abb0b43c","modified":1764161571992},{"_id":"themes/anzhiyu/layout/includes/page/default-page.pug","hash":"12c65c174d26a41821df9bad26cdf1087ec5b0ca","modified":1764161571992},{"_id":"themes/anzhiyu/layout/includes/page/equipment.pug","hash":"87ca40c49ddfe9c266cd96b4eb3594d7c64c1d55","modified":1764161571992},{"_id":"themes/anzhiyu/layout/includes/page/essay.pug","hash":"b0a25ded52c72c84bd29593bd7a57046c4b36195","modified":1764161571993},{"_id":"themes/anzhiyu/layout/includes/page/fcircle.pug","hash":"a4bfc9855bcfc859f0c04e869e0ec8cb8d2a1357","modified":1764161571993},{"_id":"themes/anzhiyu/layout/includes/page/flink.pug","hash":"3756dfd0ad97968c02a9be662dc5e9253cbc33b9","modified":1764161571993},{"_id":"themes/anzhiyu/layout/includes/page/music.pug","hash":"3cbec3b3dc0f0e812f29c222ebb2d2a3d8c2719f","modified":1764161571994},{"_id":"themes/anzhiyu/layout/includes/page/tags.pug","hash":"62882d8a699254486add2f7b0f089521732e4869","modified":1764161571994},{"_id":"themes/anzhiyu/layout/includes/popup/index.pug","hash":"3ac8714556f94a614100aeddeb7f7e0cdff2fb9c","modified":1764161571995},{"_id":"themes/anzhiyu/layout/includes/post/post-copyright.pug","hash":"10638ede3b9ea1ef4e336f5c4d690239ef353843","modified":1764161571995},{"_id":"themes/anzhiyu/layout/includes/post/ptool.pug","hash":"173d1a63099109bd909de919281db9f2b2a023f0","modified":1764161571995},{"_id":"themes/anzhiyu/layout/includes/post/reward.pug","hash":"cdf5ff34ba8efe526cfe77ddf3277d997d172d41","modified":1764161571995},{"_id":"themes/anzhiyu/layout/includes/third-party/aplayer.pug","hash":"c7cfade2b160380432c47eef4cd62273b6508c58","modified":1764161571997},{"_id":"themes/anzhiyu/layout/includes/third-party/footerBarSubtitle.pug","hash":"bb2df2fbbdc9fe0f4b9d66928247faa49f70e2e5","modified":1764161572006},{"_id":"themes/anzhiyu/layout/includes/third-party/effect.pug","hash":"6528e86656906117a1af6b90e0349c2c4651d5e1","modified":1764161572006},{"_id":"themes/anzhiyu/layout/includes/page/room.pug","hash":"c35a2fb076e0196ba28389b5309dde33a2add576","modified":1764161571994},{"_id":"themes/anzhiyu/layout/includes/third-party/pangu.pug","hash":"0f024e36b8116118233e10118714bde304e01e12","modified":1764161572011},{"_id":"themes/anzhiyu/layout/includes/third-party/prismjs.pug","hash":"ffb9ea15a2b54423cd4cd441e2d061b8233e9b58","modified":1764161572012},{"_id":"themes/anzhiyu/layout/includes/third-party/pjax.pug","hash":"4ee026b34e6ecc2c03cf04933973b496472309c2","modified":1764161572011},{"_id":"themes/anzhiyu/layout/includes/top/top.pug","hash":"9f849b05e220efa72d56f524a27ab2877e27e9e3","modified":1764161572015},{"_id":"themes/anzhiyu/layout/includes/widget/card_ad.pug","hash":"60dc48a7b5d89c2a49123c3fc5893ab9c57dd225","modified":1764161572015},{"_id":"themes/anzhiyu/layout/includes/third-party/subtitle.pug","hash":"142621f70bedcb5033ee99a988f7bb6c5eea3493","modified":1764161572015},{"_id":"themes/anzhiyu/layout/includes/widget/card_announcement.pug","hash":"ed8796dd3c5710d745fdcc0021b02a3cda07fd1b","modified":1764161572015},{"_id":"themes/anzhiyu/layout/includes/widget/card_archives.pug","hash":"9ca97d85cc7b214e1107d0b4feac4d8ad2fd0ac8","modified":1764161572016},{"_id":"themes/anzhiyu/layout/includes/widget/card_categories.pug","hash":"d1a416d0a8a7916d0b1a41d73adc66f8c811e493","modified":1764161572017},{"_id":"themes/anzhiyu/layout/includes/widget/card_author.pug","hash":"b7e11bcd199f343a844315e5d16735205dded9d2","modified":1764161572016},{"_id":"themes/anzhiyu/layout/includes/widget/card_bottom_self.pug","hash":"13dc8ce922e2e2332fe6ad5856ebb5dbf9ea4444","modified":1764161572016},{"_id":"themes/anzhiyu/layout/includes/widget/card_console_archives.pug","hash":"8c095ae91183d6a2aeed64f378e60baaa29d4065","modified":1764161572017},{"_id":"themes/anzhiyu/layout/includes/widget/card_console_tags.pug","hash":"d723516d48cd94a68819df5c61087c9e7339e2af","modified":1764161572017},{"_id":"themes/anzhiyu/layout/includes/widget/card_newest_comment.pug","hash":"419eed9a771299c9ffb85fdf38073bbd5bd7775c","modified":1764161572018},{"_id":"themes/anzhiyu/layout/includes/widget/card_post_toc.pug","hash":"638417324111b66c834314b96cbf02e959be58f4","modified":1764161572018},{"_id":"themes/anzhiyu/layout/includes/widget/card_recent_post.pug","hash":"544272cb0977b8a941de22f1f58f76d370b2cbbd","modified":1764161572018},{"_id":"themes/anzhiyu/layout/includes/widget/card_tags.pug","hash":"3475134643b70cbf0e806806bd2e0d2a7371f8a5","modified":1764161572018},{"_id":"themes/anzhiyu/layout/includes/widget/card_top_self.pug","hash":"ae67c6d4130a6c075058a9c1faea1648bcc6f83e","modified":1764161572019},{"_id":"themes/anzhiyu/layout/includes/widget/card_webinfo.pug","hash":"5ddf285ca0ecbb57cbbbc36a4e9eaaca40406257","modified":1764161572019},{"_id":"themes/anzhiyu/layout/includes/widget/card_weixin.pug","hash":"28f11437bcba4df1e53fc1e32df213392b9ca4b6","modified":1764161572019},{"_id":"themes/anzhiyu/layout/includes/widget/index.pug","hash":"e33c360217b11a7980e780a5bc20e9d31f5dacf5","modified":1764161572020},{"_id":"themes/anzhiyu/source/css/_global/function.styl","hash":"e91b257ce982b670eb911c7120f379960083c959","modified":1764161572058},{"_id":"themes/anzhiyu/source/css/_global/icon.styl","hash":"da488461e8c5e504961c0a8f44b1e3605f72f956","modified":1764161572058},{"_id":"themes/anzhiyu/source/css/_global/index.styl","hash":"55850e21e138a0ad8250f4b2ff38412fdb343d1d","modified":1764161572058},{"_id":"themes/anzhiyu/source/css/_global/loading.styl","hash":"734c69c16135543267794e12b43e776d501fb6ca","modified":1764161572059},{"_id":"themes/anzhiyu/source/css/_highlight/highlight.styl","hash":"4a1f547d921d1b44f1221e60a42666a63a19e5a1","modified":1764161572059},{"_id":"themes/anzhiyu/source/css/_highlight/theme.styl","hash":"c074efc93f4f118c3fc3b3d3c9f9abc42e4858b4","modified":1764161572061},{"_id":"themes/anzhiyu/source/css/_mode/darkmode.styl","hash":"43391bb6a4d1908c87515851c41b8d97b847b49b","modified":1764161572069},{"_id":"themes/anzhiyu/source/css/_mode/readmode.styl","hash":"a5a27dea73ed993ce81ca691eff9eb71c2b311a7","modified":1764161572069},{"_id":"themes/anzhiyu/source/css/_layout/404.styl","hash":"02a8df2e9734848cc4670a4b9f6e9a776e995644","modified":1764161572062},{"_id":"themes/anzhiyu/source/css/_layout/aside.styl","hash":"b62fbde63342f779b4dd27492e6da878c25f7dfb","modified":1764161572062},{"_id":"themes/anzhiyu/source/css/_layout/banner.styl","hash":"62f4202467cc9f313361911ed2a2005e66b3b2ca","modified":1764161572063},{"_id":"themes/anzhiyu/source/css/_layout/chat.styl","hash":"29f48f9370f245e6e575b5836bccf47eb5688d8b","modified":1764161572063},{"_id":"themes/anzhiyu/source/css/_layout/comments.styl","hash":"3dbb4c0e1ef79eab1f327d303c3aed61ddc3f58c","modified":1764161572064},{"_id":"themes/anzhiyu/source/css/_layout/footer.styl","hash":"ce21052dd27e752c3734083ec1401b96c542bfda","modified":1764161572064},{"_id":"themes/anzhiyu/source/css/_layout/head.styl","hash":"960ca89ac2456f165e0b71214ef0b1519e1690ad","modified":1764164624470},{"_id":"themes/anzhiyu/source/css/_layout/home_top.styl","hash":"c975f539ae6bed3b24c9dc3914b412f179ee2543","modified":1764161572065},{"_id":"themes/anzhiyu/source/css/_layout/nav.styl","hash":"200ddfe40c4a820af25fcfa71aa450b22741f6df","modified":1764161572065},{"_id":"themes/anzhiyu/source/css/_layout/oneGraphFlow.styl","hash":"1e5843caf8674429a5782712879c4a532074514d","modified":1764161572065},{"_id":"themes/anzhiyu/source/css/_layout/ptool.styl","hash":"2ffeca0499c6ad1c4ea2ef783d7493b713b24569","modified":1764161572066},{"_id":"themes/anzhiyu/source/css/_layout/post.styl","hash":"2a4a8af05bc24edbd14c4160b17489242164727f","modified":1764161572066},{"_id":"themes/anzhiyu/source/css/_layout/pagination.styl","hash":"88f2fbb0ccb061410b07e1ed6303583230e96d4e","modified":1764161572065},{"_id":"themes/anzhiyu/source/css/_layout/relatedposts.styl","hash":"c67558ba609b59375f8ee6ad479fcb16ddda9cb6","modified":1764161572066},{"_id":"themes/anzhiyu/source/css/_layout/rightside.styl","hash":"bebc753a414d3fb807b5bf8dfeb87fe602e92e73","modified":1764161572067},{"_id":"themes/anzhiyu/source/css/_layout/reward.styl","hash":"152b802a38f029dece2b8f8812404cec25975212","modified":1764161572067},{"_id":"themes/anzhiyu/source/css/_layout/rightmenu.styl","hash":"cc622c70ff61ef70dfa6445b5b4b09eb92cf9994","modified":1764161572067},{"_id":"themes/anzhiyu/source/css/_layout/shortcutKey.styl","hash":"ca7674768558396a8e2f9eaa452575bff099e4e8","modified":1764161572067},{"_id":"themes/anzhiyu/source/css/_layout/sidebar.styl","hash":"57d6857a1209dacb6f3fd0eb3c3f539fef3a2daf","modified":1764161572068},{"_id":"themes/anzhiyu/source/css/_layout/third-party.styl","hash":"a6b708dfeda4ad837bbfc76bd74810805ca521a0","modified":1764161572068},{"_id":"themes/anzhiyu/source/css/_page/404.styl","hash":"50dbb9e6d98c71ffe16741b8c1b0c1b9771efd2b","modified":1764161572069},{"_id":"themes/anzhiyu/source/css/_page/about.styl","hash":"72a3345b9791fcf51bb74ff6eebfda4674e8f60d","modified":1764161572070},{"_id":"themes/anzhiyu/source/css/_page/archives.styl","hash":"8652be12d88083f71a1efb88a2482a0aeda2c65f","modified":1764161572070},{"_id":"themes/anzhiyu/source/css/_page/categories.styl","hash":"f01ee74948cedb44e53cd3bb1ef36b7d2778ede7","modified":1764161572070},{"_id":"themes/anzhiyu/source/css/_page/common.styl","hash":"99ca9cb011349c045ed779bd5db9763c2073bbfe","modified":1764161572071},{"_id":"themes/anzhiyu/source/css/_page/equipment.styl","hash":"8ed450c37e8b5b5d6ce04245b54fc0877b0ad0d9","modified":1764161572071},{"_id":"themes/anzhiyu/source/css/_page/homepage.styl","hash":"7b2b2b4a7f3139f7db2d535b2ed7167db8bfd0ed","modified":1764161572072},{"_id":"themes/anzhiyu/source/css/_page/reward.styl","hash":"3a6e95f58b1692c6ee67a669fc965d9dea026186","modified":1764161572073},{"_id":"themes/anzhiyu/source/css/_page/music.styl","hash":"290dd82c05bc21a0f22a7b666f2af233e9e8bbb2","modified":1764161572072},{"_id":"themes/anzhiyu/source/css/_page/tag_page.styl","hash":"704a74185d0e872ca3358567a2ecede5c2d35910","modified":1764161572073},{"_id":"themes/anzhiyu/source/css/_page/tags.styl","hash":"580feb7e8b0822a1be48ac380f8c5c53b1523321","modified":1764161572073},{"_id":"themes/anzhiyu/source/css/_search/index.styl","hash":"fd2833ec664a9de9a7b3dd1cade7d65e3ad80ddd","modified":1764161572075},{"_id":"themes/anzhiyu/source/css/_search/algolia.styl","hash":"f7cb2effef6b4e587fad385d7c11b4b23c110589","modified":1764161572073},{"_id":"themes/anzhiyu/source/css/_page/flink.styl","hash":"990a1b5d937980ec1f6f764f4b5ce371279cc451","modified":1764161572072},{"_id":"themes/anzhiyu/source/css/_search/local-search.styl","hash":"25e58a7a8bda4b73d0a0e551643ca01b09ccd7e5","modified":1764161572075},{"_id":"themes/anzhiyu/source/css/_tags/Introduction-card.styl","hash":"ec70e67c2a8bc1a0ebe536091d97bc326faf9973","modified":1764161572075},{"_id":"themes/anzhiyu/source/css/_tags/bilbili.styl","hash":"081833e071be562201c56ec4db000b7ac144a39a","modified":1764161572076},{"_id":"themes/anzhiyu/source/css/_tags/button.styl","hash":"af1840996356aeae6ffbee49ab86aa7834ab18a0","modified":1764161572076},{"_id":"themes/anzhiyu/source/css/_tags/checkbox.styl","hash":"2a31f4c0cd31f67342564ef22254eb317d82f331","modified":1764161572077},{"_id":"themes/anzhiyu/source/css/_tags/btns.styl","hash":"903b571a6e352e5014e35e9a675b7d2d6e5b82bd","modified":1764161572076},{"_id":"themes/anzhiyu/source/css/_tags/folding.styl","hash":"537320d4762bef842beabfbde9b27f0e2ece2ba6","modified":1764161572077},{"_id":"themes/anzhiyu/source/css/_tags/gallery.styl","hash":"697408d915056ae6e6814e0f24ca013f68227f74","modified":1764161572078},{"_id":"themes/anzhiyu/source/css/_tags/inline-labels.styl","hash":"d9bdac4ca48b19cc028efc1a084ebf99c38bb8ec","modified":1764161572079},{"_id":"themes/anzhiyu/source/css/_tags/hexo.styl","hash":"d76c38adf1d9c1279ef4241835667789f5b736e0","modified":1764161572078},{"_id":"themes/anzhiyu/source/css/_tags/hide.styl","hash":"810c54530d3799fe492d9c3d4842ab5ca4243092","modified":1764161572078},{"_id":"themes/anzhiyu/source/css/_tags/image.styl","hash":"4cf305b1d57d0c9bfe948f916fe9b124ee62fc0a","modified":1764161572079},{"_id":"themes/anzhiyu/source/css/_tags/inlineImg.styl","hash":"df9d405c33a9a68946b530410f64096bcb72560c","modified":1764161572079},{"_id":"themes/anzhiyu/source/css/_tags/label.styl","hash":"66c59e193d794cdb02cca7bd1dc4aea5a19d7e84","modified":1764161572080},{"_id":"themes/anzhiyu/source/css/_tags/media.styl","hash":"05a249c807cd7760492a9ef5914b3e363d7d1028","modified":1764161572080},{"_id":"themes/anzhiyu/source/css/_tags/site-card.styl","hash":"5ff77bfa663aca406e3a0bd822da0d6e3c3c2c8b","modified":1764161572080},{"_id":"themes/anzhiyu/source/css/_tags/note.styl","hash":"3b357c94cb8e80039cc1689161637d5b9690ff18","modified":1764161572080},{"_id":"themes/anzhiyu/source/css/_tags/timeline.styl","hash":"3076b68fece8ef394cbd44570037e5e479fdd277","modified":1764161572081},{"_id":"themes/anzhiyu/source/css/_tags/span.styl","hash":"f75112e431fcbef352a7ee7f0aa85e8b2f0b4a26","modified":1764161572081},{"_id":"themes/anzhiyu/source/css/_tags/tip.styl","hash":"0f712be285681bac71e96c48d0836b8fea52bf6f","modified":1764161572082},{"_id":"themes/anzhiyu/source/css/_third-party/snackbar.styl","hash":"47a90d6a87744c6e4ced18b95220debef8f278d0","modified":1764161572083},{"_id":"themes/anzhiyu/source/css/_tags/tabs.styl","hash":"b0dc66d3daafe8c3a022f7235de3d8224cb56ec9","modified":1764161572081},{"_id":"themes/anzhiyu/source/css/_third-party/normalize.min.css","hash":"007ada04a97d0fcaf55ee840a03f2f10b9abcbff","modified":1764161572082},{"_id":"themes/anzhiyu/source/css/_third-party/twikoo.styl","hash":"51475a99ec3281fb98ca8707e28064f91dd9c68a","modified":1764161572083},{"_id":"themes/anzhiyu/source/img/siteicon/32.png","hash":"147aae33224066ef2a5987c3cbbfa4309c49cef4","modified":1764161572095},{"_id":"themes/anzhiyu/source/img/siteicon/16.png","hash":"8dc6ca32ff1264f7c1c3a8f62727a8c96ea7525b","modified":1764161572093},{"_id":"themes/anzhiyu/source/img/siteicon/apple-icon-180.png","hash":"7f580ec4819c9ef10b1306102152f4473f037a98","modified":1764161572095},{"_id":"themes/anzhiyu/source/img/siteicon/manifest-icon-192.maskable.png","hash":"528b94ebcd34fb55436d64fdda76ef43ccbf031f","modified":1764161572096},{"_id":"themes/anzhiyu/source/js/anzhiyu/ai_abstract.js","hash":"be52eb13a416b18337d3b1142277920072e698c3","modified":1764161572097},{"_id":"themes/anzhiyu/source/img/siteicon/manifest-icon-512.maskable.png","hash":"6f8b4b3df8d1498db55a559f7106dc9b6e6af647","modified":1764161572096},{"_id":"themes/anzhiyu/source/js/anzhiyu/comment_barrage.js","hash":"1b30f922238f626c6a90ce2705789ba2362a2a9e","modified":1764161572098},{"_id":"themes/anzhiyu/source/js/anzhiyu/random_friends_post.js","hash":"1548fdc0a8cb4291bc8793dc8d321c59c097c08e","modified":1764161572099},{"_id":"themes/anzhiyu/source/js/anzhiyu/people.js","hash":"f3d2a3d0c730124d9f64dbf59486145c05a42ac6","modified":1764161572098},{"_id":"themes/anzhiyu/source/js/search/algolia.js","hash":"5c2a0d0489c51c6d9e54f5a3b0c6e66a5f649450","modified":1764161572101},{"_id":"themes/anzhiyu/source/js/anzhiyu/right_click_menu.js","hash":"d605ee0cab24604f97ccef5747bfacaa108645ba","modified":1764161572099},{"_id":"themes/anzhiyu/source/js/search/local-search.js","hash":"3ad66c75b4a0fc28a14a5478ee8a19fde72f837f","modified":1764161572101},{"_id":"themes/anzhiyu/layout/includes/third-party/chat/crisp.pug","hash":"2fb098a7aa45010a8cd212dc0bd5308c6e7c63e3","modified":1764161572001},{"_id":"themes/anzhiyu/layout/includes/third-party/chat/chatra.pug","hash":"ddce8352b371a1fb426bdb6c33f587eb37a69647","modified":1764161571999},{"_id":"themes/anzhiyu/layout/includes/third-party/chat/daovoice.pug","hash":"9b57a8e13de8fc51a5f550854e47164fd8ac1be8","modified":1764161572001},{"_id":"themes/anzhiyu/layout/includes/third-party/chat/tidio.pug","hash":"76b08a6da3eed8f90304fa6546783e5c04a792fb","modified":1764161572001},{"_id":"themes/anzhiyu/layout/includes/third-party/card-post-count/artalk.pug","hash":"6b8e29a8ad921ae50f8c43b8b7459ddc152b05ed","modified":1764161571997},{"_id":"themes/anzhiyu/layout/includes/third-party/chat/index.pug","hash":"9eff7757c825d776edde1c1dd09623a91d891e6b","modified":1764161572001},{"_id":"themes/anzhiyu/layout/includes/third-party/card-post-count/index.pug","hash":"a20dd36c318c7a37870fbc9dcecbc03f94ade817","modified":1764161571997},{"_id":"themes/anzhiyu/layout/includes/third-party/card-post-count/twikoo.pug","hash":"56c028ba0ea8fac19f0125114d765dfc56ce2b48","modified":1764161571998},{"_id":"themes/anzhiyu/layout/includes/third-party/card-post-count/valine.pug","hash":"39427e107230a10790972349c9dd4c4f31d55eb7","modified":1764161571998},{"_id":"themes/anzhiyu/layout/includes/third-party/card-post-count/waline.pug","hash":"b40b0cbd0389f03fed5ddf624fa598613135046a","modified":1764161571999},{"_id":"themes/anzhiyu/layout/includes/third-party/comments/artalk.pug","hash":"a486578b5b9cd130dbe22e7b4ad5cbe724dc4678","modified":1764161572002},{"_id":"themes/anzhiyu/layout/includes/third-party/comments/giscus.pug","hash":"1359563b73f3ce1629be49dc7780b4670f370995","modified":1764161572002},{"_id":"themes/anzhiyu/layout/includes/third-party/comments/index.pug","hash":"d5bb2cd8d96523a6693fa1bfa68c307f6c63f325","modified":1764161572002},{"_id":"themes/anzhiyu/layout/includes/third-party/comments/js.pug","hash":"29539a0f6c5622efba25805c8ff3252a70e1a2b7","modified":1764161572003},{"_id":"themes/anzhiyu/layout/includes/third-party/comments/valine.pug","hash":"e54a60b1795721153faaa887b46a68b68bcd3abc","modified":1764161572004},{"_id":"themes/anzhiyu/layout/includes/third-party/comments/waline.pug","hash":"612ab49a4a2e676c7c1110b5f618726b2dc7ddf7","modified":1764161572005},{"_id":"themes/anzhiyu/layout/includes/third-party/comments/twikoo.pug","hash":"1582986ede8a9c727004d1dc114bd7ee92880641","modified":1764161572004},{"_id":"themes/anzhiyu/layout/includes/third-party/math/index.pug","hash":"b8ae5fd7d74e1edcef21f5004fc96147e064d219","modified":1764161572007},{"_id":"themes/anzhiyu/layout/includes/third-party/math/katex.pug","hash":"235fb3c8b4da8ec6b010d4d30d3594d3dbfd0bbe","modified":1764161572007},{"_id":"themes/anzhiyu/layout/includes/third-party/newest-comments/artalk.pug","hash":"bbaaa94d99c345f7412803a98bf3d83722743dfb","modified":1764161572008},{"_id":"themes/anzhiyu/layout/includes/third-party/math/mermaid.pug","hash":"10f3949da0889c1ec3e3617da290927d834d1f6d","modified":1764161572007},{"_id":"themes/anzhiyu/layout/includes/third-party/math/mathjax.pug","hash":"fc072ac839401174b5d3cf9acd3b694246c23a55","modified":1764161572007},{"_id":"themes/anzhiyu/layout/includes/third-party/newest-comments/index.pug","hash":"6dafa98f6082e909c00396a4793ed3e7c866f824","modified":1764161572008},{"_id":"themes/anzhiyu/layout/includes/third-party/newest-comments/waline.pug","hash":"3fbf5700aedaa63ea09e8f68c063961db785fa44","modified":1764161572011},{"_id":"themes/anzhiyu/layout/includes/third-party/newest-comments/twikoo-comment.pug","hash":"3b20540a0e687cb05fd71a716e78f16a175a7d58","modified":1764161572008},{"_id":"themes/anzhiyu/layout/includes/third-party/newest-comments/valine.pug","hash":"3de61f1b229f2928ae120ecfa6166862c1735d18","modified":1764161572009},{"_id":"themes/anzhiyu/layout/includes/third-party/runtime/runtime-js.pug","hash":"63391ff01fd55d8c48b3a9e46d83d4af75908ffb","modified":1764161572012},{"_id":"themes/anzhiyu/layout/includes/third-party/search/algolia.pug","hash":"fbdeb32013088e8f7f4c8a6a1f20622e58dc09c2","modified":1764161572013},{"_id":"themes/anzhiyu/layout/includes/third-party/search/docsearch.pug","hash":"cb42537ea530d6679a46a1db092da0e91756b2c3","modified":1764161572013},{"_id":"themes/anzhiyu/layout/includes/third-party/search/index.pug","hash":"a99a41334387ee9a46c6f8e8212331a29a10d159","modified":1764161572013},{"_id":"themes/anzhiyu/layout/includes/third-party/search/local-search.pug","hash":"d3f133564dda5e2c51661a914ae5aab8fb9dbaf6","modified":1764161572013},{"_id":"themes/anzhiyu/layout/includes/third-party/share/share-js.pug","hash":"f61d63724ea5c5f352568b3a16bde023affefbe5","modified":1764161572014},{"_id":"themes/anzhiyu/layout/includes/third-party/share/index.pug","hash":"b0e932171cbdfeb8a98bc1e8b78172f672f5fdfd","modified":1764161572014},{"_id":"themes/anzhiyu/layout/includes/third-party/share/addtoany.pug","hash":"85c92f8a7e44d7cd1c86f089a05be438535e5362","modified":1764161572014},{"_id":"themes/anzhiyu/source/css/_extra/album/album.css","hash":"d3938a8e6edcf2be0dff02728f605406feba800d","modified":1764161572039},{"_id":"themes/anzhiyu/source/css/_extra/anzhiyu/custom.css","hash":"262291db00a343991c5472131804a4fd00deed4f","modified":1764161572039},{"_id":"themes/anzhiyu/source/css/_extra/album/album_detail.css","hash":"b75189ece986fa6b645751791a72d2783fbae05f","modified":1764161572039},{"_id":"themes/anzhiyu/source/css/_extra/aside_weixin/aside_weixin.css","hash":"17015ed4c296ea890e807716c6abe0a11ddcb906","modified":1764161572040},{"_id":"themes/anzhiyu/source/css/_extra/catalog_list/catalog_list.css","hash":"77526a3317c058a965ca44e446412f1d74b97c96","modified":1764161572040},{"_id":"themes/anzhiyu/source/css/_extra/clock/clock.css","hash":"b91f3216c6e859f89d9348bd9517c764e607402d","modified":1764161572042},{"_id":"themes/anzhiyu/source/css/_extra/commentBarrage/commentBarrage.css","hash":"a1355fe5e03c5e5dbd17761cc7a80fa9758c5891","modified":1764161572043},{"_id":"themes/anzhiyu/source/css/_extra/categoryBar/categoryBar.css","hash":"b9ab5612f4d24092388defcb8db7399445a10710","modified":1764161572041},{"_id":"themes/anzhiyu/source/css/_extra/code/code.css","hash":"976b68722d6698d7687f362532d7a0e6b6050d3e","modified":1764161572042},{"_id":"themes/anzhiyu/source/css/_extra/code/details_summary.css","hash":"30b01d74157aaccea84c4c0d7e0ebb65f5a7f9c9","modified":1764161572042},{"_id":"themes/anzhiyu/source/css/_extra/console/console.css","hash":"f61b9504a5f7b33d7508c9c5201c0c21ae9f8d53","modified":1764161572043},{"_id":"themes/anzhiyu/source/css/_extra/essay_page/essay_page.css","hash":"0d62e0d6b6f57fce49d347c8ce969071933dcd45","modified":1764161572043},{"_id":"themes/anzhiyu/source/css/_extra/essay_page/home_essay_bar.css","hash":"bfb259092223dcdfcb1a652330dc8ea1236fe76c","modified":1764161572043},{"_id":"themes/anzhiyu/source/css/_extra/fix/aplayer.css","hash":"00aee0451ccb5b2f402ecb7f358acf78c53cee60","modified":1764161572045},{"_id":"themes/anzhiyu/source/css/_extra/fix/bilibili-ratio.css","hash":"ad6edf2b75dd717e9dff9fe4ca4db79c1599a6f9","modified":1764161572045},{"_id":"themes/anzhiyu/source/css/_extra/fix/bilibili-bangumi.css","hash":"81567514e32d5c2cc647aff121f405c7a7b50897","modified":1764161572045},{"_id":"themes/anzhiyu/source/css/_extra/fix/categories.css","hash":"563bd4583007329c6e34c28883ee26a39af6c8f3","modified":1764161572046},{"_id":"themes/anzhiyu/source/css/_extra/fix/comments.css","hash":"667a4182d046cb6bf0561bdb7fe8c788ae79438f","modified":1764161572046},{"_id":"themes/anzhiyu/source/css/_extra/fix/clock.css","hash":"90e0bce1341d9e01aa0efaf9c70256ef5fe6139b","modified":1764161572046},{"_id":"themes/anzhiyu/source/css/_extra/fix/fcircle_page.css","hash":"02ce333e7f9ed6b9756a6706475192e2fd3fbd4b","modified":1764161572047},{"_id":"themes/anzhiyu/source/css/_extra/fix/dark.css","hash":"febe18af9e0cc45c6a35f0e0ef085c182985afa6","modified":1764161572047},{"_id":"themes/anzhiyu/source/css/_extra/fix/gitcalendar.css","hash":"f99c63423cbedb8f12ccea673d8e79e10a4cfb6c","modified":1764161572047},{"_id":"themes/anzhiyu/source/css/_extra/fix/hexo-tag-dplayer.css","hash":"90e6ba180e0b9267aa0bf27eb9f0a1d2e9cb3ecc","modified":1764161572047},{"_id":"themes/anzhiyu/source/css/_extra/fix/hide-block.css","hash":"15e0c13f8451bfe36fa5e464b86767bd98cab70b","modified":1764161572048},{"_id":"themes/anzhiyu/source/css/_extra/fix/link_page.css","hash":"69e5ed458c0dc10d93ebb7e4943196be1167ed5a","modified":1764161572048},{"_id":"themes/anzhiyu/source/css/_extra/fix/site-card.css","hash":"0a662f62c69d36ac583528c02346d848aa1d026a","modified":1764161572049},{"_id":"themes/anzhiyu/source/css/_extra/fix/overflow.css","hash":"71e3bd9905684e6e2ba6e18282e982d96dc4d61d","modified":1764161572049},{"_id":"themes/anzhiyu/source/css/_extra/fix/radius.css","hash":"6ef242f7a79427da9651a26c8a07e4e56ac56a42","modified":1764161572049},{"_id":"themes/anzhiyu/source/css/_extra/footer/footer.css","hash":"d94ed305398eb831b9e7160ce54510b0d25fcf67","modified":1764161572050},{"_id":"themes/anzhiyu/source/css/_extra/friends/friends.css","hash":"a2e50f529aa1fd60732d9a892166bb1d3ae725d7","modified":1764161572050},{"_id":"themes/anzhiyu/source/css/_extra/greeting_box/greeting_box.css","hash":"208ba729979dffdaa2f82639027a09b8c64fc5c2","modified":1764161572051},{"_id":"themes/anzhiyu/source/css/_extra/home_top/categorygroup.css","hash":"bc5b8a6cddca8c36a96ea5ecd1e56a5860bbb09a","modified":1764161572051},{"_id":"themes/anzhiyu/source/css/_extra/home_top/home_top_post_group.css","hash":"04d9a3bd9cb247f4c391af0cd7cb47206974ceaf","modified":1764161572052},{"_id":"themes/anzhiyu/source/css/_extra/home_top/swiperstyle.css","hash":"ea249de8cebc68cda7e62705df2acd7c78d13f37","modified":1764161572052},{"_id":"themes/anzhiyu/source/css/_extra/home_top/home_top.css","hash":"4bf724bd2f1a0447532456c60701e79b906c8dd0","modified":1764161572051},{"_id":"themes/anzhiyu/source/css/_extra/local_search/local_search.css","hash":"d3bc30e147897fb3026284d4244c4cf195d4588a","modified":1764161572053},{"_id":"themes/anzhiyu/source/css/_extra/reset/reset.css","hash":"0617cd338ebe4be2820d03d88376b30e0f378c1c","modified":1764161572053},{"_id":"themes/anzhiyu/source/css/_extra/reward/about-reward.css","hash":"f95871737b0e883ab70b30948b2cd4339bf36756","modified":1764161572053},{"_id":"themes/anzhiyu/source/css/_extra/home_top/top_group_banner.css","hash":"909b63f4b66c1c324ea302e93b3cb7c038306d0b","modified":1764161572052},{"_id":"themes/anzhiyu/source/css/_extra/room/room.css","hash":"82eb83dc296c045b0388cd9417ff1bc822e46f41","modified":1764161572055},{"_id":"themes/anzhiyu/source/css/_extra/skills/skills.css","hash":"6dcf742c38dcdf988e3d6f545fbfa0227d3155ea","modified":1764161572056},{"_id":"themes/anzhiyu/source/css/_extra/single_card/single_card.css","hash":"1559219f059389933e435dd081af5e6e17ef4b75","modified":1764161572056},{"_id":"themes/anzhiyu/source/css/_extra/tag/link.css","hash":"dbc87df28d7dfa366ab3c91ac61967ac48d7877c","modified":1764161572057},{"_id":"themes/anzhiyu/source/css/_extra/runtime/runtime.css","hash":"7fd033212b0dcdb06ca7f7a83343ea1b6044d59c","modified":1764161572055},{"_id":"themes/anzhiyu/source/css/_extra/tag/site.css","hash":"631a068d827a84a46fa03282b4ca38936c4bc4f3","modified":1764161572057},{"_id":"themes/anzhiyu/source/css/_highlight/highlight/diff.styl","hash":"cf1fae641c927621a4df1be5ca4a853b9b526e23","modified":1764161572060},{"_id":"themes/anzhiyu/source/css/_highlight/highlight/index.styl","hash":"75b01603cacde3b58cc2719dce1f72458ecf3842","modified":1764161572060},{"_id":"themes/anzhiyu/source/css/_highlight/prismjs/index.styl","hash":"7751de787861a9b45cf3879fb18601abc8935bde","modified":1764161572061},{"_id":"themes/anzhiyu/source/css/_highlight/prismjs/line-number.styl","hash":"8970cc1916c982b64a1478792b2822d1d31e276d","modified":1764161572061},{"_id":"themes/anzhiyu/source/css/_highlight/prismjs/diff.styl","hash":"5972c61f5125068cbe0af279a0c93a54847fdc3b","modified":1764161572060},{"_id":"themes/anzhiyu/source/img/404.jpg","hash":"030b9c7c9d654b3d67c1249a6e5900bf40c79373","modified":1764161572085},{"_id":"themes/anzhiyu/source/img/friend_404.gif","hash":"4c0a482bce3710942aff900d62c48333827e5a53","modified":1764161572090},{"_id":"themes/anzhiyu/source/img/loading.gif","hash":"b9e8d78b86bc48d565e26c8c1ea275c2c758fb0d","modified":1764161572093}],"Category":[{"name":"杂谈","_id":"cuidHqSnrXVN1uv0E5aTAgzI7"}],"Data":[{"_id":"essay","data":[{"title":"闲言碎语","subTitle":"记录生活点滴","top_background":"","limit":10,"buttonLink":"/about/","buttonText":"关于本人","tips":"这里记录了一些碎碎念...","essay_list":[{"content":"测试测试，新建站测试...over","date":"2025-05-03T12:00:00.000Z","from":"Hexo"}]}]}],"Page":[{"_content":"#article-container .tag-Link {\n    background: var(--anzhiyu-secondbg);\n    border-radius: 12px !important;\n    display: flex;\n    border: var(--style-border);\n    flex-direction: column;\n    padding: 1rem 1.5rem !important;\n    border-width: 1px !important;\n    margin: 1.5rem 0;\n    text-decoration: none !important;\n    transition: all 0.3s ease;\n}\n\n#article-container .tag-Link:hover {\n    border: var(--style-border-hover);\n    background: var(--anzhiyu-card-bg);\n    transform: translateY(-2px);\n    box-shadow: var(--anzhiyu-shadow-main);\n}\n\n#article-container .tag-Link .tag-link-tips {\n    border-bottom: var(--style-border);\n    padding-bottom: 8px;\n    font-size: 14px;\n    color: var(--anzhiyu-gray);\n    font-weight: normal;\n}\n\n#article-container .tag-Link:hover .tag-link-tips {\n    color: var(--anzhiyu-main);\n}\n\n#article-container .tag-Link .tag-link-bottom {\n    display: flex;\n    margin-top: 1rem;\n    align-items: center;\n    justify-content: space-between;\n}\n\n#article-container .tag-Link .tag-link-bottom .tag-link-left {\n    width: 80px;\n    min-width: 80px;\n    height: 80px;\n    background-size: cover;\n    border-radius: var(--anzhiyu-border-radius);\n    background-color: var(--anzhiyu-card-bg);\n    display: flex;\n    align-items: center;\n    justify-content: center;\n}\n\n#article-container .tag-Link .tag-link-bottom .tag-link-left i {\n    margin: 0;\n    padding: 0;\n    margin: auto;\n    font-size: 32px;\n    color: var(--anzhiyu-fontcolor);\n}\n\n#article-container .tag-Link .tag-link-bottom .tag-link-right {\n    margin-left: 1.5rem;\n    flex: 1;\n    display: flex;\n    flex-direction: column;\n    justify-content: center;\n}\n\n#article-container .tag-Link .tag-link-bottom .tag-link-right .tag-link-title {\n    font-size: 1.2rem;\n    font-weight: bold;\n    line-height: 1.4;\n    color: var(--anzhiyu-fontcolor);\n}\n\n#article-container .tag-Link .tag-link-bottom .tag-link-right .tag-link-sitename {\n    font-size: 0.9rem;\n    color: var(--anzhiyu-gray);\n    font-weight: normal;\n    margin-top: 8px;\n}\n\n#article-container .tag-Link:hover .tag-link-bottom .tag-link-right .tag-link-sitename {\n    color: var(--anzhiyu-main);\n}\n\n#article-container .tag-Link .tag-link-bottom i {\n    margin-left: 1rem;\n    font-size: 1.2rem;\n    color: var(--anzhiyu-gray);\n}\n\n/* Homepage header gradient overlay */\nheader#page-header{\n    position: relative;\n    overflow: visible;\n}\n\nheader#page-header::after{\n    content: \"\";\n    position: absolute;\n    left: 0;\n    right: 0;\n    bottom: 0;\n    height: 220px;\n    pointer-events: none;\n    background: linear-gradient(to bottom, rgba(0,0,0,0) 0%, rgba(0,0,0,0.35) 100%);\n    opacity: 0;\n    transition: opacity 300ms ease;\n    z-index: 2;\n}\n\n/* Make sure banner content sits above the overlay */\n.banners-title, #site-info, #site-subtitle{\n    position: relative;\n    z-index: 3;\n}\n\n/* Lighter gradient for light theme (override via data-theme if available) */\nhtml[data-theme=\"light\"] header#page-header::after{\n    background: linear-gradient(to bottom, rgba(255,255,255,0) 0%, rgba(255,255,255,0.85) 100%);\n}","source":"css/link_custom.css","raw":"#article-container .tag-Link {\n    background: var(--anzhiyu-secondbg);\n    border-radius: 12px !important;\n    display: flex;\n    border: var(--style-border);\n    flex-direction: column;\n    padding: 1rem 1.5rem !important;\n    border-width: 1px !important;\n    margin: 1.5rem 0;\n    text-decoration: none !important;\n    transition: all 0.3s ease;\n}\n\n#article-container .tag-Link:hover {\n    border: var(--style-border-hover);\n    background: var(--anzhiyu-card-bg);\n    transform: translateY(-2px);\n    box-shadow: var(--anzhiyu-shadow-main);\n}\n\n#article-container .tag-Link .tag-link-tips {\n    border-bottom: var(--style-border);\n    padding-bottom: 8px;\n    font-size: 14px;\n    color: var(--anzhiyu-gray);\n    font-weight: normal;\n}\n\n#article-container .tag-Link:hover .tag-link-tips {\n    color: var(--anzhiyu-main);\n}\n\n#article-container .tag-Link .tag-link-bottom {\n    display: flex;\n    margin-top: 1rem;\n    align-items: center;\n    justify-content: space-between;\n}\n\n#article-container .tag-Link .tag-link-bottom .tag-link-left {\n    width: 80px;\n    min-width: 80px;\n    height: 80px;\n    background-size: cover;\n    border-radius: var(--anzhiyu-border-radius);\n    background-color: var(--anzhiyu-card-bg);\n    display: flex;\n    align-items: center;\n    justify-content: center;\n}\n\n#article-container .tag-Link .tag-link-bottom .tag-link-left i {\n    margin: 0;\n    padding: 0;\n    margin: auto;\n    font-size: 32px;\n    color: var(--anzhiyu-fontcolor);\n}\n\n#article-container .tag-Link .tag-link-bottom .tag-link-right {\n    margin-left: 1.5rem;\n    flex: 1;\n    display: flex;\n    flex-direction: column;\n    justify-content: center;\n}\n\n#article-container .tag-Link .tag-link-bottom .tag-link-right .tag-link-title {\n    font-size: 1.2rem;\n    font-weight: bold;\n    line-height: 1.4;\n    color: var(--anzhiyu-fontcolor);\n}\n\n#article-container .tag-Link .tag-link-bottom .tag-link-right .tag-link-sitename {\n    font-size: 0.9rem;\n    color: var(--anzhiyu-gray);\n    font-weight: normal;\n    margin-top: 8px;\n}\n\n#article-container .tag-Link:hover .tag-link-bottom .tag-link-right .tag-link-sitename {\n    color: var(--anzhiyu-main);\n}\n\n#article-container .tag-Link .tag-link-bottom i {\n    margin-left: 1rem;\n    font-size: 1.2rem;\n    color: var(--anzhiyu-gray);\n}\n\n/* Homepage header gradient overlay */\nheader#page-header{\n    position: relative;\n    overflow: visible;\n}\n\nheader#page-header::after{\n    content: \"\";\n    position: absolute;\n    left: 0;\n    right: 0;\n    bottom: 0;\n    height: 220px;\n    pointer-events: none;\n    background: linear-gradient(to bottom, rgba(0,0,0,0) 0%, rgba(0,0,0,0.35) 100%);\n    opacity: 0;\n    transition: opacity 300ms ease;\n    z-index: 2;\n}\n\n/* Make sure banner content sits above the overlay */\n.banners-title, #site-info, #site-subtitle{\n    position: relative;\n    z-index: 3;\n}\n\n/* Lighter gradient for light theme (override via data-theme if available) */\nhtml[data-theme=\"light\"] header#page-header::after{\n    background: linear-gradient(to bottom, rgba(255,255,255,0) 0%, rgba(255,255,255,0.85) 100%);\n}","date":"2025-11-25T15:56:05.414Z","updated":"2025-11-25T15:56:05.414Z","path":"css/link_custom.css","layout":"false","title":"","comments":1,"_id":"cuidPJ786hu-PZJoViM2qUTY1","content":"#article-container .tag-Link {\n    background: var(--anzhiyu-secondbg);\n    border-radius: 12px !important;\n    display: flex;\n    border: var(--style-border);\n    flex-direction: column;\n    padding: 1rem 1.5rem !important;\n    border-width: 1px !important;\n    margin: 1.5rem 0;\n    text-decoration: none !important;\n    transition: all 0.3s ease;\n}\n\n#article-container .tag-Link:hover {\n    border: var(--style-border-hover);\n    background: var(--anzhiyu-card-bg);\n    transform: translateY(-2px);\n    box-shadow: var(--anzhiyu-shadow-main);\n}\n\n#article-container .tag-Link .tag-link-tips {\n    border-bottom: var(--style-border);\n    padding-bottom: 8px;\n    font-size: 14px;\n    color: var(--anzhiyu-gray);\n    font-weight: normal;\n}\n\n#article-container .tag-Link:hover .tag-link-tips {\n    color: var(--anzhiyu-main);\n}\n\n#article-container .tag-Link .tag-link-bottom {\n    display: flex;\n    margin-top: 1rem;\n    align-items: center;\n    justify-content: space-between;\n}\n\n#article-container .tag-Link .tag-link-bottom .tag-link-left {\n    width: 80px;\n    min-width: 80px;\n    height: 80px;\n    background-size: cover;\n    border-radius: var(--anzhiyu-border-radius);\n    background-color: var(--anzhiyu-card-bg);\n    display: flex;\n    align-items: center;\n    justify-content: center;\n}\n\n#article-container .tag-Link .tag-link-bottom .tag-link-left i {\n    margin: 0;\n    padding: 0;\n    margin: auto;\n    font-size: 32px;\n    color: var(--anzhiyu-fontcolor);\n}\n\n#article-container .tag-Link .tag-link-bottom .tag-link-right {\n    margin-left: 1.5rem;\n    flex: 1;\n    display: flex;\n    flex-direction: column;\n    justify-content: center;\n}\n\n#article-container .tag-Link .tag-link-bottom .tag-link-right .tag-link-title {\n    font-size: 1.2rem;\n    font-weight: bold;\n    line-height: 1.4;\n    color: var(--anzhiyu-fontcolor);\n}\n\n#article-container .tag-Link .tag-link-bottom .tag-link-right .tag-link-sitename {\n    font-size: 0.9rem;\n    color: var(--anzhiyu-gray);\n    font-weight: normal;\n    margin-top: 8px;\n}\n\n#article-container .tag-Link:hover .tag-link-bottom .tag-link-right .tag-link-sitename {\n    color: var(--anzhiyu-main);\n}\n\n#article-container .tag-Link .tag-link-bottom i {\n    margin-left: 1rem;\n    font-size: 1.2rem;\n    color: var(--anzhiyu-gray);\n}\n\n/* Homepage header gradient overlay */\nheader#page-header{\n    position: relative;\n    overflow: visible;\n}\n\nheader#page-header::after{\n    content: \"\";\n    position: absolute;\n    left: 0;\n    right: 0;\n    bottom: 0;\n    height: 220px;\n    pointer-events: none;\n    background: linear-gradient(to bottom, rgba(0,0,0,0) 0%, rgba(0,0,0,0.35) 100%);\n    opacity: 0;\n    transition: opacity 300ms ease;\n    z-index: 2;\n}\n\n/* Make sure banner content sits above the overlay */\n.banners-title, #site-info, #site-subtitle{\n    position: relative;\n    z-index: 3;\n}\n\n/* Lighter gradient for light theme (override via data-theme if available) */\nhtml[data-theme=\"light\"] header#page-header::after{\n    background: linear-gradient(to bottom, rgba(255,255,255,0) 0%, rgba(255,255,255,0.85) 100%);\n}"},{"title":"关于本人","date":"2025-05-02T16:00:00.000Z","comments":1,"_content":"\n\n### 我的喜好\n\n- 🤖 模型\n- 🎨 ACG\n- 🎮 游戏\n- 📚 阅读\n\n---\n\n> Bye~\n","source":"about/index.md","raw":"---\ntitle: 关于本人\ndate: 2025-05-03 00:00:00\ncomments: true\n---\n\n\n### 我的喜好\n\n- 🤖 模型\n- 🎨 ACG\n- 🎮 游戏\n- 📚 阅读\n\n---\n\n> Bye~\n","updated":"2025-11-24T16:11:19.797Z","path":"about/index.html","layout":"page","_id":"cuidunP17lfzJig5Xp3CgEwuY","content":"<h3 id=\"我的喜好\"><a href=\"#我的喜好\" class=\"headerlink\" title=\"我的喜好\"></a>我的喜好</h3><ul>\n<li>🤖 模型</li>\n<li>🎨 ACG</li>\n<li>🎮 游戏</li>\n<li>📚 阅读</li>\n</ul>\n<hr>\n<blockquote>\n<p>Bye~</p>\n</blockquote>\n","cover":false,"excerpt":"","more":"<h3 id=\"我的喜好\"><a href=\"#我的喜好\" class=\"headerlink\" title=\"我的喜好\"></a>我的喜好</h3><ul>\n<li>🤖 模型</li>\n<li>🎨 ACG</li>\n<li>🎮 游戏</li>\n<li>📚 阅读</li>\n</ul>\n<hr>\n<blockquote>\n<p>Bye~</p>\n</blockquote>\n"},{"title":"闲言碎语","date":"2025-05-02T16:00:00.000Z","type":"essay","top_img":"","comments":1,"_content":"","source":"essay/index.md","raw":"---\ntitle: 闲言碎语\ndate: 2025-05-03 00:00:00\ntype: \"essay\"\ntop_img: \"\"\ncomments: true\n---\n","updated":"2025-11-25T13:57:36.513Z","path":"essay/index.html","layout":"page","_id":"cuid1rDG8Ju-xiSXpYhBalwWs","content":"","cover":false,"excerpt":"","more":""},{"_content":"/* header-gradient.js\n   Add a gradient overlay to the homepage header and adjust opacity on scroll.\n*/\n(function(){\n  function setOpacity(op){\n    // set CSS variable on root so CSS ::after can use it if needed\n    document.documentElement.style.setProperty('--header-gradient-opacity', op);\n    const header = document.querySelector('header#page-header');\n    if(header){\n      const after = header; // we control opacity via pseudo-element by toggling inline opacity on header\n      // set inline style to control pseudo-element via CSS variable fallback\n      header.style.setProperty('--hg-opacity', op);\n      // we also directly set opacity on pseudo-element via a class hack: append style tag if needed\n      // simpler: toggle a data attribute used by CSS (we'll set opacity by changing header.dataset)\n      header.setAttribute('data-hg-opacity', op);\n      // Additionally, update a real inline style to help older browsers: set a variable used in CSS\n      document.documentElement.style.setProperty('--header-gradient-opacity', op);\n    }\n  }\n\n  function onScroll(){\n    const header = document.querySelector('header#page-header');\n    if(!header) return;\n    const h = header.offsetHeight || header.getBoundingClientRect().height || 600;\n    const y = Math.max(0, window.pageYOffset || document.documentElement.scrollTop || 0);\n    // compute opacity: 0 at top, 1 at half header height\n    const op = Math.min(1, (y) / (h * 0.5));\n    // Smooth small values\n    setOpacity(Number(op.toFixed(2)));\n    // apply to pseudo-element by toggling style via a small dynamic style tag\n    const styleId = 'header-gradient-dyn-style';\n    let dyn = document.getElementById(styleId);\n    if(!dyn){\n      dyn = document.createElement('style');\n      dyn.id = styleId;\n      document.head.appendChild(dyn);\n    }\n    // Use header id selector to set opacity for ::after\n    dyn.textContent = `header#page-header::after{opacity: ${op} !important}`;\n  }\n\n  document.addEventListener('scroll', onScroll, {passive:true});\n  document.addEventListener('DOMContentLoaded', onScroll);\n  // also run after PJAX content swaps\n  document.addEventListener('pjax:complete', onScroll);\n  document.addEventListener('pjax:end', onScroll);\n  setTimeout(onScroll, 300);\n})();\n","source":"js/header-gradient.js","raw":"/* header-gradient.js\n   Add a gradient overlay to the homepage header and adjust opacity on scroll.\n*/\n(function(){\n  function setOpacity(op){\n    // set CSS variable on root so CSS ::after can use it if needed\n    document.documentElement.style.setProperty('--header-gradient-opacity', op);\n    const header = document.querySelector('header#page-header');\n    if(header){\n      const after = header; // we control opacity via pseudo-element by toggling inline opacity on header\n      // set inline style to control pseudo-element via CSS variable fallback\n      header.style.setProperty('--hg-opacity', op);\n      // we also directly set opacity on pseudo-element via a class hack: append style tag if needed\n      // simpler: toggle a data attribute used by CSS (we'll set opacity by changing header.dataset)\n      header.setAttribute('data-hg-opacity', op);\n      // Additionally, update a real inline style to help older browsers: set a variable used in CSS\n      document.documentElement.style.setProperty('--header-gradient-opacity', op);\n    }\n  }\n\n  function onScroll(){\n    const header = document.querySelector('header#page-header');\n    if(!header) return;\n    const h = header.offsetHeight || header.getBoundingClientRect().height || 600;\n    const y = Math.max(0, window.pageYOffset || document.documentElement.scrollTop || 0);\n    // compute opacity: 0 at top, 1 at half header height\n    const op = Math.min(1, (y) / (h * 0.5));\n    // Smooth small values\n    setOpacity(Number(op.toFixed(2)));\n    // apply to pseudo-element by toggling style via a small dynamic style tag\n    const styleId = 'header-gradient-dyn-style';\n    let dyn = document.getElementById(styleId);\n    if(!dyn){\n      dyn = document.createElement('style');\n      dyn.id = styleId;\n      document.head.appendChild(dyn);\n    }\n    // Use header id selector to set opacity for ::after\n    dyn.textContent = `header#page-header::after{opacity: ${op} !important}`;\n  }\n\n  document.addEventListener('scroll', onScroll, {passive:true});\n  document.addEventListener('DOMContentLoaded', onScroll);\n  // also run after PJAX content swaps\n  document.addEventListener('pjax:complete', onScroll);\n  document.addEventListener('pjax:end', onScroll);\n  setTimeout(onScroll, 300);\n})();\n","date":"2025-11-25T15:56:05.414Z","updated":"2025-11-25T15:56:05.414Z","path":"js/header-gradient.js","layout":"false","title":"","comments":1,"_id":"cuidilgef3cDKUgtBDCcgiFk2","content":"/* header-gradient.js\n   Add a gradient overlay to the homepage header and adjust opacity on scroll.\n*/\n(function(){\n  function setOpacity(op){\n    // set CSS variable on root so CSS ::after can use it if needed\n    document.documentElement.style.setProperty('--header-gradient-opacity', op);\n    const header = document.querySelector('header#page-header');\n    if(header){\n      const after = header; // we control opacity via pseudo-element by toggling inline opacity on header\n      // set inline style to control pseudo-element via CSS variable fallback\n      header.style.setProperty('--hg-opacity', op);\n      // we also directly set opacity on pseudo-element via a class hack: append style tag if needed\n      // simpler: toggle a data attribute used by CSS (we'll set opacity by changing header.dataset)\n      header.setAttribute('data-hg-opacity', op);\n      // Additionally, update a real inline style to help older browsers: set a variable used in CSS\n      document.documentElement.style.setProperty('--header-gradient-opacity', op);\n    }\n  }\n\n  function onScroll(){\n    const header = document.querySelector('header#page-header');\n    if(!header) return;\n    const h = header.offsetHeight || header.getBoundingClientRect().height || 600;\n    const y = Math.max(0, window.pageYOffset || document.documentElement.scrollTop || 0);\n    // compute opacity: 0 at top, 1 at half header height\n    const op = Math.min(1, (y) / (h * 0.5));\n    // Smooth small values\n    setOpacity(Number(op.toFixed(2)));\n    // apply to pseudo-element by toggling style via a small dynamic style tag\n    const styleId = 'header-gradient-dyn-style';\n    let dyn = document.getElementById(styleId);\n    if(!dyn){\n      dyn = document.createElement('style');\n      dyn.id = styleId;\n      document.head.appendChild(dyn);\n    }\n    // Use header id selector to set opacity for ::after\n    dyn.textContent = `header#page-header::after{opacity: ${op} !important}`;\n  }\n\n  document.addEventListener('scroll', onScroll, {passive:true});\n  document.addEventListener('DOMContentLoaded', onScroll);\n  // also run after PJAX content swaps\n  document.addEventListener('pjax:complete', onScroll);\n  document.addEventListener('pjax:end', onScroll);\n  setTimeout(onScroll, 300);\n})();\n"},{"_content":"// 首页头图加载优化\n/**\n * @description 实现medium的渐进加载背景的效果\n */\nclass ProgressiveLoad {\n    constructor(smallSrc, largeSrc) {\n      this.smallSrc = smallSrc;\n      this.largeSrc = largeSrc;\n      this.initTpl();\n    }\n  \n    /**\n     * @description 生成ui模板\n     */\n    initTpl() {\n      this.container = document.createElement('div');\n      this.smallStage = document.createElement('div');\n      this.largeStage = document.createElement('div');\n      this.smallImg = new Image();\n      this.largeImg = new Image();\n      this.container.className = 'pl-container';\n      this.smallStage.className = 'pl-img pl-blur';\n      this.largeStage.className = 'pl-img';\n      this.container.appendChild(this.smallStage);\n      this.container.appendChild(this.largeStage);\n      this.smallImg.onload = this._onSmallLoaded.bind(this);\n      this.largeImg.onload = this._onLargeLoaded.bind(this);\n    }\n  \n    /**\n     * @description 加载背景\n     */\n    progressiveLoad() {\n      this.smallImg.src = this.smallSrc;\n      this.largeImg.src = this.largeSrc;\n    }\n  \n    /**\n     * @description 大图加载完成\n     */\n    _onLargeLoaded() {\n      this.largeStage.classList.add('pl-visible');\n      this.largeStage.style.backgroundImage = `url('${this.largeSrc}')`;\n    }\n  \n    /**\n     * @description 小图加载完成\n     */\n    _onSmallLoaded() {\n      this.smallStage.classList.add('pl-visible');\n      this.smallStage.style.backgroundImage = `url('${this.smallSrc}')`;\n    }\n  }\n  \n  const executeLoad = (config, target) => {\n    console.log('执行渐进背景替换');\n    const isMobile = window.matchMedia('(max-width: 767px)').matches;\n    const loader = new ProgressiveLoad(\n      isMobile ? config.mobileSmallSrc : config.smallSrc,\n      isMobile ? config.mobileLargeSrc : config.largeSrc\n    );\n    // 和背景图颜色保持一致，防止高斯模糊后差异较大\n    if (target.children[0]) {\n      target.insertBefore(loader.container, target.children[0]);\n    }\n    loader.progressiveLoad();\n  };\n  \n  const config = {\n    smallSrc: '/img/xiaotu.jpg', // 小图链接 尽可能配置小于100k的图片\n    largeSrc: '/img/tu.jpg', // 大图链接 最终显示的图片\n    mobileSmallSrc: '/img/sjxt.jpg', // 手机端小图链接 尽可能配置小于100k的图片\n    mobileLargeSrc: '/img/sjdt.jpg', // 手机端大图链接 最终显示的图片\n    enableRoutes: ['/'],\n    };\n\n  function initProgressiveLoad(config) {\n    const target = document.getElementById('page-header');\n    if (target && target.classList.contains('full_page')) {\n      executeLoad(config, target);\n    }\n  }\n  \n  function onPJAXComplete(config) {\n    const target = document.getElementById('page-header');\n    if (target && target.classList.contains('full_page')) {\n      initProgressiveLoad(config);\n    }\n  }\n\n  document.addEventListener(\"DOMContentLoaded\", function() {\n    initProgressiveLoad(config);\n  });\n  \n  document.addEventListener(\"pjax:complete\", function() {\n    onPJAXComplete(config);\n  });\n  ","source":"js/imgloaded.js","raw":"// 首页头图加载优化\n/**\n * @description 实现medium的渐进加载背景的效果\n */\nclass ProgressiveLoad {\n    constructor(smallSrc, largeSrc) {\n      this.smallSrc = smallSrc;\n      this.largeSrc = largeSrc;\n      this.initTpl();\n    }\n  \n    /**\n     * @description 生成ui模板\n     */\n    initTpl() {\n      this.container = document.createElement('div');\n      this.smallStage = document.createElement('div');\n      this.largeStage = document.createElement('div');\n      this.smallImg = new Image();\n      this.largeImg = new Image();\n      this.container.className = 'pl-container';\n      this.smallStage.className = 'pl-img pl-blur';\n      this.largeStage.className = 'pl-img';\n      this.container.appendChild(this.smallStage);\n      this.container.appendChild(this.largeStage);\n      this.smallImg.onload = this._onSmallLoaded.bind(this);\n      this.largeImg.onload = this._onLargeLoaded.bind(this);\n    }\n  \n    /**\n     * @description 加载背景\n     */\n    progressiveLoad() {\n      this.smallImg.src = this.smallSrc;\n      this.largeImg.src = this.largeSrc;\n    }\n  \n    /**\n     * @description 大图加载完成\n     */\n    _onLargeLoaded() {\n      this.largeStage.classList.add('pl-visible');\n      this.largeStage.style.backgroundImage = `url('${this.largeSrc}')`;\n    }\n  \n    /**\n     * @description 小图加载完成\n     */\n    _onSmallLoaded() {\n      this.smallStage.classList.add('pl-visible');\n      this.smallStage.style.backgroundImage = `url('${this.smallSrc}')`;\n    }\n  }\n  \n  const executeLoad = (config, target) => {\n    console.log('执行渐进背景替换');\n    const isMobile = window.matchMedia('(max-width: 767px)').matches;\n    const loader = new ProgressiveLoad(\n      isMobile ? config.mobileSmallSrc : config.smallSrc,\n      isMobile ? config.mobileLargeSrc : config.largeSrc\n    );\n    // 和背景图颜色保持一致，防止高斯模糊后差异较大\n    if (target.children[0]) {\n      target.insertBefore(loader.container, target.children[0]);\n    }\n    loader.progressiveLoad();\n  };\n  \n  const config = {\n    smallSrc: '/img/xiaotu.jpg', // 小图链接 尽可能配置小于100k的图片\n    largeSrc: '/img/tu.jpg', // 大图链接 最终显示的图片\n    mobileSmallSrc: '/img/sjxt.jpg', // 手机端小图链接 尽可能配置小于100k的图片\n    mobileLargeSrc: '/img/sjdt.jpg', // 手机端大图链接 最终显示的图片\n    enableRoutes: ['/'],\n    };\n\n  function initProgressiveLoad(config) {\n    const target = document.getElementById('page-header');\n    if (target && target.classList.contains('full_page')) {\n      executeLoad(config, target);\n    }\n  }\n  \n  function onPJAXComplete(config) {\n    const target = document.getElementById('page-header');\n    if (target && target.classList.contains('full_page')) {\n      initProgressiveLoad(config);\n    }\n  }\n\n  document.addEventListener(\"DOMContentLoaded\", function() {\n    initProgressiveLoad(config);\n  });\n  \n  document.addEventListener(\"pjax:complete\", function() {\n    onPJAXComplete(config);\n  });\n  ","date":"2025-11-25T13:16:15.203Z","updated":"2025-11-25T13:16:15.203Z","path":"js/imgloaded.js","layout":"false","title":"","comments":1,"_id":"cuidh0KXvEBmOvxUccmJDlyp8","content":"// 首页头图加载优化\n/**\n * @description 实现medium的渐进加载背景的效果\n */\nclass ProgressiveLoad {\n    constructor(smallSrc, largeSrc) {\n      this.smallSrc = smallSrc;\n      this.largeSrc = largeSrc;\n      this.initTpl();\n    }\n  \n    /**\n     * @description 生成ui模板\n     */\n    initTpl() {\n      this.container = document.createElement('div');\n      this.smallStage = document.createElement('div');\n      this.largeStage = document.createElement('div');\n      this.smallImg = new Image();\n      this.largeImg = new Image();\n      this.container.className = 'pl-container';\n      this.smallStage.className = 'pl-img pl-blur';\n      this.largeStage.className = 'pl-img';\n      this.container.appendChild(this.smallStage);\n      this.container.appendChild(this.largeStage);\n      this.smallImg.onload = this._onSmallLoaded.bind(this);\n      this.largeImg.onload = this._onLargeLoaded.bind(this);\n    }\n  \n    /**\n     * @description 加载背景\n     */\n    progressiveLoad() {\n      this.smallImg.src = this.smallSrc;\n      this.largeImg.src = this.largeSrc;\n    }\n  \n    /**\n     * @description 大图加载完成\n     */\n    _onLargeLoaded() {\n      this.largeStage.classList.add('pl-visible');\n      this.largeStage.style.backgroundImage = `url('${this.largeSrc}')`;\n    }\n  \n    /**\n     * @description 小图加载完成\n     */\n    _onSmallLoaded() {\n      this.smallStage.classList.add('pl-visible');\n      this.smallStage.style.backgroundImage = `url('${this.smallSrc}')`;\n    }\n  }\n  \n  const executeLoad = (config, target) => {\n    console.log('执行渐进背景替换');\n    const isMobile = window.matchMedia('(max-width: 767px)').matches;\n    const loader = new ProgressiveLoad(\n      isMobile ? config.mobileSmallSrc : config.smallSrc,\n      isMobile ? config.mobileLargeSrc : config.largeSrc\n    );\n    // 和背景图颜色保持一致，防止高斯模糊后差异较大\n    if (target.children[0]) {\n      target.insertBefore(loader.container, target.children[0]);\n    }\n    loader.progressiveLoad();\n  };\n  \n  const config = {\n    smallSrc: '/img/xiaotu.jpg', // 小图链接 尽可能配置小于100k的图片\n    largeSrc: '/img/tu.jpg', // 大图链接 最终显示的图片\n    mobileSmallSrc: '/img/sjxt.jpg', // 手机端小图链接 尽可能配置小于100k的图片\n    mobileLargeSrc: '/img/sjdt.jpg', // 手机端大图链接 最终显示的图片\n    enableRoutes: ['/'],\n    };\n\n  function initProgressiveLoad(config) {\n    const target = document.getElementById('page-header');\n    if (target && target.classList.contains('full_page')) {\n      executeLoad(config, target);\n    }\n  }\n  \n  function onPJAXComplete(config) {\n    const target = document.getElementById('page-header');\n    if (target && target.classList.contains('full_page')) {\n      initProgressiveLoad(config);\n    }\n  }\n\n  document.addEventListener(\"DOMContentLoaded\", function() {\n    initProgressiveLoad(config);\n  });\n  \n  document.addEventListener(\"pjax:complete\", function() {\n    onPJAXComplete(config);\n  });\n  "},{"_content":"[\n    {\n        \"name\": \"\",\n        \"artist\": \"\",\n        \"url\": \"\",\n        \"cover\": \"\",\n        \"lrc\": \"\"\n    }\n]","source":"js/music.json","raw":"[\n    {\n        \"name\": \"\",\n        \"artist\": \"\",\n        \"url\": \"\",\n        \"cover\": \"\",\n        \"lrc\": \"\"\n    }\n]","date":"2025-11-25T13:15:35.469Z","updated":"2025-11-25T11:11:45.960Z","path":"js/music.json","layout":"false","title":"","comments":1,"_id":"cuid4BjuRiWd0ZjtJLVa9ueXv","content":"[{\"name\":\"\",\"artist\":\"\",\"url\":\"\",\"cover\":\"\",\"lrc\":\"\"}]"},{"_content":"/* home-typed-init.js\n   Ensure Typed.js is instantiated for the homepage subtitle (#subtitle).\n   Works after DOMContentLoaded and on PJAX page swaps.\n*/\n(function(){\n  function initTypedOnce(){\n    const el = document.querySelector('#subtitle');\n    (function(){\n      // Custom typing loop: fetch a new sentence each cycle (hitokoto) and type+erase it.\n      const API = 'https://v1.hitokoto.cn/?encode=json';\n\n      function sleep(ms){ return new Promise(r=>setTimeout(r, ms)); }\n\n      async function fetchSentence(){\n        try{\n          const res = await fetch(API, {cache: 'no-store'});\n          if(!res.ok) throw new Error('fetch failed');\n          const j = await res.json();\n          return (j && (j.hitokoto || j.data || j.content)) || '';\n        }catch(e){\n          console.warn('hitokoto fetch failed:', e);\n          return '';\n        }\n      }\n\n      function ensureCursorStyle(){\n        if(document.getElementById('home-typed-cursor-style')) return;\n        const style = document.createElement('style');\n        style.id = 'home-typed-cursor-style';\n        style.textContent = `#subtitle .typed-cursor{display:inline-block;margin-left:4px;opacity:1;animation:home-typed-blink .8s steps(1) infinite}@keyframes home-typed-blink{50%{opacity:0}}`;\n        document.head.appendChild(style);\n      }\n\n      function prepareElement(el){\n        el.dataset.orig = el.textContent.trim();\n        el.innerHTML = '<span class=\"typed-text\"></span><span class=\"typed-cursor\">|</span>';\n        return {\n          textEl: el.querySelector('.typed-text'),\n          cursorEl: el.querySelector('.typed-cursor')\n        };\n      }\n\n      async function typeString(textEl, str, speed){\n        textEl.textContent = '';\n        for(let i=0;i<str.length;i++){\n          textEl.textContent += str.charAt(i);\n          await sleep(speed);\n        }\n      }\n\n      async function eraseString(textEl, speed){\n        while(textEl.textContent.length){\n          textEl.textContent = textEl.textContent.slice(0, -1);\n          await sleep(speed);\n        }\n      }\n\n      async function runLoop(el){\n        if(!el) return;\n        if(el.__typing_running) return;\n        el.__typing_running = true;\n        ensureCursorStyle();\n        const {textEl} = prepareElement(el);\n\n        const staticRaw = (el.getAttribute('data-typed') || el.dataset.orig || '').trim();\n        const staticStrings = staticRaw ? staticRaw.split(/\\r?\\n|\\|\\|/).map(s=>s.trim()).filter(Boolean) : [];\n\n        const typeSpeed = window.__anzhiyu_sub_typeSpeed || 120;\n        const backSpeed = window.__anzhiyu_sub_backSpeed || 50;\n        const backDelay = window.__anzhiyu_sub_backDelay || 800;\n\n        while(!el.__typing_stop){\n          const sentence = await fetchSentence();\n          const list = [];\n          if(sentence) list.push(sentence);\n          if(staticStrings.length) list.push(...staticStrings);\n          if(list.length === 0){\n            // nothing to type; wait and retry\n            await sleep(2000);\n            continue;\n          }\n\n          for(const s of list){\n            if(el.__typing_stop) break;\n            await typeString(textEl, s, typeSpeed);\n            await sleep(backDelay);\n            await eraseString(textEl, backSpeed);\n            await sleep(300);\n          }\n          // small pause before fetching a new sentence\n          await sleep(600);\n        }\n        el.__typing_running = false;\n      }\n\n      function start(){\n        const el = document.querySelector('#subtitle');\n        if(!el) return;\n        el.__typing_stop = false;\n        runLoop(el).catch(e=>console.error(e));\n      }\n\n      function stop(){\n        const el = document.querySelector('#subtitle');\n        if(!el) return;\n        el.__typing_stop = true;\n      }\n\n      document.addEventListener('DOMContentLoaded', start);\n      document.addEventListener('pjax:complete', ()=>{ stop(); start(); });\n      document.addEventListener('pjax:end', ()=>{ stop(); start(); });\n      // fallback start\n      setTimeout(start, 600);\n    })();\n  setTimeout(initTypedOnce, 600);\n})();\n","source":"js/home-typed-init.js","raw":"/* home-typed-init.js\n   Ensure Typed.js is instantiated for the homepage subtitle (#subtitle).\n   Works after DOMContentLoaded and on PJAX page swaps.\n*/\n(function(){\n  function initTypedOnce(){\n    const el = document.querySelector('#subtitle');\n    (function(){\n      // Custom typing loop: fetch a new sentence each cycle (hitokoto) and type+erase it.\n      const API = 'https://v1.hitokoto.cn/?encode=json';\n\n      function sleep(ms){ return new Promise(r=>setTimeout(r, ms)); }\n\n      async function fetchSentence(){\n        try{\n          const res = await fetch(API, {cache: 'no-store'});\n          if(!res.ok) throw new Error('fetch failed');\n          const j = await res.json();\n          return (j && (j.hitokoto || j.data || j.content)) || '';\n        }catch(e){\n          console.warn('hitokoto fetch failed:', e);\n          return '';\n        }\n      }\n\n      function ensureCursorStyle(){\n        if(document.getElementById('home-typed-cursor-style')) return;\n        const style = document.createElement('style');\n        style.id = 'home-typed-cursor-style';\n        style.textContent = `#subtitle .typed-cursor{display:inline-block;margin-left:4px;opacity:1;animation:home-typed-blink .8s steps(1) infinite}@keyframes home-typed-blink{50%{opacity:0}}`;\n        document.head.appendChild(style);\n      }\n\n      function prepareElement(el){\n        el.dataset.orig = el.textContent.trim();\n        el.innerHTML = '<span class=\"typed-text\"></span><span class=\"typed-cursor\">|</span>';\n        return {\n          textEl: el.querySelector('.typed-text'),\n          cursorEl: el.querySelector('.typed-cursor')\n        };\n      }\n\n      async function typeString(textEl, str, speed){\n        textEl.textContent = '';\n        for(let i=0;i<str.length;i++){\n          textEl.textContent += str.charAt(i);\n          await sleep(speed);\n        }\n      }\n\n      async function eraseString(textEl, speed){\n        while(textEl.textContent.length){\n          textEl.textContent = textEl.textContent.slice(0, -1);\n          await sleep(speed);\n        }\n      }\n\n      async function runLoop(el){\n        if(!el) return;\n        if(el.__typing_running) return;\n        el.__typing_running = true;\n        ensureCursorStyle();\n        const {textEl} = prepareElement(el);\n\n        const staticRaw = (el.getAttribute('data-typed') || el.dataset.orig || '').trim();\n        const staticStrings = staticRaw ? staticRaw.split(/\\r?\\n|\\|\\|/).map(s=>s.trim()).filter(Boolean) : [];\n\n        const typeSpeed = window.__anzhiyu_sub_typeSpeed || 120;\n        const backSpeed = window.__anzhiyu_sub_backSpeed || 50;\n        const backDelay = window.__anzhiyu_sub_backDelay || 800;\n\n        while(!el.__typing_stop){\n          const sentence = await fetchSentence();\n          const list = [];\n          if(sentence) list.push(sentence);\n          if(staticStrings.length) list.push(...staticStrings);\n          if(list.length === 0){\n            // nothing to type; wait and retry\n            await sleep(2000);\n            continue;\n          }\n\n          for(const s of list){\n            if(el.__typing_stop) break;\n            await typeString(textEl, s, typeSpeed);\n            await sleep(backDelay);\n            await eraseString(textEl, backSpeed);\n            await sleep(300);\n          }\n          // small pause before fetching a new sentence\n          await sleep(600);\n        }\n        el.__typing_running = false;\n      }\n\n      function start(){\n        const el = document.querySelector('#subtitle');\n        if(!el) return;\n        el.__typing_stop = false;\n        runLoop(el).catch(e=>console.error(e));\n      }\n\n      function stop(){\n        const el = document.querySelector('#subtitle');\n        if(!el) return;\n        el.__typing_stop = true;\n      }\n\n      document.addEventListener('DOMContentLoaded', start);\n      document.addEventListener('pjax:complete', ()=>{ stop(); start(); });\n      document.addEventListener('pjax:end', ()=>{ stop(); start(); });\n      // fallback start\n      setTimeout(start, 600);\n    })();\n  setTimeout(initTypedOnce, 600);\n})();\n","date":"2025-11-25T14:59:37.924Z","updated":"2025-11-25T14:59:37.924Z","path":"js/home-typed-init.js","layout":"false","title":"","comments":1,"_id":"cuidQ6PGMwVV5snihLdZxDLoH","content":"/* home-typed-init.js\n   Ensure Typed.js is instantiated for the homepage subtitle (#subtitle).\n   Works after DOMContentLoaded and on PJAX page swaps.\n*/\n(function(){\n  function initTypedOnce(){\n    const el = document.querySelector('#subtitle');\n    (function(){\n      // Custom typing loop: fetch a new sentence each cycle (hitokoto) and type+erase it.\n      const API = 'https://v1.hitokoto.cn/?encode=json';\n\n      function sleep(ms){ return new Promise(r=>setTimeout(r, ms)); }\n\n      async function fetchSentence(){\n        try{\n          const res = await fetch(API, {cache: 'no-store'});\n          if(!res.ok) throw new Error('fetch failed');\n          const j = await res.json();\n          return (j && (j.hitokoto || j.data || j.content)) || '';\n        }catch(e){\n          console.warn('hitokoto fetch failed:', e);\n          return '';\n        }\n      }\n\n      function ensureCursorStyle(){\n        if(document.getElementById('home-typed-cursor-style')) return;\n        const style = document.createElement('style');\n        style.id = 'home-typed-cursor-style';\n        style.textContent = `#subtitle .typed-cursor{display:inline-block;margin-left:4px;opacity:1;animation:home-typed-blink .8s steps(1) infinite}@keyframes home-typed-blink{50%{opacity:0}}`;\n        document.head.appendChild(style);\n      }\n\n      function prepareElement(el){\n        el.dataset.orig = el.textContent.trim();\n        el.innerHTML = '<span class=\"typed-text\"></span><span class=\"typed-cursor\">|</span>';\n        return {\n          textEl: el.querySelector('.typed-text'),\n          cursorEl: el.querySelector('.typed-cursor')\n        };\n      }\n\n      async function typeString(textEl, str, speed){\n        textEl.textContent = '';\n        for(let i=0;i<str.length;i++){\n          textEl.textContent += str.charAt(i);\n          await sleep(speed);\n        }\n      }\n\n      async function eraseString(textEl, speed){\n        while(textEl.textContent.length){\n          textEl.textContent = textEl.textContent.slice(0, -1);\n          await sleep(speed);\n        }\n      }\n\n      async function runLoop(el){\n        if(!el) return;\n        if(el.__typing_running) return;\n        el.__typing_running = true;\n        ensureCursorStyle();\n        const {textEl} = prepareElement(el);\n\n        const staticRaw = (el.getAttribute('data-typed') || el.dataset.orig || '').trim();\n        const staticStrings = staticRaw ? staticRaw.split(/\\r?\\n|\\|\\|/).map(s=>s.trim()).filter(Boolean) : [];\n\n        const typeSpeed = window.__anzhiyu_sub_typeSpeed || 120;\n        const backSpeed = window.__anzhiyu_sub_backSpeed || 50;\n        const backDelay = window.__anzhiyu_sub_backDelay || 800;\n\n        while(!el.__typing_stop){\n          const sentence = await fetchSentence();\n          const list = [];\n          if(sentence) list.push(sentence);\n          if(staticStrings.length) list.push(...staticStrings);\n          if(list.length === 0){\n            // nothing to type; wait and retry\n            await sleep(2000);\n            continue;\n          }\n\n          for(const s of list){\n            if(el.__typing_stop) break;\n            await typeString(textEl, s, typeSpeed);\n            await sleep(backDelay);\n            await eraseString(textEl, backSpeed);\n            await sleep(300);\n          }\n          // small pause before fetching a new sentence\n          await sleep(600);\n        }\n        el.__typing_running = false;\n      }\n\n      function start(){\n        const el = document.querySelector('#subtitle');\n        if(!el) return;\n        el.__typing_stop = false;\n        runLoop(el).catch(e=>console.error(e));\n      }\n\n      function stop(){\n        const el = document.querySelector('#subtitle');\n        if(!el) return;\n        el.__typing_stop = true;\n      }\n\n      document.addEventListener('DOMContentLoaded', start);\n      document.addEventListener('pjax:complete', ()=>{ stop(); start(); });\n      document.addEventListener('pjax:end', ()=>{ stop(); start(); });\n      // fallback start\n      setTimeout(start, 600);\n    })();\n  setTimeout(initTypedOnce, 600);\n})();\n"},{"title":"音乐馆","date":"2021-04-24T13:41:30.000Z","type":"music","aplayer":true,"top_img":false,"comments":0,"aside":false,"_content":"","source":"music/index.md","raw":"---\ntitle: 音乐馆\ndate: 2021-04-24 21:41:30\ntype: music\naplayer: true\ntop_img: false\ncomments: false\naside: false\n---\n","updated":"2025-11-24T16:20:34.462Z","path":"music/index.html","layout":"page","_id":"cuidkObO0stuGRUsxj18dTPuy","content":"","cover":false,"excerpt":"","more":""}],"Post":[{"title":"Fuwari部署Twikoo过程分享","published":1,"description":"此文章记录Twikoo部署过程，仅供参考","image":"https://twikoo.js.org/assets/logo.KgWMX3A2.png","draft":true,"lang":"","top_img":false,"_content":"\nTwikoo — \"一个简洁、安全、免费的静态网站评论系统\"\n\n---\n\n本站原本使用Giscus的评论功能\n\n但考虑到必须要Github账户的局限性\n\n为了更方便评论，我决定放弃前者，毅然加入更权威的代表—‘Twikoo’\n\n本文参考官方教程，也可以按照官方的来，大差不差~\n\n## 搭建后端\n\n首先，你需要注册一个[MongoDB](https://account.mongodb.com/account/login)账号以获取一个免费的数据库\n\n{% link MongoDB Atlas | Twikoo 文档,一个简洁、安全、免费的静态网站评论系统,https://twikoo.js.org/mongodb-atlas,/img/twikoo-logo.png %}\n\n区域选择: Region优先选择离主机近的站点，一般默认的就是。如果使用云主机就按其地理位置为准。\n设置好后，你将会得到类似的代码：\n\n```\nmongodb+srv://<db_username>:<db_password>@cluster0.xxx.mongodb.net/?retryWrites......Cluster0\n```\n\n{% note danger %}\n请牢记在 Password Authentication 下设置数据库用户名和密码!!!\n{% endnote %}\n\n## 部署数据库\n\n使用你的Github账户来登录Vercel\n\n{% link Dashboard,Vercel Dashboard,https://vercel.com,/images/link-default.png %}\n\n再点击下面的链接来快速部署\n\n{% link New Project – Vercel,,https://vercel.com/new/clone?repository-url=https%3A%2F%2Fgithub.com%2Fimaegoo%2Ftwikoo%2Ftree%2Fmain%2Fsrc%2Fserver%2Fvercel-min&teamSlug=brizens-projects,https://assets.vercel.com/image/upload/front/import/og.png %}\n\n`Git Providers`选择`Github`，`Git Scope`选择自己的账户，`Private Repository Name`为你的库命名。\n\n若是一切顺利，你会看见这样的画面\n![](https://cdn.jsdelivr.net/gh/Cooper1896/MyPic/68ac9f5575e4b_1756143445.webp)\n\n> 这时你还不会有Domain位址\n\n---\n\n选择`Settings` - `Environment Variables`,填写以下变量：\n\n```\nKey:MONGODB_URI\nValue:mongodb+srv://<db_username>......<此处需要更改为你上面获取到的链接字符>\n```\n\n随后点save\n\n此时再选择`Deployments`,点击任意一个项目后面的三个点，再选择`Redeploy`，再选择下方的`Redeploy`\n\n这时回到`Overview`,会发现`Domain`处已分配了一个域名,复制下该域名。\n\n## 参数设置\n\n可以跟随其他大大的教程设置本地文件，伟大无需多言\n\n{% link 给你的 Fuwari 接入 Twikoo 评论 - 咸鱼小窝,Fuwari 博客接入 Twikoo 评论,<https://blog.qqquq.com/posts/fuwari-twikoo-comments/,https://blog.qqquq.com/favicon/favicon-light-32.png> %}\n\n其中，请将上面复制的域名复制到`envID`,并将<username>,<password>修改成你设置的账号和密码。\n\n```\nexport const commentConfig: CommentConfig = {\n  twikoo: {\n    envId: '这里替换为你的 envId',\n  },\n}\n```\n\n最后在终端输入`pnpm dev`即可本地预览，enjoy!\n","source":"_posts/Twikko.md","raw":"---\ntitle: Fuwari部署Twikoo过程分享\npublished: 2025-08-26\ndescription: '此文章记录Twikoo部署过程，仅供参考'\nimage: 'https://twikoo.js.org/assets/logo.KgWMX3A2.png'\ntags: [分享/博客]\ncategory: '杂谈'\ndraft: true\nlang: ''\ntop_img: false\n---\n\nTwikoo — \"一个简洁、安全、免费的静态网站评论系统\"\n\n---\n\n本站原本使用Giscus的评论功能\n\n但考虑到必须要Github账户的局限性\n\n为了更方便评论，我决定放弃前者，毅然加入更权威的代表—‘Twikoo’\n\n本文参考官方教程，也可以按照官方的来，大差不差~\n\n## 搭建后端\n\n首先，你需要注册一个[MongoDB](https://account.mongodb.com/account/login)账号以获取一个免费的数据库\n\n{% link MongoDB Atlas | Twikoo 文档,一个简洁、安全、免费的静态网站评论系统,https://twikoo.js.org/mongodb-atlas,/img/twikoo-logo.png %}\n\n区域选择: Region优先选择离主机近的站点，一般默认的就是。如果使用云主机就按其地理位置为准。\n设置好后，你将会得到类似的代码：\n\n```\nmongodb+srv://<db_username>:<db_password>@cluster0.xxx.mongodb.net/?retryWrites......Cluster0\n```\n\n{% note danger %}\n请牢记在 Password Authentication 下设置数据库用户名和密码!!!\n{% endnote %}\n\n## 部署数据库\n\n使用你的Github账户来登录Vercel\n\n{% link Dashboard,Vercel Dashboard,https://vercel.com,/images/link-default.png %}\n\n再点击下面的链接来快速部署\n\n{% link New Project – Vercel,,https://vercel.com/new/clone?repository-url=https%3A%2F%2Fgithub.com%2Fimaegoo%2Ftwikoo%2Ftree%2Fmain%2Fsrc%2Fserver%2Fvercel-min&teamSlug=brizens-projects,https://assets.vercel.com/image/upload/front/import/og.png %}\n\n`Git Providers`选择`Github`，`Git Scope`选择自己的账户，`Private Repository Name`为你的库命名。\n\n若是一切顺利，你会看见这样的画面\n![](https://cdn.jsdelivr.net/gh/Cooper1896/MyPic/68ac9f5575e4b_1756143445.webp)\n\n> 这时你还不会有Domain位址\n\n---\n\n选择`Settings` - `Environment Variables`,填写以下变量：\n\n```\nKey:MONGODB_URI\nValue:mongodb+srv://<db_username>......<此处需要更改为你上面获取到的链接字符>\n```\n\n随后点save\n\n此时再选择`Deployments`,点击任意一个项目后面的三个点，再选择`Redeploy`，再选择下方的`Redeploy`\n\n这时回到`Overview`,会发现`Domain`处已分配了一个域名,复制下该域名。\n\n## 参数设置\n\n可以跟随其他大大的教程设置本地文件，伟大无需多言\n\n{% link 给你的 Fuwari 接入 Twikoo 评论 - 咸鱼小窝,Fuwari 博客接入 Twikoo 评论,<https://blog.qqquq.com/posts/fuwari-twikoo-comments/,https://blog.qqquq.com/favicon/favicon-light-32.png> %}\n\n其中，请将上面复制的域名复制到`envID`,并将<username>,<password>修改成你设置的账号和密码。\n\n```\nexport const commentConfig: CommentConfig = {\n  twikoo: {\n    envId: '这里替换为你的 envId',\n  },\n}\n```\n\n最后在终端输入`pnpm dev`即可本地预览，enjoy!\n","slug":"Twikko","date":"2025-11-26T12:54:25.159Z","updated":"2025-11-26T13:50:21.587Z","comments":1,"layout":"post","photos":[],"_id":"cuidcxfp-1aqJKjmYT4mj67Aa","content":"<p>Twikoo — “一个简洁、安全、免费的静态网站评论系统”</p>\n<hr>\n<p>本站原本使用Giscus的评论功能</p>\n<p>但考虑到必须要Github账户的局限性</p>\n<p>为了更方便评论，我决定放弃前者，毅然加入更权威的代表—‘Twikoo’</p>\n<p>本文参考官方教程，也可以按照官方的来，大差不差~</p>\n<h2 id=\"搭建后端\"><a href=\"#搭建后端\" class=\"headerlink\" title=\"搭建后端\"></a>搭建后端</h2><p>首先，你需要注册一个<a href=\"https://account.mongodb.com/account/login\">MongoDB</a>账号以获取一个免费的数据库</p>\n<div calss='anzhiyu-tag-link'><a class=\"tag-Link\" target=\"_blank\" href=\"https://twikoo.js.org/mongodb-atlas\">\n    <div class=\"tag-link-tips\">引用站外地址</div>\n    <div class=\"tag-link-bottom\">\n        <div class=\"tag-link-left\" style=\"background-image: url(/img/twikoo-logo.png)\">\n          <i class=\"anzhiyufont anzhiyu-icon-link\" style=\"display: none\"></i>\n        </div>\n        <div class=\"tag-link-right\">\n            <div class=\"tag-link-title\">MongoDB Atlas | Twikoo 文档</div>\n            <div class=\"tag-link-sitename\">一个简洁、安全、免费的静态网站评论系统</div>\n        </div>\n        <i class=\"anzhiyufont anzhiyu-icon-angle-right\"></i>\n    </div>\n    </a></div>\n\n<p>区域选择: Region优先选择离主机近的站点，一般默认的就是。如果使用云主机就按其地理位置为准。<br>设置好后，你将会得到类似的代码：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">mongodb+srv://&lt;db_username&gt;:&lt;db_password&gt;@cluster0.xxx.mongodb.net/?retryWrites......Cluster0</span><br></pre></td></tr></table></figure>\n\n<div class=\"note danger flat\"><p>请牢记在 Password Authentication 下设置数据库用户名和密码!!!</p>\n</div>\n\n<h2 id=\"部署数据库\"><a href=\"#部署数据库\" class=\"headerlink\" title=\"部署数据库\"></a>部署数据库</h2><p>使用你的Github账户来登录Vercel</p>\n<div calss='anzhiyu-tag-link'><a class=\"tag-Link\" target=\"_blank\" href=\"https://vercel.com\">\n    <div class=\"tag-link-tips\">引用站外地址</div>\n    <div class=\"tag-link-bottom\">\n        <div class=\"tag-link-left\" style=\"background-image: url(/images/link-default.png)\">\n          <i class=\"anzhiyufont anzhiyu-icon-link\" style=\"display: none\"></i>\n        </div>\n        <div class=\"tag-link-right\">\n            <div class=\"tag-link-title\">Dashboard</div>\n            <div class=\"tag-link-sitename\">Vercel Dashboard</div>\n        </div>\n        <i class=\"anzhiyufont anzhiyu-icon-angle-right\"></i>\n    </div>\n    </a></div>\n\n<p>再点击下面的链接来快速部署</p>\n<p><div calss='anzhiyu-tag-link'><a class=\"tag-Link\" target=\"_blank\" href=\"/%3Ca%20href=https:/vercel.com/new/clone?repository-url=https:/github.com/imaegoo/twikoo/tree/main/src/server/vercel-min&teamSlug=brizens-projects\">\n    <div class=\"tag-link-tips\">引用站外地址</div>\n    <div class=\"tag-link-bottom\">\n        <div class=\"tag-link-left\" style=\"background-image: url(https://assets.vercel.com/image/upload/front/import/og.png>https://vercel.com/new/clone?repository-url=https%3A%2F%2Fgithub.com%2Fimaegoo%2Ftwikoo%2Ftree%2Fmain%2Fsrc%2Fserver%2Fvercel-min&amp;teamSlug=brizens-projects)\">\n          <i class=\"anzhiyufont anzhiyu-icon-link\" style=\"display: none\"></i>\n        </div>\n        <div class=\"tag-link-right\">\n            <div class=\"tag-link-title\">New Project – Vercel</div>\n            <div class=\"tag-link-sitename\"></div>\n        </div>\n        <i class=\"anzhiyufont anzhiyu-icon-angle-right\"></i>\n    </div>\n    </a></div></p>\n<p><code>Git Providers</code>选择<code>Github</code>，<code>Git Scope</code>选择自己的账户，<code>Private Repository Name</code>为你的库命名。</p>\n<p>若是一切顺利，你会看见这样的画面<br><img src= \"data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7\" onerror=\"this.onerror=null,this.src=&quot;/img/404.jpg&quot;\" data-lazy-src=\"https://cdn.jsdelivr.net/gh/Cooper1896/MyPic/68ac9f5575e4b_1756143445.webp\"></p>\n<blockquote>\n<p>这时你还不会有Domain位址</p>\n</blockquote>\n<hr>\n<p>选择<code>Settings</code> - <code>Environment Variables</code>,填写以下变量：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Key:MONGODB_URI</span><br><span class=\"line\">Value:mongodb+srv://&lt;db_username&gt;......&lt;此处需要更改为你上面获取到的链接字符&gt;</span><br></pre></td></tr></table></figure>\n\n<p>随后点save</p>\n<p>此时再选择<code>Deployments</code>,点击任意一个项目后面的三个点，再选择<code>Redeploy</code>，再选择下方的<code>Redeploy</code></p>\n<p>这时回到<code>Overview</code>,会发现<code>Domain</code>处已分配了一个域名,复制下该域名。</p>\n<h2 id=\"参数设置\"><a href=\"#参数设置\" class=\"headerlink\" title=\"参数设置\"></a>参数设置</h2><p>可以跟随其他大大的教程设置本地文件，伟大无需多言</p>\n<div calss='anzhiyu-tag-link'><a class=\"tag-Link\" target=\"_blank\" href=\"/%3Chttps:/blog.qqquq.com/posts/fuwari-twikoo-comments/\">\n    <div class=\"tag-link-tips\">引用站外地址</div>\n    <div class=\"tag-link-bottom\">\n        <div class=\"tag-link-left\" style=\"background-image: url(https://blog.qqquq.com/favicon/favicon-light-32.png>)\">\n          <i class=\"anzhiyufont anzhiyu-icon-link\" style=\"display: none\"></i>\n        </div>\n        <div class=\"tag-link-right\">\n            <div class=\"tag-link-title\">给你的 Fuwari 接入 Twikoo 评论 - 咸鱼小窝</div>\n            <div class=\"tag-link-sitename\">Fuwari 博客接入 Twikoo 评论</div>\n        </div>\n        <i class=\"anzhiyufont anzhiyu-icon-angle-right\"></i>\n    </div>\n    </a></div>\n\n<p>其中，请将上面复制的域名复制到<code>envID</code>,并将<username>,<password>修改成你设置的账号和密码。</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">export const commentConfig: CommentConfig = &#123;</span><br><span class=\"line\">  twikoo: &#123;</span><br><span class=\"line\">    envId: &#x27;这里替换为你的 envId&#x27;,</span><br><span class=\"line\">  &#125;,</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>最后在终端输入<code>pnpm dev</code>即可本地预览，enjoy!</p>\n","cover":false,"excerpt":"","more":"<p>Twikoo — “一个简洁、安全、免费的静态网站评论系统”</p>\n<hr>\n<p>本站原本使用Giscus的评论功能</p>\n<p>但考虑到必须要Github账户的局限性</p>\n<p>为了更方便评论，我决定放弃前者，毅然加入更权威的代表—‘Twikoo’</p>\n<p>本文参考官方教程，也可以按照官方的来，大差不差~</p>\n<h2 id=\"搭建后端\"><a href=\"#搭建后端\" class=\"headerlink\" title=\"搭建后端\"></a>搭建后端</h2><p>首先，你需要注册一个<a href=\"https://account.mongodb.com/account/login\">MongoDB</a>账号以获取一个免费的数据库</p>\n<div calss='anzhiyu-tag-link'><a class=\"tag-Link\" target=\"_blank\" href=\"https://twikoo.js.org/mongodb-atlas\">\n    <div class=\"tag-link-tips\">引用站外地址</div>\n    <div class=\"tag-link-bottom\">\n        <div class=\"tag-link-left\" style=\"background-image: url(/img/twikoo-logo.png)\">\n          <i class=\"anzhiyufont anzhiyu-icon-link\" style=\"display: none\"></i>\n        </div>\n        <div class=\"tag-link-right\">\n            <div class=\"tag-link-title\">MongoDB Atlas | Twikoo 文档</div>\n            <div class=\"tag-link-sitename\">一个简洁、安全、免费的静态网站评论系统</div>\n        </div>\n        <i class=\"anzhiyufont anzhiyu-icon-angle-right\"></i>\n    </div>\n    </a></div>\n\n<p>区域选择: Region优先选择离主机近的站点，一般默认的就是。如果使用云主机就按其地理位置为准。<br>设置好后，你将会得到类似的代码：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">mongodb+srv://&lt;db_username&gt;:&lt;db_password&gt;@cluster0.xxx.mongodb.net/?retryWrites......Cluster0</span><br></pre></td></tr></table></figure>\n\n<div class=\"note danger flat\"><p>请牢记在 Password Authentication 下设置数据库用户名和密码!!!</p>\n</div>\n\n<h2 id=\"部署数据库\"><a href=\"#部署数据库\" class=\"headerlink\" title=\"部署数据库\"></a>部署数据库</h2><p>使用你的Github账户来登录Vercel</p>\n<div calss='anzhiyu-tag-link'><a class=\"tag-Link\" target=\"_blank\" href=\"https://vercel.com\">\n    <div class=\"tag-link-tips\">引用站外地址</div>\n    <div class=\"tag-link-bottom\">\n        <div class=\"tag-link-left\" style=\"background-image: url(/images/link-default.png)\">\n          <i class=\"anzhiyufont anzhiyu-icon-link\" style=\"display: none\"></i>\n        </div>\n        <div class=\"tag-link-right\">\n            <div class=\"tag-link-title\">Dashboard</div>\n            <div class=\"tag-link-sitename\">Vercel Dashboard</div>\n        </div>\n        <i class=\"anzhiyufont anzhiyu-icon-angle-right\"></i>\n    </div>\n    </a></div>\n\n<p>再点击下面的链接来快速部署</p>\n<p><div calss='anzhiyu-tag-link'><a class=\"tag-Link\" target=\"_blank\" href=\"/%3Ca%20href=https:/vercel.com/new/clone?repository-url=https:/github.com/imaegoo/twikoo/tree/main/src/server/vercel-min&teamSlug=brizens-projects\">\n    <div class=\"tag-link-tips\">引用站外地址</div>\n    <div class=\"tag-link-bottom\">\n        <div class=\"tag-link-left\" style=\"background-image: url(https://assets.vercel.com/image/upload/front/import/og.png>https://vercel.com/new/clone?repository-url=https%3A%2F%2Fgithub.com%2Fimaegoo%2Ftwikoo%2Ftree%2Fmain%2Fsrc%2Fserver%2Fvercel-min&amp;teamSlug=brizens-projects)\">\n          <i class=\"anzhiyufont anzhiyu-icon-link\" style=\"display: none\"></i>\n        </div>\n        <div class=\"tag-link-right\">\n            <div class=\"tag-link-title\">New Project – Vercel</div>\n            <div class=\"tag-link-sitename\"></div>\n        </div>\n        <i class=\"anzhiyufont anzhiyu-icon-angle-right\"></i>\n    </div>\n    </a></div></p>\n<p><code>Git Providers</code>选择<code>Github</code>，<code>Git Scope</code>选择自己的账户，<code>Private Repository Name</code>为你的库命名。</p>\n<p>若是一切顺利，你会看见这样的画面<br><img src=\"https://cdn.jsdelivr.net/gh/Cooper1896/MyPic/68ac9f5575e4b_1756143445.webp\"></p>\n<blockquote>\n<p>这时你还不会有Domain位址</p>\n</blockquote>\n<hr>\n<p>选择<code>Settings</code> - <code>Environment Variables</code>,填写以下变量：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Key:MONGODB_URI</span><br><span class=\"line\">Value:mongodb+srv://&lt;db_username&gt;......&lt;此处需要更改为你上面获取到的链接字符&gt;</span><br></pre></td></tr></table></figure>\n\n<p>随后点save</p>\n<p>此时再选择<code>Deployments</code>,点击任意一个项目后面的三个点，再选择<code>Redeploy</code>，再选择下方的<code>Redeploy</code></p>\n<p>这时回到<code>Overview</code>,会发现<code>Domain</code>处已分配了一个域名,复制下该域名。</p>\n<h2 id=\"参数设置\"><a href=\"#参数设置\" class=\"headerlink\" title=\"参数设置\"></a>参数设置</h2><p>可以跟随其他大大的教程设置本地文件，伟大无需多言</p>\n<div calss='anzhiyu-tag-link'><a class=\"tag-Link\" target=\"_blank\" href=\"/%3Chttps:/blog.qqquq.com/posts/fuwari-twikoo-comments/\">\n    <div class=\"tag-link-tips\">引用站外地址</div>\n    <div class=\"tag-link-bottom\">\n        <div class=\"tag-link-left\" style=\"background-image: url(https://blog.qqquq.com/favicon/favicon-light-32.png>)\">\n          <i class=\"anzhiyufont anzhiyu-icon-link\" style=\"display: none\"></i>\n        </div>\n        <div class=\"tag-link-right\">\n            <div class=\"tag-link-title\">给你的 Fuwari 接入 Twikoo 评论 - 咸鱼小窝</div>\n            <div class=\"tag-link-sitename\">Fuwari 博客接入 Twikoo 评论</div>\n        </div>\n        <i class=\"anzhiyufont anzhiyu-icon-angle-right\"></i>\n    </div>\n    </a></div>\n\n<p>其中，请将上面复制的域名复制到<code>envID</code>,并将<username>,<password>修改成你设置的账号和密码。</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">export const commentConfig: CommentConfig = &#123;</span><br><span class=\"line\">  twikoo: &#123;</span><br><span class=\"line\">    envId: &#x27;这里替换为你的 envId&#x27;,</span><br><span class=\"line\">  &#125;,</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>最后在终端输入<code>pnpm dev</code>即可本地预览，enjoy!</p>\n"},{"title":"AI","date":"2025-10-23T16:00:00.000Z","description":"聊聊ai","image":"","type":"杂谈","top_img":false,"_content":"\n想了很久，终于有时间来讲讲AI了，些许错误，多多包容\n\n---\n\n### I. 人工智能 (Artificial Intelligence,AI)\n\n大家都听过的词语，依照维基百科的解释:  [人工智能（AI）](https://www.wikiwand.com/en/articles/Artificial_intelligence.com)是指计算系统执行通常与人类智能相关任务的能力，例如学习、推理、解决问题、感知和决策。\n\n而AI分为 **强AI** 和 **弱AI**：\n\n##### **弱AI(ANI - Artificial Narrow Intelligence）**\n\n被设计用来 ****解决特定的任务****（如下棋、人脸识别、写代码）。如AlphaGo, Copilot, Siri 均属此类。\n\n##### **强 AI (AGI - Artificial General Intelligence):**\n\n理论上的“通用人工智能”，拥有与人类同等或超越人类的、跨领域的思考和学习能力。类似于天网、终结者的存在，或者说目标，目前尚未实现。\n\n随着AI的不断发展，也发展出了不同的发展方向，主要是:**机器学习（ML）与专家系统（Expert Systems）**\n\n---\n\n#### **专家系统**\n\n专家系统是人工智能发展早期出现的一种 **方法**，它属于基于规则的 AI，与现代的机器学习驱动的 AI 有着十分鲜明对比。\n\n###### **核心思想与定义**\n\n专家系统旨在模拟人类领域专家（如医生、金融分析师）的决策能力和推理过程，通过将人类的专业知识进行形式化编码，来解决复杂、专业性的问题。本质上是一个由程序员编写的，十分庞大，嵌套极深的 `if-else` 抉择树。\n\n###### 结构\n\n一个典型的专家系统由三个关键组成部分构成：\n\n###### **1. 知识库 (Knowledge Base)**\n\n这是专家系统的信息来源，存储了领域专家的所有专业知识。这些知识通常以两种形式存在：\n\n- **事实 (Facts):** 关于领域的基本信息（例如：“水在100°C 沸腾”）。\n\n- **规则 (Rules):** **条件-行动 (IF-THEN)** 语句，代表专家的经验和推理逻辑。\n  \n  - *示例规则：* `IF (病人有发烧) AND (病人有咳嗽) THEN (推断患有呼吸道感染)`\n\n##### **2. 推理机 (Inference Engine)**\n\n顾名思义，它负责根据用户输入的信息和知识库中的规则进行逻辑推理，得出结论。主要的推理方法有两种：\n\n- **正向链 (Forward Chaining):** **数据驱动**。从已知事实开始，不断应用规则，直到达到目标或所有规则都被应用。\n  \n  - *逻辑：* 如果 $A$ 且 $B$ 为真，而我们知道 $A$ 和 $B$ 是真，则 $C$ 为真。\n\n- **反向链 (Backward Chaining):** **目标驱动**。从目标（假设的结论）开始，向后寻找支持该结论的必要事实或子目标。\n  \n  - *逻辑：* 要证明 $C$，需要 $A$ 和 $B$。那么，先证明 $A$，再证明 $B$。\n\n##### **3. 用户界面 (User Interface)**\n\n用于与用户交互,来接收你输入资讯的地方\n\n相当直观的一种结构，但是简单的代价是会有两个限制和问题：\n\n- **极其脆弱**：遇到规则之外的情况就崩溃。因此，相关模型多用于特定的领域，如医疗，金融等..\n\n- **无法学习**:你必须手动更新模型的规则以及知识库，维护的成本也大大增加\n\n---\n\n### II. 机器学习 (Machine Learning, ML)\n\nML 的本质在于，它不再要求开发者为机器硬编码规则，而是让机器从海量数据中**自动学习**（或“拟合”）出最优的映射函数 $f$。\n\n##### 一. 严谨的定义与三要素 (T, E, P)\n\n机器学习最被认可的定义来自于计算机科学家 Tom M. Mitchell。他指出，一个程序从经验中学习，必须满足三个要素：\n\n| **要素**                       | **解释**                       | **案例：垃圾邮件过滤器**                                                |\n| ---------------------------- | ---------------------------- | ------------------------------------------------------------- |\n| **任务 ($T$ - Task)**          | 机器需要完成的具体工作，通常是预测或推断。        | **分类任务**：将邮件内容 $X$ 分类到 $Y=\\{\\text{“垃圾邮件”}, \\text{“非垃圾邮件”}\\}$。 |\n| **经验 ($E$ - Experience)**    | 模型用于学习的观测数据。                 | **数据集**：100 万封邮件，其中每封邮件都已人工标注了正确的标签。                          |\n| **性能度量 ($P$ - Performance)** | 量化模型表现的指标，衡量其预测结果与真实标签的匹配程度。 | **准确率 (Accuracy)**：模型正确分类的邮件占总邮件数的百分比。                        |\n\n这也是机器学习与专家系统的最大不同。专家系统是输入`数据`+`规则`，输出`答案`；而机器学习则是输入`数据`+`答案`，输出`规则`。\n\n##### 二. 特征工程 (Feature Engineering)\n\n这是将原始数据（如图像像素、原始文本）转换成算法可以理解的、具有信息价值的特征向量的过程，或许能称为“学习”？\n\n1. 优化与统计\n\n机器学习的过程，在数学上被定义为一个**最优化问题**。 (读M2震怒 。学习的目标是找到一组最优参数 $\\theta$，使得模型的**损失函数 ($L$)** 最小化。损失函数度量了模型预测 $\\hat{Y}$ 与真实值 $Y$ 之间的差异：\n\n$$f^* = \\underset{f}{\\operatorname{argmin}} L(f(X), Y)$$\n\n- $f$: 代表模型（如神经网络、决策树）。\n\n- $L(f(X), Y)$: **损失函数**，用于度量模型的预测 $f(X)$ 与真实标签 $Y$ 之间的差异。最小化损失是学习的驱动力。\n\n- $\\operatorname{argmin}$: **最优化操作**，寻找使损失函数 $L$ 达到最小值的模型参数集 $\\theta$。\n\n2. 核心算法：梯度下降 (Gradient Descent)\n\n大多数 ML 模型（尤其是深度学习）使用梯度下降 (Gradient Descent)及其变种（如 SGD, Adam）来执行优化。大概就是一种数学的计算方式，我不会。\n\n<blockquote style=\"border-left: 4px solid #ff6b6b; background: #ffe0e0; padding: 15px; margin: 15px 0;\">\n看看得了\n</blockquote>\n\n**举个栗子**\n\n例子1：银行贷款违约风险预测\n\n| **原始特征 (Raw Data)** | **领域知识应用（工程操作）** | **构造的新特征 (Engineered Feature)**         | **价值**                            |\n| ------------------- | ---------------- | --------------------------------------- | --------------------------------- |\n| `年龄`                | 分箱（Binning）      | `年龄段` (例如：[18-25], [26-40], [41-60]...) | 将连续变量转化为离散变量，捕捉不同年龄段客户的风险特性。      |\n| `信用卡额度`、`已用额度`      | 运算/比率            | `使用率` ($\\text{已用额度} / \\text{总额度}$)      | 这是比两个独立数值更有力的违约风险信号。高使用率通常意味着高风险。 |\n| `过去 12 个月的交易笔数`     | 统计               | `最近 3 个月的平均交易额增长率`                      | 捕捉客户近期消费行为的趋势变化，而非简单的总量。          |\n| `居住城市` (类别)         | 编码               | `城市风险评分` (基于该城市历史违约率)                   | 将高维度的类别特征转化为具有预测意义的数值特征。          |\n\n案例 2：情绪分析\n\n客户评论：“这个应用太卡了，但设计很漂亮。”\n\n| **原始特征** | **领域知识应用（工程操作）**                     | **构造的新特征**             | **价值**                           |\n| -------- | ------------------------------------ | ---------------------- | -------------------------------- |\n| 原始句子     | **词袋模型 (Bag-of-Words)** 或 **TF-IDF** | `“卡”的频率`, `“漂亮”的权重`    | 将不定长的文本转化为固定长度的数值向量。             |\n| 词语       | **N-gram 构造**                        | `“太卡了”` (三元词组)         | 捕捉词语的局部顺序和语义，“太卡了”比单独的“卡”更有负面情感。 |\n| 情感词典     | **计数**                               | `负面词汇数量`, `正面词汇数量`     | 捕捉评论的**情感极性**和**强度**。            |\n| 连词       | **结构分析**                             | `是否存在转折连词 (“但”, “可是”)` | “卡但漂亮”表示复杂情绪，模型应区别于“卡且丑陋”。       |\n\n##### 三、 机器学习的主要任务类型\n\n机器学习任务通常根据训练数据的性质和模型目标被划分为三大类：\n\n###### 1. 监督学习 (Supervised Learning)\n\n监督学习是目前应用最广泛的 ML 类型，类似于有老师手把手教你，即训练数据中的每一个输入 $X$ 都对应一个已知的、正确的输出标签 $Y$。这类算法的目的是学习和逼近输入 $X$ 到输出 $Y$ 的映射函数 $f$，使得对于任何新的输入 $X_{\\text{new}}$，模型能够准确预测其对应的 $\\hat{Y}_{\\text{new}}$。\n\n<blockquote style=\"border-left: 4px solid #4dabf7; background: #e7f5ff; padding: 15px; margin: 15px 0;\">\n金融预测： 输入经济指标和历史数据，输出连续的未来某商品价格。\n\n住房预测： 输入房屋面积、地理位置等，输出具体的房价数值。\n</blockquote>\n\n###### 2.无监督学习 (Unsupervised Learning)\n\n无监督学习就像是让学生自主探索。模型接收的训练数据**只有输入 $X$**，没有标签 $Y$。在此类算法中，模型必须自主地探索数据，找出隐藏在数据中的统计结构、分布等。它不进行预测，而是进行描述和组织。\n\n<blockquote style=\"border-left: 4px solid #4dabf7; background: #e7f5ff; padding: 15px; margin: 15px 0;\">\n购物分析：发现“如果客户购买了牛奶 (A)，那么他们有 80% 的概率也会购买面包 (B)”。\n</blockquote>\n\n###### 3.[强化学习 (Reinforcement Learning, RL)](https://www.wikiwand.com/en/articles/Reinforcement_learning)\n\n![https://assets.wikiwand.com/_next/image?url=https://upload.wikimedia.org/wikipedia/commons/thumb/1/1b/Reinforcement_learning_diagram.svg/1100px-Reinforcement_learning_diagram.svg.png&w=828&q=70](https://assets.wikiwand.com/_next/image?url=https://upload.wikimedia.org/wikipedia/commons/thumb/1/1b/Reinforcement_learning_diagram.svg/1100px-Reinforcement_learning_diagram.svg.png&w=828&q=70)\n\n强化学习与前两者完全不同，它是一种**基于试错 (Trial-and-Error)** 的学习方法，灵感来源于心理学中的行为主义。\n\n如果你想让你家的狗学会坐下或叼飞盘，你不会像人类一样让它看书，而是使用**奖励**和**惩罚**来塑造它的行为，这也是强化学习的逻辑。训练机器狗的过程是一个永不停止的、基于**马尔可夫决策过程 (MDP)** 的循环：\n\n#### 步骤 1：观察\n\n机器狗环顾四周，确定它在哪里（**状态 $S$**）。\n\n- *例如：* 机器狗知道它在 $(5, 5)$ 位置，并且闻到了前方有食物的气味。\n\n#### 步骤 2：行动\n\n机器狗根据它**当前的策略 $\\pi$**（行为准则），决定下一步做什么（**行动 $A$**）。\n\n- *例如：* 机器狗的策略是“闻到食物，就前进”。它执行了“前进”的动作。\n\n#### 步骤 3：反馈与奖励\n\n机器狗执行动作后，环境发生变化，并返回反馈：\n\n- **新状态 $S'$：** 机器狗移动到了 $(6, 5)$ 位置。\n\n- **奖励 $R$：**\n  \n  - 如果它吃到了食物：$+100$ (奖励)\n  \n  - 如果它撞到了墙：$-10$ (惩罚)\n  \n  - 如果它踩到了地雷：$-1000$ (巨大惩罚)\n  \n  - 如果只是普通移动：$-1$ (微小惩罚)\n\n#### 步骤 4：更新策略\n\n机器狗利用这个反馈（奖励 $R$）来**评估**它刚才的行动好不好，并**调整它的策略 $\\pi$**。\n\n- **如果 $R$ 为正：** 它知道这个行动是好的，下次在类似状态下会倾向于重复这个行动。\n\n- **如果 $R$ 为负：** 它知道这个行动是坏的，下次在类似状态下会避免这个行动。\n\n这个循环会重复数百万次，机器狗从随机的试错开始，逐步搭建一套最优策略，即：如何避开地雷，并以最快的速度找到最多的食物。\n\n---\n\n### III 深度学习 (Deep Learning,DL)\n\n深度学习属于机器学习的其中一种，是实现机器学习的一种技术。它特指使用一种名为**深度神经网络 (Deep Neural Networks, DNN)** 的特定模型结构来完成学习任务。\n\n##### 说文解字\n\n“深”，意为深度，有点像是层级化的特征学习\n\n- **传统 ML：** 高度依赖人类专家手动设计特征。例如，要识别一张图片中的人脸，你可能需要手动编写代码来检测“眼睛的形状”、“鼻子的比例”、“肤色分布”等特征。\n\n- **深度学习：** 实现了自动化的特征学习。您只需将原始数据（如图像的原始像素）喂给模型，模型会自动在它的“深度”结构中学习到最优特征。\n\n这种叫做**层级化特征学习**\n\n##### 举个栗子\n\n以图像识别的CNN为例:\n\n- **Layer 1 (浅层):** 神经网络的第一层会自动学习到最基础的特征，如`边缘`、`角落`、简单的`颜色块`。\n\n- **Layer 2 (中层):** 这一层会组合第一层的简单特征，自动学习到更复杂的形状和纹理，如`圆形`、`网格状`、`毛发纹理`。\n\n- **Layer 3 (深层):** 这一层会组合中层的形状，自动学习到物体的部件，如`眼睛`、`鼻子`、`汽车轮胎`。\n\n- **Output Layer (顶层):** 最终，顶层会组合这些部件，做出最终的分类判断：“这是一张人脸”或“这是一辆汽车”\n\n**深度** 指的就是这种特征抽象的层级数量。因为模型会自动学习这些特征，所以它能发现人类工程师难以想到的更优、更抽象的东西。\n\n##### 构成\n\n一个**深度神经网络** 由三个部分组成：\n\n1. **输入层 (Input Layer):** 接收原始数据（如图像像素、词向量）。\n\n2. **隐藏层 (Hidden Layers):** 这是模型的核心。DNN 至少有两个或更多的隐藏层（通常是几十到几百层）。每一层都由许多**神经元** 组成，每个神经元都会对其输入进行**加权求和**并应用**激活函数**来引入非线性。\n\n3. **输出层 (Output Layer):** 生成最终的预测结果（如分类的概率）。\n\n##### 主要架构\n\n| **架构**          | **全称**                                       | **核心机制**                                   | **擅长领域**                                  |\n| --------------- | -------------------------------------------- | ------------------------------------------ | ----------------------------------------- |\n| **CNN**         | **卷积神经网络**<br>(Convolutional Neural Network) | **卷积核 (Filters)** 与 **参数共享**。              | **网格状数据（如图像）**：图像识别、医学影像分析、目标检测。          |\n| **RNN**         | **循环神经网络**<br>(Recurrent Neural Network)     | **隐藏状态 (Hidden State)** 的循环，用于处理序列。        | **序列数据（如文本、时间序列）**：自然语言处理、语音识别。           |\n| **LSTM**        | **长短期记忆网络**<br>(Long Short-Term Memory)      | RNN 的变体，使用“门控”机制来解决 RNN 的  **长距离依赖（遗忘**问题。 | 复杂的序列任务。                                  |\n| **Transformer** | (无特定全称)                                      | **自注意力机制 (Self-Attention)**。               | **现代 NLP 的基石**：GPT-4、BERT 等大型语言模型，以及机器翻译。 |\n\n<blockquote style=\"border-left: 4px solid #ff6b6b; background: #ffe0e0; padding: 15px; margin: 15px 0;\">\n以上内容看看得了\n</blockquote>\n\n看不懂是正常的，我们来举个栗子\n\n让我们把**深度神经网络 (DNN)** 想象为一家公司\n\n---\n\n### 第一部分：DNN 的结构 — 公司的层级\n\n#### 1. 输入层 — 前台接待员\n\n这是公司的前台。当客户（数据）上门时，前台接待员（输入神经元）负责接收最原始、最琐碎的信息。\n\n- **事件：** 客户给了一张图片。\n\n- **接待员的工作：** 他们不会思考，只是把图片拆解成最基本的信息（比如，每个像素点的颜色值）。\n  \n  - “接待员 1：左上角像素，红色值 255。”\n  \n  - “接待员 2：左上角像素，绿色值 100。”\n  \n  - ...\n\n- 输入层只负责**接收原始数据**，并将其传递给下一层。\n\n#### 2. 隐藏层 — 工作团队\n\n深度一词的由来。想象每一家公司有很多部门。\n\n- 假设每一层都是一个部门。\n\n- **工作流程：**\n  \n  - **层级 1 (部门A)：** 他们从所有“接待员”那里拿到原始像素数据。他们的工作是**识别最简单的模式**。\n\n    - 员工 A：“我发现了一些横向边缘。”\n\n    - 员工 B：”我发现了一些垂直线条。”\n\n    - 员工 C：“我发现了一块毛茸茸的纹理。”\n  \n  - **层级 2 (部门B)：** 他们不看原始数据，只看部门A的报告。他们的工作是**组合简单模式，形成复杂形状**。\n\n    - 员工 X：”我把`边缘 A`和`纹理 C`组合起来，这看起来像一个`耳朵`的轮廓。”\n\n    - 员工 Y：“我把`线条 B`和另一条线组合，这像`胡须`。”\n  \n  - **隐藏层 3 (部门C)：** 他们继续组合先前部门的所有报告，形成更复杂的概念。\n\n    - 员工 P：”我拿到了`耳朵`、`胡须`和`眼睛`的报告，我认为这构成了一张`动物的脸`。”\n\n**...... 以此类推**\n\n#### 3. 权重— 经理的偏好\n\n每个经理在看下属的报告时，都有自己的**偏好（权重）**。\n\n- 在部门A的经理看来：\n  \n  - 下属 A (边缘) 的报告**非常重要** (权重 = 0.9)。\n  \n  - 下属 B (线条) 的报告**不太重要** (权重 = 0.1)。\n  \n  - 下属 C (纹理) 的报告**中等重要** (权重 = 0.5)。\n\n- 经理会把所有报告的**重要性**加权求和，形成自己的最终判断。\n\n#### 4. 输出层 — 老板\n\n这是一家公司的最高层\n\n- 老板不看任何琐碎细节，只看各部门的最终报告。\n\n- **决策：**\n  \n  - A 报告：“我 95% 确定这是一张‘动物的脸’。”\n  \n  - B 报告：“我 80% 确定这是‘猫的身体’。”\n  \n  - X 报告：“我20%确定是‘狗的身体’。”\n\n- 老板综合所有最高层的信息，做出最终的、唯一的决策：“**我宣布，这是猫**。”\n\n### 第二部分：反向传播 — 秋后算账\n\n这时候，身为正常人的你下楼一看，糟糕了：\n\n- 老板：“这是猫！”\n\n- 你：“？？？这不是狗吗？”\n\n现在，公司必须从这个巨大的错误中学习。这就是**反向传播 (Backpropagation)** 的开始，它是一个**追责**和**纠正**的过程。\n\n生气的你冲到老板面前，一招大荒囚天指技惊四座。\n\n“你个蠢货，那是只狗！”\n\n##### 反向追责 (Backward Pass)\n\n这个“追责”的过程是**从老板开始，一层一层往下**的：\n\n- **第 1 站：老板 (输出层)**\n  \n  - **你问老板：** “你为什么判断是猫？”\n  \n  - **老板回答：** “因为我的 A 报告 (动物的脸) 和 B 报告 (猫的身体) 都给了充足的论证。我的偏好是更相信 B(猫的身体)。”\n  \n  - **你的指示 (梯度)：** “你（老板）的 **判断** 错了！下次 B (猫的身体) 报告时，你**必须降低对它的信任度** (降低权重)。同时，X (狗的身体) 的报告，你**必须提高信任度** (提高权重)。”\n\n- **第 2 站：部门经理 (隐藏层 N)**\n  \n  - **老板跑去问经理：** “你为什么说那是‘猫的身体’？害我被骂！”\n  \n  - **经理回答：** “因为我的员工的分析，让我更偏向于相信是猫的身体。”\n  \n  - **总教练指示 (梯度)：** “你**判断** 也错了！下次报告时，你**必须降低对它的信任度**。同时，你要更关注狗爪子的报告！”\n  \n  **...... 以此类推，直至最底层**\n\n#### 3. 链式法则 (Chain Rule)\n\n你注意到了吗？**错误的“责任”从顶层传递到了底层。**\n\n- 老板的错误，导致了对经理的“指责”。\n\n- 经理的错误，导致了对员工的“指责”。\n\n- ...\n\n- 这个**指责**的**具体数值（你应该调整多少？）**，在数学上就是**梯度 (Gradient)**。\n\n- 这种**逐层反向传递责任**的数学工具，就是**链式法则 (Chain Rule)**。\n\n#### 4. 全员调整 (Weight Update)\n\n经过这一次秋后算账，公司里的**每一个经理，一直到底层员工（所有神经元）**，都收到了一个具体的“调整指令”：\n\n> “你之前对下属 X 的报告‘偏好’（权重）太高了，下次把它调低 0.05%。”\n> “你之前对下属 Y 的报告‘偏好’太低了，下次把它调高 0.02%。”\n\n**这个过程（决策 -> 犯错 -> 反向追责 -> 全员微调）会重复数百万次。**\n\n最终，这家公司的所有经理都学会了一套极其复杂且精妙的“偏好”（权重），使得他们在下次看到一张“狗”的图片时，能从前台开始，一路正确地传递信息，最终让老板做出正确的决策：“这是狗！”\n\n---\n\n### IV 注意力的革命\n\n在 GPT 出现之前，处理序列数据（如文本、语音）的主流模型是 **RNN (循环神经网络)** 及其变体 **LSTM**。\n\nRNN 的设计很直观：它像人一样，一个词一个词地阅读。它有一个“记忆单元”（Hidden State），在阅读句子:'The cat sat on the floor.'时，在读完“The cat”后，会把'The cat'的信息编码到记忆里，再去读下一个词‘sat’。\n\n但这种设计存在两个致命问题。**首先是长距离依赖和梯度消失**：当句子很长时（“我昨天...（省略50个词）...那只猫”），到处理“猫”时，关于“昨天”的信息（梯度）在“记忆”中已经极其微弱，模型“忘记”了。**其次是串行计算瓶颈**：你必须处理完 `word[n]` 才能处理 `word[n+1]`。这在 GPU 时代是灾难性的，因为 GPU 最擅长的是**并行计算**（同时处理 1000 个 `word`），而 RNN 的设计使其无法利用这一点。\n\n直到 2017 年，一篇论文[《Attention Is All You Need》](https://proceedings.neurips.cc/paper_files/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf)彻底改变了这一切。**Transformer** 模型登场，它做的第一件事就是：**彻底抛弃 RNN 的“循环”结构**。\n\nTransformer 的核心是**自注意力机制 (Self-Attention)**。它的核心思想是：一个句子中的词，其含义不是孤立的，而是由它和句子中所有其他词的关系共同决定的。\n\n> 例子：“The **animal** didn't cross the street because **it** was too tired.”\n\n当模型处理 \"it\" 时，\"it\" 指的是 \"animal\" 还是 \"street\"？RNN 必须依赖其摇摇欲坠的“短期记忆”。而 Self-Attention 允许 \"it\" *直接“看”向* 句子中的所有其他词，并计算一个“注意力得分”。它会发现 \"it\" 和 \"animal\" 的关联性远高于 \"street\"。\n\n那么，Self-Attention 在技术上是如何做到这一点的呢？它为句子中的 每个词 都生成三个不同的向量：\n\n- **Query (Q) 向量：** 代表当前词作为“查询者”的身份。可以理解为：“**我** (it) 是谁？我正在寻找和我相关的东西。”\n\n- **Key (K) 向量：** 代表该词可被“索引”的标签。可以理解为：“我是“animal”，一个可以被指代的名词。”\n\n- **Value (V) 向量：** 代表该词的“真正含义”或“内容”。\n\n整个过程如下（以‘it’为例）：\n\n**首先是打分(Scoring)**：拿 \"it\" 的 **Q 向量**，去和 **句子中所有词**（包括 \"it\" 自己）的 **K** 向量进行**点积** (Dot-Product)。这个点积的结果，就是**相关性得分**。（如果 \"it\" 的 Q 和 \"animal\" 的 K 很接近，得分就高）。\n\n**接着是归一化(Softmax)**：将这些原始得分通过一个 Softmax 函数，将其转换为总和为 1 的“注意力权重”（例如：{ \"The\": 0.05, \"animal\": **0.85**, ..., \"it\": 0.05, ...}）。\n\n**最后是加权求和(Weighted Sum)**：用这些**注意力权重**，去对 句子中所有词 的 **V** 向量进行加权求和。\n\n`Output_for_it = (0.05 * V_The) + (0.85 * V_animal) + ...`\n\n最终的结果是： \"it\" 的原始 V 向量（它自己的含义）被“注入”了 85% 的 \"animal\" 的 V 向量（含义）。模型在这一层就明确知道了 \"it\" 指向 \"animal\"。\n\nTransformer 的革命性在于两个方面。**第一是并行化**：整个 Q-K-V 计算是纯粹的矩阵乘法。GPU 可以 *同时* 计算句子中所有词的 Q/K/V 和注意力得分。这充分运用了设备的算力，使得训练千亿（甚至万亿）参数的巨型模型（LLM）成为可能。**第二是全局依赖**：任何两个词（无论相隔多远）的“距离”都为 1。模型可以轻易捕捉长距离依赖，彻底解决了 RNN 的“遗忘”问题。\n\n---\n\n东拼西凑的一个月，终于完成了🙌\n","source":"_posts/Artificial Intelligence.md","raw":"---\ntitle: AI\ndate: 2025-10-24\ndescription: '聊聊ai'\nimage: ''\ntags: AI/Artificial Intelligence\ntype: '杂谈'\ntop_img: false\n---\n\n想了很久，终于有时间来讲讲AI了，些许错误，多多包容\n\n---\n\n### I. 人工智能 (Artificial Intelligence,AI)\n\n大家都听过的词语，依照维基百科的解释:  [人工智能（AI）](https://www.wikiwand.com/en/articles/Artificial_intelligence.com)是指计算系统执行通常与人类智能相关任务的能力，例如学习、推理、解决问题、感知和决策。\n\n而AI分为 **强AI** 和 **弱AI**：\n\n##### **弱AI(ANI - Artificial Narrow Intelligence）**\n\n被设计用来 ****解决特定的任务****（如下棋、人脸识别、写代码）。如AlphaGo, Copilot, Siri 均属此类。\n\n##### **强 AI (AGI - Artificial General Intelligence):**\n\n理论上的“通用人工智能”，拥有与人类同等或超越人类的、跨领域的思考和学习能力。类似于天网、终结者的存在，或者说目标，目前尚未实现。\n\n随着AI的不断发展，也发展出了不同的发展方向，主要是:**机器学习（ML）与专家系统（Expert Systems）**\n\n---\n\n#### **专家系统**\n\n专家系统是人工智能发展早期出现的一种 **方法**，它属于基于规则的 AI，与现代的机器学习驱动的 AI 有着十分鲜明对比。\n\n###### **核心思想与定义**\n\n专家系统旨在模拟人类领域专家（如医生、金融分析师）的决策能力和推理过程，通过将人类的专业知识进行形式化编码，来解决复杂、专业性的问题。本质上是一个由程序员编写的，十分庞大，嵌套极深的 `if-else` 抉择树。\n\n###### 结构\n\n一个典型的专家系统由三个关键组成部分构成：\n\n###### **1. 知识库 (Knowledge Base)**\n\n这是专家系统的信息来源，存储了领域专家的所有专业知识。这些知识通常以两种形式存在：\n\n- **事实 (Facts):** 关于领域的基本信息（例如：“水在100°C 沸腾”）。\n\n- **规则 (Rules):** **条件-行动 (IF-THEN)** 语句，代表专家的经验和推理逻辑。\n  \n  - *示例规则：* `IF (病人有发烧) AND (病人有咳嗽) THEN (推断患有呼吸道感染)`\n\n##### **2. 推理机 (Inference Engine)**\n\n顾名思义，它负责根据用户输入的信息和知识库中的规则进行逻辑推理，得出结论。主要的推理方法有两种：\n\n- **正向链 (Forward Chaining):** **数据驱动**。从已知事实开始，不断应用规则，直到达到目标或所有规则都被应用。\n  \n  - *逻辑：* 如果 $A$ 且 $B$ 为真，而我们知道 $A$ 和 $B$ 是真，则 $C$ 为真。\n\n- **反向链 (Backward Chaining):** **目标驱动**。从目标（假设的结论）开始，向后寻找支持该结论的必要事实或子目标。\n  \n  - *逻辑：* 要证明 $C$，需要 $A$ 和 $B$。那么，先证明 $A$，再证明 $B$。\n\n##### **3. 用户界面 (User Interface)**\n\n用于与用户交互,来接收你输入资讯的地方\n\n相当直观的一种结构，但是简单的代价是会有两个限制和问题：\n\n- **极其脆弱**：遇到规则之外的情况就崩溃。因此，相关模型多用于特定的领域，如医疗，金融等..\n\n- **无法学习**:你必须手动更新模型的规则以及知识库，维护的成本也大大增加\n\n---\n\n### II. 机器学习 (Machine Learning, ML)\n\nML 的本质在于，它不再要求开发者为机器硬编码规则，而是让机器从海量数据中**自动学习**（或“拟合”）出最优的映射函数 $f$。\n\n##### 一. 严谨的定义与三要素 (T, E, P)\n\n机器学习最被认可的定义来自于计算机科学家 Tom M. Mitchell。他指出，一个程序从经验中学习，必须满足三个要素：\n\n| **要素**                       | **解释**                       | **案例：垃圾邮件过滤器**                                                |\n| ---------------------------- | ---------------------------- | ------------------------------------------------------------- |\n| **任务 ($T$ - Task)**          | 机器需要完成的具体工作，通常是预测或推断。        | **分类任务**：将邮件内容 $X$ 分类到 $Y=\\{\\text{“垃圾邮件”}, \\text{“非垃圾邮件”}\\}$。 |\n| **经验 ($E$ - Experience)**    | 模型用于学习的观测数据。                 | **数据集**：100 万封邮件，其中每封邮件都已人工标注了正确的标签。                          |\n| **性能度量 ($P$ - Performance)** | 量化模型表现的指标，衡量其预测结果与真实标签的匹配程度。 | **准确率 (Accuracy)**：模型正确分类的邮件占总邮件数的百分比。                        |\n\n这也是机器学习与专家系统的最大不同。专家系统是输入`数据`+`规则`，输出`答案`；而机器学习则是输入`数据`+`答案`，输出`规则`。\n\n##### 二. 特征工程 (Feature Engineering)\n\n这是将原始数据（如图像像素、原始文本）转换成算法可以理解的、具有信息价值的特征向量的过程，或许能称为“学习”？\n\n1. 优化与统计\n\n机器学习的过程，在数学上被定义为一个**最优化问题**。 (读M2震怒 。学习的目标是找到一组最优参数 $\\theta$，使得模型的**损失函数 ($L$)** 最小化。损失函数度量了模型预测 $\\hat{Y}$ 与真实值 $Y$ 之间的差异：\n\n$$f^* = \\underset{f}{\\operatorname{argmin}} L(f(X), Y)$$\n\n- $f$: 代表模型（如神经网络、决策树）。\n\n- $L(f(X), Y)$: **损失函数**，用于度量模型的预测 $f(X)$ 与真实标签 $Y$ 之间的差异。最小化损失是学习的驱动力。\n\n- $\\operatorname{argmin}$: **最优化操作**，寻找使损失函数 $L$ 达到最小值的模型参数集 $\\theta$。\n\n2. 核心算法：梯度下降 (Gradient Descent)\n\n大多数 ML 模型（尤其是深度学习）使用梯度下降 (Gradient Descent)及其变种（如 SGD, Adam）来执行优化。大概就是一种数学的计算方式，我不会。\n\n<blockquote style=\"border-left: 4px solid #ff6b6b; background: #ffe0e0; padding: 15px; margin: 15px 0;\">\n看看得了\n</blockquote>\n\n**举个栗子**\n\n例子1：银行贷款违约风险预测\n\n| **原始特征 (Raw Data)** | **领域知识应用（工程操作）** | **构造的新特征 (Engineered Feature)**         | **价值**                            |\n| ------------------- | ---------------- | --------------------------------------- | --------------------------------- |\n| `年龄`                | 分箱（Binning）      | `年龄段` (例如：[18-25], [26-40], [41-60]...) | 将连续变量转化为离散变量，捕捉不同年龄段客户的风险特性。      |\n| `信用卡额度`、`已用额度`      | 运算/比率            | `使用率` ($\\text{已用额度} / \\text{总额度}$)      | 这是比两个独立数值更有力的违约风险信号。高使用率通常意味着高风险。 |\n| `过去 12 个月的交易笔数`     | 统计               | `最近 3 个月的平均交易额增长率`                      | 捕捉客户近期消费行为的趋势变化，而非简单的总量。          |\n| `居住城市` (类别)         | 编码               | `城市风险评分` (基于该城市历史违约率)                   | 将高维度的类别特征转化为具有预测意义的数值特征。          |\n\n案例 2：情绪分析\n\n客户评论：“这个应用太卡了，但设计很漂亮。”\n\n| **原始特征** | **领域知识应用（工程操作）**                     | **构造的新特征**             | **价值**                           |\n| -------- | ------------------------------------ | ---------------------- | -------------------------------- |\n| 原始句子     | **词袋模型 (Bag-of-Words)** 或 **TF-IDF** | `“卡”的频率`, `“漂亮”的权重`    | 将不定长的文本转化为固定长度的数值向量。             |\n| 词语       | **N-gram 构造**                        | `“太卡了”` (三元词组)         | 捕捉词语的局部顺序和语义，“太卡了”比单独的“卡”更有负面情感。 |\n| 情感词典     | **计数**                               | `负面词汇数量`, `正面词汇数量`     | 捕捉评论的**情感极性**和**强度**。            |\n| 连词       | **结构分析**                             | `是否存在转折连词 (“但”, “可是”)` | “卡但漂亮”表示复杂情绪，模型应区别于“卡且丑陋”。       |\n\n##### 三、 机器学习的主要任务类型\n\n机器学习任务通常根据训练数据的性质和模型目标被划分为三大类：\n\n###### 1. 监督学习 (Supervised Learning)\n\n监督学习是目前应用最广泛的 ML 类型，类似于有老师手把手教你，即训练数据中的每一个输入 $X$ 都对应一个已知的、正确的输出标签 $Y$。这类算法的目的是学习和逼近输入 $X$ 到输出 $Y$ 的映射函数 $f$，使得对于任何新的输入 $X_{\\text{new}}$，模型能够准确预测其对应的 $\\hat{Y}_{\\text{new}}$。\n\n<blockquote style=\"border-left: 4px solid #4dabf7; background: #e7f5ff; padding: 15px; margin: 15px 0;\">\n金融预测： 输入经济指标和历史数据，输出连续的未来某商品价格。\n\n住房预测： 输入房屋面积、地理位置等，输出具体的房价数值。\n</blockquote>\n\n###### 2.无监督学习 (Unsupervised Learning)\n\n无监督学习就像是让学生自主探索。模型接收的训练数据**只有输入 $X$**，没有标签 $Y$。在此类算法中，模型必须自主地探索数据，找出隐藏在数据中的统计结构、分布等。它不进行预测，而是进行描述和组织。\n\n<blockquote style=\"border-left: 4px solid #4dabf7; background: #e7f5ff; padding: 15px; margin: 15px 0;\">\n购物分析：发现“如果客户购买了牛奶 (A)，那么他们有 80% 的概率也会购买面包 (B)”。\n</blockquote>\n\n###### 3.[强化学习 (Reinforcement Learning, RL)](https://www.wikiwand.com/en/articles/Reinforcement_learning)\n\n![https://assets.wikiwand.com/_next/image?url=https://upload.wikimedia.org/wikipedia/commons/thumb/1/1b/Reinforcement_learning_diagram.svg/1100px-Reinforcement_learning_diagram.svg.png&w=828&q=70](https://assets.wikiwand.com/_next/image?url=https://upload.wikimedia.org/wikipedia/commons/thumb/1/1b/Reinforcement_learning_diagram.svg/1100px-Reinforcement_learning_diagram.svg.png&w=828&q=70)\n\n强化学习与前两者完全不同，它是一种**基于试错 (Trial-and-Error)** 的学习方法，灵感来源于心理学中的行为主义。\n\n如果你想让你家的狗学会坐下或叼飞盘，你不会像人类一样让它看书，而是使用**奖励**和**惩罚**来塑造它的行为，这也是强化学习的逻辑。训练机器狗的过程是一个永不停止的、基于**马尔可夫决策过程 (MDP)** 的循环：\n\n#### 步骤 1：观察\n\n机器狗环顾四周，确定它在哪里（**状态 $S$**）。\n\n- *例如：* 机器狗知道它在 $(5, 5)$ 位置，并且闻到了前方有食物的气味。\n\n#### 步骤 2：行动\n\n机器狗根据它**当前的策略 $\\pi$**（行为准则），决定下一步做什么（**行动 $A$**）。\n\n- *例如：* 机器狗的策略是“闻到食物，就前进”。它执行了“前进”的动作。\n\n#### 步骤 3：反馈与奖励\n\n机器狗执行动作后，环境发生变化，并返回反馈：\n\n- **新状态 $S'$：** 机器狗移动到了 $(6, 5)$ 位置。\n\n- **奖励 $R$：**\n  \n  - 如果它吃到了食物：$+100$ (奖励)\n  \n  - 如果它撞到了墙：$-10$ (惩罚)\n  \n  - 如果它踩到了地雷：$-1000$ (巨大惩罚)\n  \n  - 如果只是普通移动：$-1$ (微小惩罚)\n\n#### 步骤 4：更新策略\n\n机器狗利用这个反馈（奖励 $R$）来**评估**它刚才的行动好不好，并**调整它的策略 $\\pi$**。\n\n- **如果 $R$ 为正：** 它知道这个行动是好的，下次在类似状态下会倾向于重复这个行动。\n\n- **如果 $R$ 为负：** 它知道这个行动是坏的，下次在类似状态下会避免这个行动。\n\n这个循环会重复数百万次，机器狗从随机的试错开始，逐步搭建一套最优策略，即：如何避开地雷，并以最快的速度找到最多的食物。\n\n---\n\n### III 深度学习 (Deep Learning,DL)\n\n深度学习属于机器学习的其中一种，是实现机器学习的一种技术。它特指使用一种名为**深度神经网络 (Deep Neural Networks, DNN)** 的特定模型结构来完成学习任务。\n\n##### 说文解字\n\n“深”，意为深度，有点像是层级化的特征学习\n\n- **传统 ML：** 高度依赖人类专家手动设计特征。例如，要识别一张图片中的人脸，你可能需要手动编写代码来检测“眼睛的形状”、“鼻子的比例”、“肤色分布”等特征。\n\n- **深度学习：** 实现了自动化的特征学习。您只需将原始数据（如图像的原始像素）喂给模型，模型会自动在它的“深度”结构中学习到最优特征。\n\n这种叫做**层级化特征学习**\n\n##### 举个栗子\n\n以图像识别的CNN为例:\n\n- **Layer 1 (浅层):** 神经网络的第一层会自动学习到最基础的特征，如`边缘`、`角落`、简单的`颜色块`。\n\n- **Layer 2 (中层):** 这一层会组合第一层的简单特征，自动学习到更复杂的形状和纹理，如`圆形`、`网格状`、`毛发纹理`。\n\n- **Layer 3 (深层):** 这一层会组合中层的形状，自动学习到物体的部件，如`眼睛`、`鼻子`、`汽车轮胎`。\n\n- **Output Layer (顶层):** 最终，顶层会组合这些部件，做出最终的分类判断：“这是一张人脸”或“这是一辆汽车”\n\n**深度** 指的就是这种特征抽象的层级数量。因为模型会自动学习这些特征，所以它能发现人类工程师难以想到的更优、更抽象的东西。\n\n##### 构成\n\n一个**深度神经网络** 由三个部分组成：\n\n1. **输入层 (Input Layer):** 接收原始数据（如图像像素、词向量）。\n\n2. **隐藏层 (Hidden Layers):** 这是模型的核心。DNN 至少有两个或更多的隐藏层（通常是几十到几百层）。每一层都由许多**神经元** 组成，每个神经元都会对其输入进行**加权求和**并应用**激活函数**来引入非线性。\n\n3. **输出层 (Output Layer):** 生成最终的预测结果（如分类的概率）。\n\n##### 主要架构\n\n| **架构**          | **全称**                                       | **核心机制**                                   | **擅长领域**                                  |\n| --------------- | -------------------------------------------- | ------------------------------------------ | ----------------------------------------- |\n| **CNN**         | **卷积神经网络**<br>(Convolutional Neural Network) | **卷积核 (Filters)** 与 **参数共享**。              | **网格状数据（如图像）**：图像识别、医学影像分析、目标检测。          |\n| **RNN**         | **循环神经网络**<br>(Recurrent Neural Network)     | **隐藏状态 (Hidden State)** 的循环，用于处理序列。        | **序列数据（如文本、时间序列）**：自然语言处理、语音识别。           |\n| **LSTM**        | **长短期记忆网络**<br>(Long Short-Term Memory)      | RNN 的变体，使用“门控”机制来解决 RNN 的  **长距离依赖（遗忘**问题。 | 复杂的序列任务。                                  |\n| **Transformer** | (无特定全称)                                      | **自注意力机制 (Self-Attention)**。               | **现代 NLP 的基石**：GPT-4、BERT 等大型语言模型，以及机器翻译。 |\n\n<blockquote style=\"border-left: 4px solid #ff6b6b; background: #ffe0e0; padding: 15px; margin: 15px 0;\">\n以上内容看看得了\n</blockquote>\n\n看不懂是正常的，我们来举个栗子\n\n让我们把**深度神经网络 (DNN)** 想象为一家公司\n\n---\n\n### 第一部分：DNN 的结构 — 公司的层级\n\n#### 1. 输入层 — 前台接待员\n\n这是公司的前台。当客户（数据）上门时，前台接待员（输入神经元）负责接收最原始、最琐碎的信息。\n\n- **事件：** 客户给了一张图片。\n\n- **接待员的工作：** 他们不会思考，只是把图片拆解成最基本的信息（比如，每个像素点的颜色值）。\n  \n  - “接待员 1：左上角像素，红色值 255。”\n  \n  - “接待员 2：左上角像素，绿色值 100。”\n  \n  - ...\n\n- 输入层只负责**接收原始数据**，并将其传递给下一层。\n\n#### 2. 隐藏层 — 工作团队\n\n深度一词的由来。想象每一家公司有很多部门。\n\n- 假设每一层都是一个部门。\n\n- **工作流程：**\n  \n  - **层级 1 (部门A)：** 他们从所有“接待员”那里拿到原始像素数据。他们的工作是**识别最简单的模式**。\n\n    - 员工 A：“我发现了一些横向边缘。”\n\n    - 员工 B：”我发现了一些垂直线条。”\n\n    - 员工 C：“我发现了一块毛茸茸的纹理。”\n  \n  - **层级 2 (部门B)：** 他们不看原始数据，只看部门A的报告。他们的工作是**组合简单模式，形成复杂形状**。\n\n    - 员工 X：”我把`边缘 A`和`纹理 C`组合起来，这看起来像一个`耳朵`的轮廓。”\n\n    - 员工 Y：“我把`线条 B`和另一条线组合，这像`胡须`。”\n  \n  - **隐藏层 3 (部门C)：** 他们继续组合先前部门的所有报告，形成更复杂的概念。\n\n    - 员工 P：”我拿到了`耳朵`、`胡须`和`眼睛`的报告，我认为这构成了一张`动物的脸`。”\n\n**...... 以此类推**\n\n#### 3. 权重— 经理的偏好\n\n每个经理在看下属的报告时，都有自己的**偏好（权重）**。\n\n- 在部门A的经理看来：\n  \n  - 下属 A (边缘) 的报告**非常重要** (权重 = 0.9)。\n  \n  - 下属 B (线条) 的报告**不太重要** (权重 = 0.1)。\n  \n  - 下属 C (纹理) 的报告**中等重要** (权重 = 0.5)。\n\n- 经理会把所有报告的**重要性**加权求和，形成自己的最终判断。\n\n#### 4. 输出层 — 老板\n\n这是一家公司的最高层\n\n- 老板不看任何琐碎细节，只看各部门的最终报告。\n\n- **决策：**\n  \n  - A 报告：“我 95% 确定这是一张‘动物的脸’。”\n  \n  - B 报告：“我 80% 确定这是‘猫的身体’。”\n  \n  - X 报告：“我20%确定是‘狗的身体’。”\n\n- 老板综合所有最高层的信息，做出最终的、唯一的决策：“**我宣布，这是猫**。”\n\n### 第二部分：反向传播 — 秋后算账\n\n这时候，身为正常人的你下楼一看，糟糕了：\n\n- 老板：“这是猫！”\n\n- 你：“？？？这不是狗吗？”\n\n现在，公司必须从这个巨大的错误中学习。这就是**反向传播 (Backpropagation)** 的开始，它是一个**追责**和**纠正**的过程。\n\n生气的你冲到老板面前，一招大荒囚天指技惊四座。\n\n“你个蠢货，那是只狗！”\n\n##### 反向追责 (Backward Pass)\n\n这个“追责”的过程是**从老板开始，一层一层往下**的：\n\n- **第 1 站：老板 (输出层)**\n  \n  - **你问老板：** “你为什么判断是猫？”\n  \n  - **老板回答：** “因为我的 A 报告 (动物的脸) 和 B 报告 (猫的身体) 都给了充足的论证。我的偏好是更相信 B(猫的身体)。”\n  \n  - **你的指示 (梯度)：** “你（老板）的 **判断** 错了！下次 B (猫的身体) 报告时，你**必须降低对它的信任度** (降低权重)。同时，X (狗的身体) 的报告，你**必须提高信任度** (提高权重)。”\n\n- **第 2 站：部门经理 (隐藏层 N)**\n  \n  - **老板跑去问经理：** “你为什么说那是‘猫的身体’？害我被骂！”\n  \n  - **经理回答：** “因为我的员工的分析，让我更偏向于相信是猫的身体。”\n  \n  - **总教练指示 (梯度)：** “你**判断** 也错了！下次报告时，你**必须降低对它的信任度**。同时，你要更关注狗爪子的报告！”\n  \n  **...... 以此类推，直至最底层**\n\n#### 3. 链式法则 (Chain Rule)\n\n你注意到了吗？**错误的“责任”从顶层传递到了底层。**\n\n- 老板的错误，导致了对经理的“指责”。\n\n- 经理的错误，导致了对员工的“指责”。\n\n- ...\n\n- 这个**指责**的**具体数值（你应该调整多少？）**，在数学上就是**梯度 (Gradient)**。\n\n- 这种**逐层反向传递责任**的数学工具，就是**链式法则 (Chain Rule)**。\n\n#### 4. 全员调整 (Weight Update)\n\n经过这一次秋后算账，公司里的**每一个经理，一直到底层员工（所有神经元）**，都收到了一个具体的“调整指令”：\n\n> “你之前对下属 X 的报告‘偏好’（权重）太高了，下次把它调低 0.05%。”\n> “你之前对下属 Y 的报告‘偏好’太低了，下次把它调高 0.02%。”\n\n**这个过程（决策 -> 犯错 -> 反向追责 -> 全员微调）会重复数百万次。**\n\n最终，这家公司的所有经理都学会了一套极其复杂且精妙的“偏好”（权重），使得他们在下次看到一张“狗”的图片时，能从前台开始，一路正确地传递信息，最终让老板做出正确的决策：“这是狗！”\n\n---\n\n### IV 注意力的革命\n\n在 GPT 出现之前，处理序列数据（如文本、语音）的主流模型是 **RNN (循环神经网络)** 及其变体 **LSTM**。\n\nRNN 的设计很直观：它像人一样，一个词一个词地阅读。它有一个“记忆单元”（Hidden State），在阅读句子:'The cat sat on the floor.'时，在读完“The cat”后，会把'The cat'的信息编码到记忆里，再去读下一个词‘sat’。\n\n但这种设计存在两个致命问题。**首先是长距离依赖和梯度消失**：当句子很长时（“我昨天...（省略50个词）...那只猫”），到处理“猫”时，关于“昨天”的信息（梯度）在“记忆”中已经极其微弱，模型“忘记”了。**其次是串行计算瓶颈**：你必须处理完 `word[n]` 才能处理 `word[n+1]`。这在 GPU 时代是灾难性的，因为 GPU 最擅长的是**并行计算**（同时处理 1000 个 `word`），而 RNN 的设计使其无法利用这一点。\n\n直到 2017 年，一篇论文[《Attention Is All You Need》](https://proceedings.neurips.cc/paper_files/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf)彻底改变了这一切。**Transformer** 模型登场，它做的第一件事就是：**彻底抛弃 RNN 的“循环”结构**。\n\nTransformer 的核心是**自注意力机制 (Self-Attention)**。它的核心思想是：一个句子中的词，其含义不是孤立的，而是由它和句子中所有其他词的关系共同决定的。\n\n> 例子：“The **animal** didn't cross the street because **it** was too tired.”\n\n当模型处理 \"it\" 时，\"it\" 指的是 \"animal\" 还是 \"street\"？RNN 必须依赖其摇摇欲坠的“短期记忆”。而 Self-Attention 允许 \"it\" *直接“看”向* 句子中的所有其他词，并计算一个“注意力得分”。它会发现 \"it\" 和 \"animal\" 的关联性远高于 \"street\"。\n\n那么，Self-Attention 在技术上是如何做到这一点的呢？它为句子中的 每个词 都生成三个不同的向量：\n\n- **Query (Q) 向量：** 代表当前词作为“查询者”的身份。可以理解为：“**我** (it) 是谁？我正在寻找和我相关的东西。”\n\n- **Key (K) 向量：** 代表该词可被“索引”的标签。可以理解为：“我是“animal”，一个可以被指代的名词。”\n\n- **Value (V) 向量：** 代表该词的“真正含义”或“内容”。\n\n整个过程如下（以‘it’为例）：\n\n**首先是打分(Scoring)**：拿 \"it\" 的 **Q 向量**，去和 **句子中所有词**（包括 \"it\" 自己）的 **K** 向量进行**点积** (Dot-Product)。这个点积的结果，就是**相关性得分**。（如果 \"it\" 的 Q 和 \"animal\" 的 K 很接近，得分就高）。\n\n**接着是归一化(Softmax)**：将这些原始得分通过一个 Softmax 函数，将其转换为总和为 1 的“注意力权重”（例如：{ \"The\": 0.05, \"animal\": **0.85**, ..., \"it\": 0.05, ...}）。\n\n**最后是加权求和(Weighted Sum)**：用这些**注意力权重**，去对 句子中所有词 的 **V** 向量进行加权求和。\n\n`Output_for_it = (0.05 * V_The) + (0.85 * V_animal) + ...`\n\n最终的结果是： \"it\" 的原始 V 向量（它自己的含义）被“注入”了 85% 的 \"animal\" 的 V 向量（含义）。模型在这一层就明确知道了 \"it\" 指向 \"animal\"。\n\nTransformer 的革命性在于两个方面。**第一是并行化**：整个 Q-K-V 计算是纯粹的矩阵乘法。GPU 可以 *同时* 计算句子中所有词的 Q/K/V 和注意力得分。这充分运用了设备的算力，使得训练千亿（甚至万亿）参数的巨型模型（LLM）成为可能。**第二是全局依赖**：任何两个词（无论相隔多远）的“距离”都为 1。模型可以轻易捕捉长距离依赖，彻底解决了 RNN 的“遗忘”问题。\n\n---\n\n东拼西凑的一个月，终于完成了🙌\n","slug":"Artificial Intelligence","published":1,"updated":"2025-11-26T13:25:55.684Z","comments":1,"layout":"post","photos":[],"_id":"cuidodTpyy0S0uEWKx9bPDVhe","content":"<p>想了很久，终于有时间来讲讲AI了，些许错误，多多包容</p>\n<hr>\n<h3 id=\"I-人工智能-Artificial-Intelligence-AI\"><a href=\"#I-人工智能-Artificial-Intelligence-AI\" class=\"headerlink\" title=\"I. 人工智能 (Artificial Intelligence,AI)\"></a>I. 人工智能 (Artificial Intelligence,AI)</h3><p>大家都听过的词语，依照维基百科的解释:  <a href=\"https://www.wikiwand.com/en/articles/Artificial_intelligence.com\">人工智能（AI）</a>是指计算系统执行通常与人类智能相关任务的能力，例如学习、推理、解决问题、感知和决策。</p>\n<p>而AI分为 <strong>强AI</strong> 和 <strong>弱AI</strong>：</p>\n<h5 id=\"弱AI-ANI-Artificial-Narrow-Intelligence）\"><a href=\"#弱AI-ANI-Artificial-Narrow-Intelligence）\" class=\"headerlink\" title=\"弱AI(ANI - Artificial Narrow Intelligence）\"></a><strong>弱AI(ANI - Artificial Narrow Intelligence）</strong></h5><p>被设计用来 <strong><strong>解决特定的任务</strong></strong>（如下棋、人脸识别、写代码）。如AlphaGo, Copilot, Siri 均属此类。</p>\n<h5 id=\"强-AI-AGI-Artificial-General-Intelligence\"><a href=\"#强-AI-AGI-Artificial-General-Intelligence\" class=\"headerlink\" title=\"强 AI (AGI - Artificial General Intelligence):\"></a><strong>强 AI (AGI - Artificial General Intelligence):</strong></h5><p>理论上的“通用人工智能”，拥有与人类同等或超越人类的、跨领域的思考和学习能力。类似于天网、终结者的存在，或者说目标，目前尚未实现。</p>\n<p>随着AI的不断发展，也发展出了不同的发展方向，主要是:<strong>机器学习（ML）与专家系统（Expert Systems）</strong></p>\n<hr>\n<h4 id=\"专家系统\"><a href=\"#专家系统\" class=\"headerlink\" title=\"专家系统\"></a><strong>专家系统</strong></h4><p>专家系统是人工智能发展早期出现的一种 <strong>方法</strong>，它属于基于规则的 AI，与现代的机器学习驱动的 AI 有着十分鲜明对比。</p>\n<h6 id=\"核心思想与定义\"><a href=\"#核心思想与定义\" class=\"headerlink\" title=\"核心思想与定义\"></a><strong>核心思想与定义</strong></h6><p>专家系统旨在模拟人类领域专家（如医生、金融分析师）的决策能力和推理过程，通过将人类的专业知识进行形式化编码，来解决复杂、专业性的问题。本质上是一个由程序员编写的，十分庞大，嵌套极深的 <code>if-else</code> 抉择树。</p>\n<h6 id=\"结构\"><a href=\"#结构\" class=\"headerlink\" title=\"结构\"></a>结构</h6><p>一个典型的专家系统由三个关键组成部分构成：</p>\n<h6 id=\"1-知识库-Knowledge-Base\"><a href=\"#1-知识库-Knowledge-Base\" class=\"headerlink\" title=\"1. 知识库 (Knowledge Base)\"></a><strong>1. 知识库 (Knowledge Base)</strong></h6><p>这是专家系统的信息来源，存储了领域专家的所有专业知识。这些知识通常以两种形式存在：</p>\n<ul>\n<li><p><strong>事实 (Facts):</strong> 关于领域的基本信息（例如：“水在100°C 沸腾”）。</p>\n</li>\n<li><p><strong>规则 (Rules):</strong> <strong>条件-行动 (IF-THEN)</strong> 语句，代表专家的经验和推理逻辑。</p>\n<ul>\n<li><em>示例规则：</em> <code>IF (病人有发烧) AND (病人有咳嗽) THEN (推断患有呼吸道感染)</code></li>\n</ul>\n</li>\n</ul>\n<h5 id=\"2-推理机-Inference-Engine\"><a href=\"#2-推理机-Inference-Engine\" class=\"headerlink\" title=\"2. 推理机 (Inference Engine)\"></a><strong>2. 推理机 (Inference Engine)</strong></h5><p>顾名思义，它负责根据用户输入的信息和知识库中的规则进行逻辑推理，得出结论。主要的推理方法有两种：</p>\n<ul>\n<li><p><strong>正向链 (Forward Chaining):</strong> <strong>数据驱动</strong>。从已知事实开始，不断应用规则，直到达到目标或所有规则都被应用。</p>\n<ul>\n<li><em>逻辑：</em> 如果 $A$ 且 $B$ 为真，而我们知道 $A$ 和 $B$ 是真，则 $C$ 为真。</li>\n</ul>\n</li>\n<li><p><strong>反向链 (Backward Chaining):</strong> <strong>目标驱动</strong>。从目标（假设的结论）开始，向后寻找支持该结论的必要事实或子目标。</p>\n<ul>\n<li><em>逻辑：</em> 要证明 $C$，需要 $A$ 和 $B$。那么，先证明 $A$，再证明 $B$。</li>\n</ul>\n</li>\n</ul>\n<h5 id=\"3-用户界面-User-Interface\"><a href=\"#3-用户界面-User-Interface\" class=\"headerlink\" title=\"3. 用户界面 (User Interface)\"></a><strong>3. 用户界面 (User Interface)</strong></h5><p>用于与用户交互,来接收你输入资讯的地方</p>\n<p>相当直观的一种结构，但是简单的代价是会有两个限制和问题：</p>\n<ul>\n<li><p><strong>极其脆弱</strong>：遇到规则之外的情况就崩溃。因此，相关模型多用于特定的领域，如医疗，金融等..</p>\n</li>\n<li><p><strong>无法学习</strong>:你必须手动更新模型的规则以及知识库，维护的成本也大大增加</p>\n</li>\n</ul>\n<hr>\n<h3 id=\"II-机器学习-Machine-Learning-ML\"><a href=\"#II-机器学习-Machine-Learning-ML\" class=\"headerlink\" title=\"II. 机器学习 (Machine Learning, ML)\"></a>II. 机器学习 (Machine Learning, ML)</h3><p>ML 的本质在于，它不再要求开发者为机器硬编码规则，而是让机器从海量数据中<strong>自动学习</strong>（或“拟合”）出最优的映射函数 $f$。</p>\n<h5 id=\"一-严谨的定义与三要素-T-E-P\"><a href=\"#一-严谨的定义与三要素-T-E-P\" class=\"headerlink\" title=\"一. 严谨的定义与三要素 (T, E, P)\"></a>一. 严谨的定义与三要素 (T, E, P)</h5><p>机器学习最被认可的定义来自于计算机科学家 Tom M. Mitchell。他指出，一个程序从经验中学习，必须满足三个要素：</p>\n<table>\n<thead>\n<tr>\n<th><strong>要素</strong></th>\n<th><strong>解释</strong></th>\n<th><strong>案例：垃圾邮件过滤器</strong></th>\n</tr>\n</thead>\n<tbody><tr>\n<td><strong>任务 ($T$ - Task)</strong></td>\n<td>机器需要完成的具体工作，通常是预测或推断。</td>\n<td><strong>分类任务</strong>：将邮件内容 $X$ 分类到 $Y&#x3D;{\\text{“垃圾邮件”}, \\text{“非垃圾邮件”}}$。</td>\n</tr>\n<tr>\n<td><strong>经验 ($E$ - Experience)</strong></td>\n<td>模型用于学习的观测数据。</td>\n<td><strong>数据集</strong>：100 万封邮件，其中每封邮件都已人工标注了正确的标签。</td>\n</tr>\n<tr>\n<td><strong>性能度量 ($P$ - Performance)</strong></td>\n<td>量化模型表现的指标，衡量其预测结果与真实标签的匹配程度。</td>\n<td><strong>准确率 (Accuracy)</strong>：模型正确分类的邮件占总邮件数的百分比。</td>\n</tr>\n</tbody></table>\n<p>这也是机器学习与专家系统的最大不同。专家系统是输入<code>数据</code>+<code>规则</code>，输出<code>答案</code>；而机器学习则是输入<code>数据</code>+<code>答案</code>，输出<code>规则</code>。</p>\n<h5 id=\"二-特征工程-Feature-Engineering\"><a href=\"#二-特征工程-Feature-Engineering\" class=\"headerlink\" title=\"二. 特征工程 (Feature Engineering)\"></a>二. 特征工程 (Feature Engineering)</h5><p>这是将原始数据（如图像像素、原始文本）转换成算法可以理解的、具有信息价值的特征向量的过程，或许能称为“学习”？</p>\n<ol>\n<li>优化与统计</li>\n</ol>\n<p>机器学习的过程，在数学上被定义为一个<strong>最优化问题</strong>。 (读M2震怒 。学习的目标是找到一组最优参数 $\\theta$，使得模型的<strong>损失函数 ($L$)</strong> 最小化。损失函数度量了模型预测 $\\hat{Y}$ 与真实值 $Y$ 之间的差异：</p>\n<p>$$f^* &#x3D; \\underset{f}{\\operatorname{argmin}} L(f(X), Y)$$</p>\n<ul>\n<li><p>$f$: 代表模型（如神经网络、决策树）。</p>\n</li>\n<li><p>$L(f(X), Y)$: <strong>损失函数</strong>，用于度量模型的预测 $f(X)$ 与真实标签 $Y$ 之间的差异。最小化损失是学习的驱动力。</p>\n</li>\n<li><p>$\\operatorname{argmin}$: <strong>最优化操作</strong>，寻找使损失函数 $L$ 达到最小值的模型参数集 $\\theta$。</p>\n</li>\n</ul>\n<ol start=\"2\">\n<li>核心算法：梯度下降 (Gradient Descent)</li>\n</ol>\n<p>大多数 ML 模型（尤其是深度学习）使用梯度下降 (Gradient Descent)及其变种（如 SGD, Adam）来执行优化。大概就是一种数学的计算方式，我不会。</p>\n<blockquote style=\"border-left: 4px solid #ff6b6b; background: #ffe0e0; padding: 15px; margin: 15px 0;\">\n看看得了\n</blockquote>\n\n<p><strong>举个栗子</strong></p>\n<p>例子1：银行贷款违约风险预测</p>\n<table>\n<thead>\n<tr>\n<th><strong>原始特征 (Raw Data)</strong></th>\n<th><strong>领域知识应用（工程操作）</strong></th>\n<th><strong>构造的新特征 (Engineered Feature)</strong></th>\n<th><strong>价值</strong></th>\n</tr>\n</thead>\n<tbody><tr>\n<td><code>年龄</code></td>\n<td>分箱（Binning）</td>\n<td><code>年龄段</code> (例如：[18-25], [26-40], [41-60]…)</td>\n<td>将连续变量转化为离散变量，捕捉不同年龄段客户的风险特性。</td>\n</tr>\n<tr>\n<td><code>信用卡额度</code>、<code>已用额度</code></td>\n<td>运算&#x2F;比率</td>\n<td><code>使用率</code> ($\\text{已用额度} &#x2F; \\text{总额度}$)</td>\n<td>这是比两个独立数值更有力的违约风险信号。高使用率通常意味着高风险。</td>\n</tr>\n<tr>\n<td><code>过去 12 个月的交易笔数</code></td>\n<td>统计</td>\n<td><code>最近 3 个月的平均交易额增长率</code></td>\n<td>捕捉客户近期消费行为的趋势变化，而非简单的总量。</td>\n</tr>\n<tr>\n<td><code>居住城市</code> (类别)</td>\n<td>编码</td>\n<td><code>城市风险评分</code> (基于该城市历史违约率)</td>\n<td>将高维度的类别特征转化为具有预测意义的数值特征。</td>\n</tr>\n</tbody></table>\n<p>案例 2：情绪分析</p>\n<p>客户评论：“这个应用太卡了，但设计很漂亮。”</p>\n<table>\n<thead>\n<tr>\n<th><strong>原始特征</strong></th>\n<th><strong>领域知识应用（工程操作）</strong></th>\n<th><strong>构造的新特征</strong></th>\n<th><strong>价值</strong></th>\n</tr>\n</thead>\n<tbody><tr>\n<td>原始句子</td>\n<td><strong>词袋模型 (Bag-of-Words)</strong> 或 <strong>TF-IDF</strong></td>\n<td><code>“卡”的频率</code>, <code>“漂亮”的权重</code></td>\n<td>将不定长的文本转化为固定长度的数值向量。</td>\n</tr>\n<tr>\n<td>词语</td>\n<td><strong>N-gram 构造</strong></td>\n<td><code>“太卡了”</code> (三元词组)</td>\n<td>捕捉词语的局部顺序和语义，“太卡了”比单独的“卡”更有负面情感。</td>\n</tr>\n<tr>\n<td>情感词典</td>\n<td><strong>计数</strong></td>\n<td><code>负面词汇数量</code>, <code>正面词汇数量</code></td>\n<td>捕捉评论的<strong>情感极性</strong>和<strong>强度</strong>。</td>\n</tr>\n<tr>\n<td>连词</td>\n<td><strong>结构分析</strong></td>\n<td><code>是否存在转折连词 (“但”, “可是”)</code></td>\n<td>“卡但漂亮”表示复杂情绪，模型应区别于“卡且丑陋”。</td>\n</tr>\n</tbody></table>\n<h5 id=\"三、-机器学习的主要任务类型\"><a href=\"#三、-机器学习的主要任务类型\" class=\"headerlink\" title=\"三、 机器学习的主要任务类型\"></a>三、 机器学习的主要任务类型</h5><p>机器学习任务通常根据训练数据的性质和模型目标被划分为三大类：</p>\n<h6 id=\"1-监督学习-Supervised-Learning\"><a href=\"#1-监督学习-Supervised-Learning\" class=\"headerlink\" title=\"1. 监督学习 (Supervised Learning)\"></a>1. 监督学习 (Supervised Learning)</h6><p>监督学习是目前应用最广泛的 ML 类型，类似于有老师手把手教你，即训练数据中的每一个输入 $X$ 都对应一个已知的、正确的输出标签 $Y$。这类算法的目的是学习和逼近输入 $X$ 到输出 $Y$ 的映射函数 $f$，使得对于任何新的输入 $X_{\\text{new}}$，模型能够准确预测其对应的 $\\hat{Y}_{\\text{new}}$。</p>\n<blockquote style=\"border-left: 4px solid #4dabf7; background: #e7f5ff; padding: 15px; margin: 15px 0;\">\n金融预测： 输入经济指标和历史数据，输出连续的未来某商品价格。\n\n<p>住房预测： 输入房屋面积、地理位置等，输出具体的房价数值。</p>\n</blockquote>\n\n<h6 id=\"2-无监督学习-Unsupervised-Learning\"><a href=\"#2-无监督学习-Unsupervised-Learning\" class=\"headerlink\" title=\"2.无监督学习 (Unsupervised Learning)\"></a>2.无监督学习 (Unsupervised Learning)</h6><p>无监督学习就像是让学生自主探索。模型接收的训练数据<strong>只有输入 $X$</strong>，没有标签 $Y$。在此类算法中，模型必须自主地探索数据，找出隐藏在数据中的统计结构、分布等。它不进行预测，而是进行描述和组织。</p>\n<blockquote style=\"border-left: 4px solid #4dabf7; background: #e7f5ff; padding: 15px; margin: 15px 0;\">\n购物分析：发现“如果客户购买了牛奶 (A)，那么他们有 80% 的概率也会购买面包 (B)”。\n</blockquote>\n\n<h6 id=\"3-强化学习-Reinforcement-Learning-RL\"><a href=\"#3-强化学习-Reinforcement-Learning-RL\" class=\"headerlink\" title=\"3.强化学习 (Reinforcement Learning, RL)\"></a>3.<a href=\"https://www.wikiwand.com/en/articles/Reinforcement_learning\">强化学习 (Reinforcement Learning, RL)</a></h6><p><img src= \"data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7\" onerror=\"this.onerror=null,this.src=&quot;/img/404.jpg&quot;\" data-lazy-src=\"https://assets.wikiwand.com/_next/image?url=https://upload.wikimedia.org/wikipedia/commons/thumb/1/1b/Reinforcement_learning_diagram.svg/1100px-Reinforcement_learning_diagram.svg.png&w=828&q=70\" alt=\"https:&#x2F;&#x2F;assets.wikiwand.com&#x2F;_next&#x2F;image?url&#x3D;https:&#x2F;&#x2F;upload.wikimedia.org&#x2F;wikipedia&#x2F;commons&#x2F;thumb&#x2F;1&#x2F;1b&#x2F;Reinforcement_learning_diagram.svg&#x2F;1100px-Reinforcement_learning_diagram.svg.png&amp;w&#x3D;828&amp;q&#x3D;70\"></p>\n<p>强化学习与前两者完全不同，它是一种<strong>基于试错 (Trial-and-Error)</strong> 的学习方法，灵感来源于心理学中的行为主义。</p>\n<p>如果你想让你家的狗学会坐下或叼飞盘，你不会像人类一样让它看书，而是使用<strong>奖励</strong>和<strong>惩罚</strong>来塑造它的行为，这也是强化学习的逻辑。训练机器狗的过程是一个永不停止的、基于<strong>马尔可夫决策过程 (MDP)</strong> 的循环：</p>\n<h4 id=\"步骤-1：观察\"><a href=\"#步骤-1：观察\" class=\"headerlink\" title=\"步骤 1：观察\"></a>步骤 1：观察</h4><p>机器狗环顾四周，确定它在哪里（<strong>状态 $S$</strong>）。</p>\n<ul>\n<li><em>例如：</em> 机器狗知道它在 $(5, 5)$ 位置，并且闻到了前方有食物的气味。</li>\n</ul>\n<h4 id=\"步骤-2：行动\"><a href=\"#步骤-2：行动\" class=\"headerlink\" title=\"步骤 2：行动\"></a>步骤 2：行动</h4><p>机器狗根据它<strong>当前的策略 $\\pi$</strong>（行为准则），决定下一步做什么（<strong>行动 $A$</strong>）。</p>\n<ul>\n<li><em>例如：</em> 机器狗的策略是“闻到食物，就前进”。它执行了“前进”的动作。</li>\n</ul>\n<h4 id=\"步骤-3：反馈与奖励\"><a href=\"#步骤-3：反馈与奖励\" class=\"headerlink\" title=\"步骤 3：反馈与奖励\"></a>步骤 3：反馈与奖励</h4><p>机器狗执行动作后，环境发生变化，并返回反馈：</p>\n<ul>\n<li><p><strong>新状态 $S’$：</strong> 机器狗移动到了 $(6, 5)$ 位置。</p>\n</li>\n<li><p><strong>奖励 $R$：</strong></p>\n<ul>\n<li><p>如果它吃到了食物：$+100$ (奖励)</p>\n</li>\n<li><p>如果它撞到了墙：$-10$ (惩罚)</p>\n</li>\n<li><p>如果它踩到了地雷：$-1000$ (巨大惩罚)</p>\n</li>\n<li><p>如果只是普通移动：$-1$ (微小惩罚)</p>\n</li>\n</ul>\n</li>\n</ul>\n<h4 id=\"步骤-4：更新策略\"><a href=\"#步骤-4：更新策略\" class=\"headerlink\" title=\"步骤 4：更新策略\"></a>步骤 4：更新策略</h4><p>机器狗利用这个反馈（奖励 $R$）来<strong>评估</strong>它刚才的行动好不好，并<strong>调整它的策略 $\\pi$</strong>。</p>\n<ul>\n<li><p><strong>如果 $R$ 为正：</strong> 它知道这个行动是好的，下次在类似状态下会倾向于重复这个行动。</p>\n</li>\n<li><p><strong>如果 $R$ 为负：</strong> 它知道这个行动是坏的，下次在类似状态下会避免这个行动。</p>\n</li>\n</ul>\n<p>这个循环会重复数百万次，机器狗从随机的试错开始，逐步搭建一套最优策略，即：如何避开地雷，并以最快的速度找到最多的食物。</p>\n<hr>\n<h3 id=\"III-深度学习-Deep-Learning-DL\"><a href=\"#III-深度学习-Deep-Learning-DL\" class=\"headerlink\" title=\"III 深度学习 (Deep Learning,DL)\"></a>III 深度学习 (Deep Learning,DL)</h3><p>深度学习属于机器学习的其中一种，是实现机器学习的一种技术。它特指使用一种名为<strong>深度神经网络 (Deep Neural Networks, DNN)</strong> 的特定模型结构来完成学习任务。</p>\n<h5 id=\"说文解字\"><a href=\"#说文解字\" class=\"headerlink\" title=\"说文解字\"></a>说文解字</h5><p>“深”，意为深度，有点像是层级化的特征学习</p>\n<ul>\n<li><p><strong>传统 ML：</strong> 高度依赖人类专家手动设计特征。例如，要识别一张图片中的人脸，你可能需要手动编写代码来检测“眼睛的形状”、“鼻子的比例”、“肤色分布”等特征。</p>\n</li>\n<li><p><strong>深度学习：</strong> 实现了自动化的特征学习。您只需将原始数据（如图像的原始像素）喂给模型，模型会自动在它的“深度”结构中学习到最优特征。</p>\n</li>\n</ul>\n<p>这种叫做<strong>层级化特征学习</strong></p>\n<h5 id=\"举个栗子\"><a href=\"#举个栗子\" class=\"headerlink\" title=\"举个栗子\"></a>举个栗子</h5><p>以图像识别的CNN为例:</p>\n<ul>\n<li><p><strong>Layer 1 (浅层):</strong> 神经网络的第一层会自动学习到最基础的特征，如<code>边缘</code>、<code>角落</code>、简单的<code>颜色块</code>。</p>\n</li>\n<li><p><strong>Layer 2 (中层):</strong> 这一层会组合第一层的简单特征，自动学习到更复杂的形状和纹理，如<code>圆形</code>、<code>网格状</code>、<code>毛发纹理</code>。</p>\n</li>\n<li><p><strong>Layer 3 (深层):</strong> 这一层会组合中层的形状，自动学习到物体的部件，如<code>眼睛</code>、<code>鼻子</code>、<code>汽车轮胎</code>。</p>\n</li>\n<li><p><strong>Output Layer (顶层):</strong> 最终，顶层会组合这些部件，做出最终的分类判断：“这是一张人脸”或“这是一辆汽车”</p>\n</li>\n</ul>\n<p><strong>深度</strong> 指的就是这种特征抽象的层级数量。因为模型会自动学习这些特征，所以它能发现人类工程师难以想到的更优、更抽象的东西。</p>\n<h5 id=\"构成\"><a href=\"#构成\" class=\"headerlink\" title=\"构成\"></a>构成</h5><p>一个<strong>深度神经网络</strong> 由三个部分组成：</p>\n<ol>\n<li><p><strong>输入层 (Input Layer):</strong> 接收原始数据（如图像像素、词向量）。</p>\n</li>\n<li><p><strong>隐藏层 (Hidden Layers):</strong> 这是模型的核心。DNN 至少有两个或更多的隐藏层（通常是几十到几百层）。每一层都由许多<strong>神经元</strong> 组成，每个神经元都会对其输入进行<strong>加权求和</strong>并应用<strong>激活函数</strong>来引入非线性。</p>\n</li>\n<li><p><strong>输出层 (Output Layer):</strong> 生成最终的预测结果（如分类的概率）。</p>\n</li>\n</ol>\n<h5 id=\"主要架构\"><a href=\"#主要架构\" class=\"headerlink\" title=\"主要架构\"></a>主要架构</h5><table>\n<thead>\n<tr>\n<th><strong>架构</strong></th>\n<th><strong>全称</strong></th>\n<th><strong>核心机制</strong></th>\n<th><strong>擅长领域</strong></th>\n</tr>\n</thead>\n<tbody><tr>\n<td><strong>CNN</strong></td>\n<td><strong>卷积神经网络</strong><br>(Convolutional Neural Network)</td>\n<td><strong>卷积核 (Filters)</strong> 与 <strong>参数共享</strong>。</td>\n<td><strong>网格状数据（如图像）</strong>：图像识别、医学影像分析、目标检测。</td>\n</tr>\n<tr>\n<td><strong>RNN</strong></td>\n<td><strong>循环神经网络</strong><br>(Recurrent Neural Network)</td>\n<td><strong>隐藏状态 (Hidden State)</strong> 的循环，用于处理序列。</td>\n<td><strong>序列数据（如文本、时间序列）</strong>：自然语言处理、语音识别。</td>\n</tr>\n<tr>\n<td><strong>LSTM</strong></td>\n<td><strong>长短期记忆网络</strong><br>(Long Short-Term Memory)</td>\n<td>RNN 的变体，使用“门控”机制来解决 RNN 的  <strong>长距离依赖（遗忘</strong>问题。</td>\n<td>复杂的序列任务。</td>\n</tr>\n<tr>\n<td><strong>Transformer</strong></td>\n<td>(无特定全称)</td>\n<td><strong>自注意力机制 (Self-Attention)</strong>。</td>\n<td><strong>现代 NLP 的基石</strong>：GPT-4、BERT 等大型语言模型，以及机器翻译。</td>\n</tr>\n</tbody></table>\n<blockquote style=\"border-left: 4px solid #ff6b6b; background: #ffe0e0; padding: 15px; margin: 15px 0;\">\n以上内容看看得了\n</blockquote>\n\n<p>看不懂是正常的，我们来举个栗子</p>\n<p>让我们把<strong>深度神经网络 (DNN)</strong> 想象为一家公司</p>\n<hr>\n<h3 id=\"第一部分：DNN-的结构-—-公司的层级\"><a href=\"#第一部分：DNN-的结构-—-公司的层级\" class=\"headerlink\" title=\"第一部分：DNN 的结构 — 公司的层级\"></a>第一部分：DNN 的结构 — 公司的层级</h3><h4 id=\"1-输入层-—-前台接待员\"><a href=\"#1-输入层-—-前台接待员\" class=\"headerlink\" title=\"1. 输入层 — 前台接待员\"></a>1. 输入层 — 前台接待员</h4><p>这是公司的前台。当客户（数据）上门时，前台接待员（输入神经元）负责接收最原始、最琐碎的信息。</p>\n<ul>\n<li><p><strong>事件：</strong> 客户给了一张图片。</p>\n</li>\n<li><p><strong>接待员的工作：</strong> 他们不会思考，只是把图片拆解成最基本的信息（比如，每个像素点的颜色值）。</p>\n<ul>\n<li><p>“接待员 1：左上角像素，红色值 255。”</p>\n</li>\n<li><p>“接待员 2：左上角像素，绿色值 100。”</p>\n</li>\n<li><p>…</p>\n</li>\n</ul>\n</li>\n<li><p>输入层只负责<strong>接收原始数据</strong>，并将其传递给下一层。</p>\n</li>\n</ul>\n<h4 id=\"2-隐藏层-—-工作团队\"><a href=\"#2-隐藏层-—-工作团队\" class=\"headerlink\" title=\"2. 隐藏层 — 工作团队\"></a>2. 隐藏层 — 工作团队</h4><p>深度一词的由来。想象每一家公司有很多部门。</p>\n<ul>\n<li><p>假设每一层都是一个部门。</p>\n</li>\n<li><p><strong>工作流程：</strong></p>\n<ul>\n<li><p><strong>层级 1 (部门A)：</strong> 他们从所有“接待员”那里拿到原始像素数据。他们的工作是<strong>识别最简单的模式</strong>。</p>\n<ul>\n<li><p>员工 A：“我发现了一些横向边缘。”</p>\n</li>\n<li><p>员工 B：”我发现了一些垂直线条。”</p>\n</li>\n<li><p>员工 C：“我发现了一块毛茸茸的纹理。”</p>\n</li>\n</ul>\n</li>\n<li><p><strong>层级 2 (部门B)：</strong> 他们不看原始数据，只看部门A的报告。他们的工作是<strong>组合简单模式，形成复杂形状</strong>。</p>\n<ul>\n<li><p>员工 X：”我把<code>边缘 A</code>和<code>纹理 C</code>组合起来，这看起来像一个<code>耳朵</code>的轮廓。”</p>\n</li>\n<li><p>员工 Y：“我把<code>线条 B</code>和另一条线组合，这像<code>胡须</code>。”</p>\n</li>\n</ul>\n</li>\n<li><p><strong>隐藏层 3 (部门C)：</strong> 他们继续组合先前部门的所有报告，形成更复杂的概念。</p>\n<ul>\n<li>员工 P：”我拿到了<code>耳朵</code>、<code>胡须</code>和<code>眼睛</code>的报告，我认为这构成了一张<code>动物的脸</code>。”</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<p><strong>…… 以此类推</strong></p>\n<h4 id=\"3-权重—-经理的偏好\"><a href=\"#3-权重—-经理的偏好\" class=\"headerlink\" title=\"3. 权重— 经理的偏好\"></a>3. 权重— 经理的偏好</h4><p>每个经理在看下属的报告时，都有自己的<strong>偏好（权重）</strong>。</p>\n<ul>\n<li><p>在部门A的经理看来：</p>\n<ul>\n<li><p>下属 A (边缘) 的报告<strong>非常重要</strong> (权重 &#x3D; 0.9)。</p>\n</li>\n<li><p>下属 B (线条) 的报告<strong>不太重要</strong> (权重 &#x3D; 0.1)。</p>\n</li>\n<li><p>下属 C (纹理) 的报告<strong>中等重要</strong> (权重 &#x3D; 0.5)。</p>\n</li>\n</ul>\n</li>\n<li><p>经理会把所有报告的<strong>重要性</strong>加权求和，形成自己的最终判断。</p>\n</li>\n</ul>\n<h4 id=\"4-输出层-—-老板\"><a href=\"#4-输出层-—-老板\" class=\"headerlink\" title=\"4. 输出层 — 老板\"></a>4. 输出层 — 老板</h4><p>这是一家公司的最高层</p>\n<ul>\n<li><p>老板不看任何琐碎细节，只看各部门的最终报告。</p>\n</li>\n<li><p><strong>决策：</strong></p>\n<ul>\n<li><p>A 报告：“我 95% 确定这是一张‘动物的脸’。”</p>\n</li>\n<li><p>B 报告：“我 80% 确定这是‘猫的身体’。”</p>\n</li>\n<li><p>X 报告：“我20%确定是‘狗的身体’。”</p>\n</li>\n</ul>\n</li>\n<li><p>老板综合所有最高层的信息，做出最终的、唯一的决策：“<strong>我宣布，这是猫</strong>。”</p>\n</li>\n</ul>\n<h3 id=\"第二部分：反向传播-—-秋后算账\"><a href=\"#第二部分：反向传播-—-秋后算账\" class=\"headerlink\" title=\"第二部分：反向传播 — 秋后算账\"></a>第二部分：反向传播 — 秋后算账</h3><p>这时候，身为正常人的你下楼一看，糟糕了：</p>\n<ul>\n<li><p>老板：“这是猫！”</p>\n</li>\n<li><p>你：“？？？这不是狗吗？”</p>\n</li>\n</ul>\n<p>现在，公司必须从这个巨大的错误中学习。这就是<strong>反向传播 (Backpropagation)</strong> 的开始，它是一个<strong>追责</strong>和<strong>纠正</strong>的过程。</p>\n<p>生气的你冲到老板面前，一招大荒囚天指技惊四座。</p>\n<p>“你个蠢货，那是只狗！”</p>\n<h5 id=\"反向追责-Backward-Pass\"><a href=\"#反向追责-Backward-Pass\" class=\"headerlink\" title=\"反向追责 (Backward Pass)\"></a>反向追责 (Backward Pass)</h5><p>这个“追责”的过程是<strong>从老板开始，一层一层往下</strong>的：</p>\n<ul>\n<li><p><strong>第 1 站：老板 (输出层)</strong></p>\n<ul>\n<li><p><strong>你问老板：</strong> “你为什么判断是猫？”</p>\n</li>\n<li><p><strong>老板回答：</strong> “因为我的 A 报告 (动物的脸) 和 B 报告 (猫的身体) 都给了充足的论证。我的偏好是更相信 B(猫的身体)。”</p>\n</li>\n<li><p><strong>你的指示 (梯度)：</strong> “你（老板）的 <strong>判断</strong> 错了！下次 B (猫的身体) 报告时，你<strong>必须降低对它的信任度</strong> (降低权重)。同时，X (狗的身体) 的报告，你<strong>必须提高信任度</strong> (提高权重)。”</p>\n</li>\n</ul>\n</li>\n<li><p><strong>第 2 站：部门经理 (隐藏层 N)</strong></p>\n<ul>\n<li><p><strong>老板跑去问经理：</strong> “你为什么说那是‘猫的身体’？害我被骂！”</p>\n</li>\n<li><p><strong>经理回答：</strong> “因为我的员工的分析，让我更偏向于相信是猫的身体。”</p>\n</li>\n<li><p><strong>总教练指示 (梯度)：</strong> “你<strong>判断</strong> 也错了！下次报告时，你<strong>必须降低对它的信任度</strong>。同时，你要更关注狗爪子的报告！”</p>\n</li>\n</ul>\n<p><strong>…… 以此类推，直至最底层</strong></p>\n</li>\n</ul>\n<h4 id=\"3-链式法则-Chain-Rule\"><a href=\"#3-链式法则-Chain-Rule\" class=\"headerlink\" title=\"3. 链式法则 (Chain Rule)\"></a>3. 链式法则 (Chain Rule)</h4><p>你注意到了吗？<strong>错误的“责任”从顶层传递到了底层。</strong></p>\n<ul>\n<li><p>老板的错误，导致了对经理的“指责”。</p>\n</li>\n<li><p>经理的错误，导致了对员工的“指责”。</p>\n</li>\n<li><p>…</p>\n</li>\n<li><p>这个<strong>指责</strong>的<strong>具体数值（你应该调整多少？）</strong>，在数学上就是<strong>梯度 (Gradient)</strong>。</p>\n</li>\n<li><p>这种<strong>逐层反向传递责任</strong>的数学工具，就是<strong>链式法则 (Chain Rule)</strong>。</p>\n</li>\n</ul>\n<h4 id=\"4-全员调整-Weight-Update\"><a href=\"#4-全员调整-Weight-Update\" class=\"headerlink\" title=\"4. 全员调整 (Weight Update)\"></a>4. 全员调整 (Weight Update)</h4><p>经过这一次秋后算账，公司里的<strong>每一个经理，一直到底层员工（所有神经元）</strong>，都收到了一个具体的“调整指令”：</p>\n<blockquote>\n<p>“你之前对下属 X 的报告‘偏好’（权重）太高了，下次把它调低 0.05%。”<br>“你之前对下属 Y 的报告‘偏好’太低了，下次把它调高 0.02%。”</p>\n</blockquote>\n<p><strong>这个过程（决策 -&gt; 犯错 -&gt; 反向追责 -&gt; 全员微调）会重复数百万次。</strong></p>\n<p>最终，这家公司的所有经理都学会了一套极其复杂且精妙的“偏好”（权重），使得他们在下次看到一张“狗”的图片时，能从前台开始，一路正确地传递信息，最终让老板做出正确的决策：“这是狗！”</p>\n<hr>\n<h3 id=\"IV-注意力的革命\"><a href=\"#IV-注意力的革命\" class=\"headerlink\" title=\"IV 注意力的革命\"></a>IV 注意力的革命</h3><p>在 GPT 出现之前，处理序列数据（如文本、语音）的主流模型是 <strong>RNN (循环神经网络)</strong> 及其变体 <strong>LSTM</strong>。</p>\n<p>RNN 的设计很直观：它像人一样，一个词一个词地阅读。它有一个“记忆单元”（Hidden State），在阅读句子:’The cat sat on the floor.’时，在读完“The cat”后，会把’The cat’的信息编码到记忆里，再去读下一个词‘sat’。</p>\n<p>但这种设计存在两个致命问题。<strong>首先是长距离依赖和梯度消失</strong>：当句子很长时（“我昨天…（省略50个词）…那只猫”），到处理“猫”时，关于“昨天”的信息（梯度）在“记忆”中已经极其微弱，模型“忘记”了。<strong>其次是串行计算瓶颈</strong>：你必须处理完 <code>word[n]</code> 才能处理 <code>word[n+1]</code>。这在 GPU 时代是灾难性的，因为 GPU 最擅长的是<strong>并行计算</strong>（同时处理 1000 个 <code>word</code>），而 RNN 的设计使其无法利用这一点。</p>\n<p>直到 2017 年，一篇论文<a href=\"https://proceedings.neurips.cc/paper_files/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf\">《Attention Is All You Need》</a>彻底改变了这一切。<strong>Transformer</strong> 模型登场，它做的第一件事就是：<strong>彻底抛弃 RNN 的“循环”结构</strong>。</p>\n<p>Transformer 的核心是<strong>自注意力机制 (Self-Attention)</strong>。它的核心思想是：一个句子中的词，其含义不是孤立的，而是由它和句子中所有其他词的关系共同决定的。</p>\n<blockquote>\n<p>例子：“The <strong>animal</strong> didn’t cross the street because <strong>it</strong> was too tired.”</p>\n</blockquote>\n<p>当模型处理 “it” 时，”it” 指的是 “animal” 还是 “street”？RNN 必须依赖其摇摇欲坠的“短期记忆”。而 Self-Attention 允许 “it” <em>直接“看”向</em> 句子中的所有其他词，并计算一个“注意力得分”。它会发现 “it” 和 “animal” 的关联性远高于 “street”。</p>\n<p>那么，Self-Attention 在技术上是如何做到这一点的呢？它为句子中的 每个词 都生成三个不同的向量：</p>\n<ul>\n<li><p><strong>Query (Q) 向量：</strong> 代表当前词作为“查询者”的身份。可以理解为：“<strong>我</strong> (it) 是谁？我正在寻找和我相关的东西。”</p>\n</li>\n<li><p><strong>Key (K) 向量：</strong> 代表该词可被“索引”的标签。可以理解为：“我是“animal”，一个可以被指代的名词。”</p>\n</li>\n<li><p><strong>Value (V) 向量：</strong> 代表该词的“真正含义”或“内容”。</p>\n</li>\n</ul>\n<p>整个过程如下（以‘it’为例）：</p>\n<p><strong>首先是打分(Scoring)</strong>：拿 “it” 的 <strong>Q 向量</strong>，去和 <strong>句子中所有词</strong>（包括 “it” 自己）的 <strong>K</strong> 向量进行<strong>点积</strong> (Dot-Product)。这个点积的结果，就是<strong>相关性得分</strong>。（如果 “it” 的 Q 和 “animal” 的 K 很接近，得分就高）。</p>\n<p><strong>接着是归一化(Softmax)</strong>：将这些原始得分通过一个 Softmax 函数，将其转换为总和为 1 的“注意力权重”（例如：{ “The”: 0.05, “animal”: <strong>0.85</strong>, …, “it”: 0.05, …}）。</p>\n<p><strong>最后是加权求和(Weighted Sum)</strong>：用这些<strong>注意力权重</strong>，去对 句子中所有词 的 <strong>V</strong> 向量进行加权求和。</p>\n<p><code>Output_for_it = (0.05 * V_The) + (0.85 * V_animal) + ...</code></p>\n<p>最终的结果是： “it” 的原始 V 向量（它自己的含义）被“注入”了 85% 的 “animal” 的 V 向量（含义）。模型在这一层就明确知道了 “it” 指向 “animal”。</p>\n<p>Transformer 的革命性在于两个方面。<strong>第一是并行化</strong>：整个 Q-K-V 计算是纯粹的矩阵乘法。GPU 可以 <em>同时</em> 计算句子中所有词的 Q&#x2F;K&#x2F;V 和注意力得分。这充分运用了设备的算力，使得训练千亿（甚至万亿）参数的巨型模型（LLM）成为可能。<strong>第二是全局依赖</strong>：任何两个词（无论相隔多远）的“距离”都为 1。模型可以轻易捕捉长距离依赖，彻底解决了 RNN 的“遗忘”问题。</p>\n<hr>\n<p>东拼西凑的一个月，终于完成了🙌</p>\n","cover":false,"excerpt":"","more":"<p>想了很久，终于有时间来讲讲AI了，些许错误，多多包容</p>\n<hr>\n<h3 id=\"I-人工智能-Artificial-Intelligence-AI\"><a href=\"#I-人工智能-Artificial-Intelligence-AI\" class=\"headerlink\" title=\"I. 人工智能 (Artificial Intelligence,AI)\"></a>I. 人工智能 (Artificial Intelligence,AI)</h3><p>大家都听过的词语，依照维基百科的解释:  <a href=\"https://www.wikiwand.com/en/articles/Artificial_intelligence.com\">人工智能（AI）</a>是指计算系统执行通常与人类智能相关任务的能力，例如学习、推理、解决问题、感知和决策。</p>\n<p>而AI分为 <strong>强AI</strong> 和 <strong>弱AI</strong>：</p>\n<h5 id=\"弱AI-ANI-Artificial-Narrow-Intelligence）\"><a href=\"#弱AI-ANI-Artificial-Narrow-Intelligence）\" class=\"headerlink\" title=\"弱AI(ANI - Artificial Narrow Intelligence）\"></a><strong>弱AI(ANI - Artificial Narrow Intelligence）</strong></h5><p>被设计用来 <strong><strong>解决特定的任务</strong></strong>（如下棋、人脸识别、写代码）。如AlphaGo, Copilot, Siri 均属此类。</p>\n<h5 id=\"强-AI-AGI-Artificial-General-Intelligence\"><a href=\"#强-AI-AGI-Artificial-General-Intelligence\" class=\"headerlink\" title=\"强 AI (AGI - Artificial General Intelligence):\"></a><strong>强 AI (AGI - Artificial General Intelligence):</strong></h5><p>理论上的“通用人工智能”，拥有与人类同等或超越人类的、跨领域的思考和学习能力。类似于天网、终结者的存在，或者说目标，目前尚未实现。</p>\n<p>随着AI的不断发展，也发展出了不同的发展方向，主要是:<strong>机器学习（ML）与专家系统（Expert Systems）</strong></p>\n<hr>\n<h4 id=\"专家系统\"><a href=\"#专家系统\" class=\"headerlink\" title=\"专家系统\"></a><strong>专家系统</strong></h4><p>专家系统是人工智能发展早期出现的一种 <strong>方法</strong>，它属于基于规则的 AI，与现代的机器学习驱动的 AI 有着十分鲜明对比。</p>\n<h6 id=\"核心思想与定义\"><a href=\"#核心思想与定义\" class=\"headerlink\" title=\"核心思想与定义\"></a><strong>核心思想与定义</strong></h6><p>专家系统旨在模拟人类领域专家（如医生、金融分析师）的决策能力和推理过程，通过将人类的专业知识进行形式化编码，来解决复杂、专业性的问题。本质上是一个由程序员编写的，十分庞大，嵌套极深的 <code>if-else</code> 抉择树。</p>\n<h6 id=\"结构\"><a href=\"#结构\" class=\"headerlink\" title=\"结构\"></a>结构</h6><p>一个典型的专家系统由三个关键组成部分构成：</p>\n<h6 id=\"1-知识库-Knowledge-Base\"><a href=\"#1-知识库-Knowledge-Base\" class=\"headerlink\" title=\"1. 知识库 (Knowledge Base)\"></a><strong>1. 知识库 (Knowledge Base)</strong></h6><p>这是专家系统的信息来源，存储了领域专家的所有专业知识。这些知识通常以两种形式存在：</p>\n<ul>\n<li><p><strong>事实 (Facts):</strong> 关于领域的基本信息（例如：“水在100°C 沸腾”）。</p>\n</li>\n<li><p><strong>规则 (Rules):</strong> <strong>条件-行动 (IF-THEN)</strong> 语句，代表专家的经验和推理逻辑。</p>\n<ul>\n<li><em>示例规则：</em> <code>IF (病人有发烧) AND (病人有咳嗽) THEN (推断患有呼吸道感染)</code></li>\n</ul>\n</li>\n</ul>\n<h5 id=\"2-推理机-Inference-Engine\"><a href=\"#2-推理机-Inference-Engine\" class=\"headerlink\" title=\"2. 推理机 (Inference Engine)\"></a><strong>2. 推理机 (Inference Engine)</strong></h5><p>顾名思义，它负责根据用户输入的信息和知识库中的规则进行逻辑推理，得出结论。主要的推理方法有两种：</p>\n<ul>\n<li><p><strong>正向链 (Forward Chaining):</strong> <strong>数据驱动</strong>。从已知事实开始，不断应用规则，直到达到目标或所有规则都被应用。</p>\n<ul>\n<li><em>逻辑：</em> 如果 $A$ 且 $B$ 为真，而我们知道 $A$ 和 $B$ 是真，则 $C$ 为真。</li>\n</ul>\n</li>\n<li><p><strong>反向链 (Backward Chaining):</strong> <strong>目标驱动</strong>。从目标（假设的结论）开始，向后寻找支持该结论的必要事实或子目标。</p>\n<ul>\n<li><em>逻辑：</em> 要证明 $C$，需要 $A$ 和 $B$。那么，先证明 $A$，再证明 $B$。</li>\n</ul>\n</li>\n</ul>\n<h5 id=\"3-用户界面-User-Interface\"><a href=\"#3-用户界面-User-Interface\" class=\"headerlink\" title=\"3. 用户界面 (User Interface)\"></a><strong>3. 用户界面 (User Interface)</strong></h5><p>用于与用户交互,来接收你输入资讯的地方</p>\n<p>相当直观的一种结构，但是简单的代价是会有两个限制和问题：</p>\n<ul>\n<li><p><strong>极其脆弱</strong>：遇到规则之外的情况就崩溃。因此，相关模型多用于特定的领域，如医疗，金融等..</p>\n</li>\n<li><p><strong>无法学习</strong>:你必须手动更新模型的规则以及知识库，维护的成本也大大增加</p>\n</li>\n</ul>\n<hr>\n<h3 id=\"II-机器学习-Machine-Learning-ML\"><a href=\"#II-机器学习-Machine-Learning-ML\" class=\"headerlink\" title=\"II. 机器学习 (Machine Learning, ML)\"></a>II. 机器学习 (Machine Learning, ML)</h3><p>ML 的本质在于，它不再要求开发者为机器硬编码规则，而是让机器从海量数据中<strong>自动学习</strong>（或“拟合”）出最优的映射函数 $f$。</p>\n<h5 id=\"一-严谨的定义与三要素-T-E-P\"><a href=\"#一-严谨的定义与三要素-T-E-P\" class=\"headerlink\" title=\"一. 严谨的定义与三要素 (T, E, P)\"></a>一. 严谨的定义与三要素 (T, E, P)</h5><p>机器学习最被认可的定义来自于计算机科学家 Tom M. Mitchell。他指出，一个程序从经验中学习，必须满足三个要素：</p>\n<table>\n<thead>\n<tr>\n<th><strong>要素</strong></th>\n<th><strong>解释</strong></th>\n<th><strong>案例：垃圾邮件过滤器</strong></th>\n</tr>\n</thead>\n<tbody><tr>\n<td><strong>任务 ($T$ - Task)</strong></td>\n<td>机器需要完成的具体工作，通常是预测或推断。</td>\n<td><strong>分类任务</strong>：将邮件内容 $X$ 分类到 $Y&#x3D;{\\text{“垃圾邮件”}, \\text{“非垃圾邮件”}}$。</td>\n</tr>\n<tr>\n<td><strong>经验 ($E$ - Experience)</strong></td>\n<td>模型用于学习的观测数据。</td>\n<td><strong>数据集</strong>：100 万封邮件，其中每封邮件都已人工标注了正确的标签。</td>\n</tr>\n<tr>\n<td><strong>性能度量 ($P$ - Performance)</strong></td>\n<td>量化模型表现的指标，衡量其预测结果与真实标签的匹配程度。</td>\n<td><strong>准确率 (Accuracy)</strong>：模型正确分类的邮件占总邮件数的百分比。</td>\n</tr>\n</tbody></table>\n<p>这也是机器学习与专家系统的最大不同。专家系统是输入<code>数据</code>+<code>规则</code>，输出<code>答案</code>；而机器学习则是输入<code>数据</code>+<code>答案</code>，输出<code>规则</code>。</p>\n<h5 id=\"二-特征工程-Feature-Engineering\"><a href=\"#二-特征工程-Feature-Engineering\" class=\"headerlink\" title=\"二. 特征工程 (Feature Engineering)\"></a>二. 特征工程 (Feature Engineering)</h5><p>这是将原始数据（如图像像素、原始文本）转换成算法可以理解的、具有信息价值的特征向量的过程，或许能称为“学习”？</p>\n<ol>\n<li>优化与统计</li>\n</ol>\n<p>机器学习的过程，在数学上被定义为一个<strong>最优化问题</strong>。 (读M2震怒 。学习的目标是找到一组最优参数 $\\theta$，使得模型的<strong>损失函数 ($L$)</strong> 最小化。损失函数度量了模型预测 $\\hat{Y}$ 与真实值 $Y$ 之间的差异：</p>\n<p>$$f^* &#x3D; \\underset{f}{\\operatorname{argmin}} L(f(X), Y)$$</p>\n<ul>\n<li><p>$f$: 代表模型（如神经网络、决策树）。</p>\n</li>\n<li><p>$L(f(X), Y)$: <strong>损失函数</strong>，用于度量模型的预测 $f(X)$ 与真实标签 $Y$ 之间的差异。最小化损失是学习的驱动力。</p>\n</li>\n<li><p>$\\operatorname{argmin}$: <strong>最优化操作</strong>，寻找使损失函数 $L$ 达到最小值的模型参数集 $\\theta$。</p>\n</li>\n</ul>\n<ol start=\"2\">\n<li>核心算法：梯度下降 (Gradient Descent)</li>\n</ol>\n<p>大多数 ML 模型（尤其是深度学习）使用梯度下降 (Gradient Descent)及其变种（如 SGD, Adam）来执行优化。大概就是一种数学的计算方式，我不会。</p>\n<blockquote style=\"border-left: 4px solid #ff6b6b; background: #ffe0e0; padding: 15px; margin: 15px 0;\">\n看看得了\n</blockquote>\n\n<p><strong>举个栗子</strong></p>\n<p>例子1：银行贷款违约风险预测</p>\n<table>\n<thead>\n<tr>\n<th><strong>原始特征 (Raw Data)</strong></th>\n<th><strong>领域知识应用（工程操作）</strong></th>\n<th><strong>构造的新特征 (Engineered Feature)</strong></th>\n<th><strong>价值</strong></th>\n</tr>\n</thead>\n<tbody><tr>\n<td><code>年龄</code></td>\n<td>分箱（Binning）</td>\n<td><code>年龄段</code> (例如：[18-25], [26-40], [41-60]…)</td>\n<td>将连续变量转化为离散变量，捕捉不同年龄段客户的风险特性。</td>\n</tr>\n<tr>\n<td><code>信用卡额度</code>、<code>已用额度</code></td>\n<td>运算&#x2F;比率</td>\n<td><code>使用率</code> ($\\text{已用额度} &#x2F; \\text{总额度}$)</td>\n<td>这是比两个独立数值更有力的违约风险信号。高使用率通常意味着高风险。</td>\n</tr>\n<tr>\n<td><code>过去 12 个月的交易笔数</code></td>\n<td>统计</td>\n<td><code>最近 3 个月的平均交易额增长率</code></td>\n<td>捕捉客户近期消费行为的趋势变化，而非简单的总量。</td>\n</tr>\n<tr>\n<td><code>居住城市</code> (类别)</td>\n<td>编码</td>\n<td><code>城市风险评分</code> (基于该城市历史违约率)</td>\n<td>将高维度的类别特征转化为具有预测意义的数值特征。</td>\n</tr>\n</tbody></table>\n<p>案例 2：情绪分析</p>\n<p>客户评论：“这个应用太卡了，但设计很漂亮。”</p>\n<table>\n<thead>\n<tr>\n<th><strong>原始特征</strong></th>\n<th><strong>领域知识应用（工程操作）</strong></th>\n<th><strong>构造的新特征</strong></th>\n<th><strong>价值</strong></th>\n</tr>\n</thead>\n<tbody><tr>\n<td>原始句子</td>\n<td><strong>词袋模型 (Bag-of-Words)</strong> 或 <strong>TF-IDF</strong></td>\n<td><code>“卡”的频率</code>, <code>“漂亮”的权重</code></td>\n<td>将不定长的文本转化为固定长度的数值向量。</td>\n</tr>\n<tr>\n<td>词语</td>\n<td><strong>N-gram 构造</strong></td>\n<td><code>“太卡了”</code> (三元词组)</td>\n<td>捕捉词语的局部顺序和语义，“太卡了”比单独的“卡”更有负面情感。</td>\n</tr>\n<tr>\n<td>情感词典</td>\n<td><strong>计数</strong></td>\n<td><code>负面词汇数量</code>, <code>正面词汇数量</code></td>\n<td>捕捉评论的<strong>情感极性</strong>和<strong>强度</strong>。</td>\n</tr>\n<tr>\n<td>连词</td>\n<td><strong>结构分析</strong></td>\n<td><code>是否存在转折连词 (“但”, “可是”)</code></td>\n<td>“卡但漂亮”表示复杂情绪，模型应区别于“卡且丑陋”。</td>\n</tr>\n</tbody></table>\n<h5 id=\"三、-机器学习的主要任务类型\"><a href=\"#三、-机器学习的主要任务类型\" class=\"headerlink\" title=\"三、 机器学习的主要任务类型\"></a>三、 机器学习的主要任务类型</h5><p>机器学习任务通常根据训练数据的性质和模型目标被划分为三大类：</p>\n<h6 id=\"1-监督学习-Supervised-Learning\"><a href=\"#1-监督学习-Supervised-Learning\" class=\"headerlink\" title=\"1. 监督学习 (Supervised Learning)\"></a>1. 监督学习 (Supervised Learning)</h6><p>监督学习是目前应用最广泛的 ML 类型，类似于有老师手把手教你，即训练数据中的每一个输入 $X$ 都对应一个已知的、正确的输出标签 $Y$。这类算法的目的是学习和逼近输入 $X$ 到输出 $Y$ 的映射函数 $f$，使得对于任何新的输入 $X_{\\text{new}}$，模型能够准确预测其对应的 $\\hat{Y}_{\\text{new}}$。</p>\n<blockquote style=\"border-left: 4px solid #4dabf7; background: #e7f5ff; padding: 15px; margin: 15px 0;\">\n金融预测： 输入经济指标和历史数据，输出连续的未来某商品价格。\n\n<p>住房预测： 输入房屋面积、地理位置等，输出具体的房价数值。</p>\n</blockquote>\n\n<h6 id=\"2-无监督学习-Unsupervised-Learning\"><a href=\"#2-无监督学习-Unsupervised-Learning\" class=\"headerlink\" title=\"2.无监督学习 (Unsupervised Learning)\"></a>2.无监督学习 (Unsupervised Learning)</h6><p>无监督学习就像是让学生自主探索。模型接收的训练数据<strong>只有输入 $X$</strong>，没有标签 $Y$。在此类算法中，模型必须自主地探索数据，找出隐藏在数据中的统计结构、分布等。它不进行预测，而是进行描述和组织。</p>\n<blockquote style=\"border-left: 4px solid #4dabf7; background: #e7f5ff; padding: 15px; margin: 15px 0;\">\n购物分析：发现“如果客户购买了牛奶 (A)，那么他们有 80% 的概率也会购买面包 (B)”。\n</blockquote>\n\n<h6 id=\"3-强化学习-Reinforcement-Learning-RL\"><a href=\"#3-强化学习-Reinforcement-Learning-RL\" class=\"headerlink\" title=\"3.强化学习 (Reinforcement Learning, RL)\"></a>3.<a href=\"https://www.wikiwand.com/en/articles/Reinforcement_learning\">强化学习 (Reinforcement Learning, RL)</a></h6><p><img src=\"https://assets.wikiwand.com/_next/image?url=https://upload.wikimedia.org/wikipedia/commons/thumb/1/1b/Reinforcement_learning_diagram.svg/1100px-Reinforcement_learning_diagram.svg.png&w=828&q=70\" alt=\"https:&#x2F;&#x2F;assets.wikiwand.com&#x2F;_next&#x2F;image?url&#x3D;https:&#x2F;&#x2F;upload.wikimedia.org&#x2F;wikipedia&#x2F;commons&#x2F;thumb&#x2F;1&#x2F;1b&#x2F;Reinforcement_learning_diagram.svg&#x2F;1100px-Reinforcement_learning_diagram.svg.png&amp;w&#x3D;828&amp;q&#x3D;70\"></p>\n<p>强化学习与前两者完全不同，它是一种<strong>基于试错 (Trial-and-Error)</strong> 的学习方法，灵感来源于心理学中的行为主义。</p>\n<p>如果你想让你家的狗学会坐下或叼飞盘，你不会像人类一样让它看书，而是使用<strong>奖励</strong>和<strong>惩罚</strong>来塑造它的行为，这也是强化学习的逻辑。训练机器狗的过程是一个永不停止的、基于<strong>马尔可夫决策过程 (MDP)</strong> 的循环：</p>\n<h4 id=\"步骤-1：观察\"><a href=\"#步骤-1：观察\" class=\"headerlink\" title=\"步骤 1：观察\"></a>步骤 1：观察</h4><p>机器狗环顾四周，确定它在哪里（<strong>状态 $S$</strong>）。</p>\n<ul>\n<li><em>例如：</em> 机器狗知道它在 $(5, 5)$ 位置，并且闻到了前方有食物的气味。</li>\n</ul>\n<h4 id=\"步骤-2：行动\"><a href=\"#步骤-2：行动\" class=\"headerlink\" title=\"步骤 2：行动\"></a>步骤 2：行动</h4><p>机器狗根据它<strong>当前的策略 $\\pi$</strong>（行为准则），决定下一步做什么（<strong>行动 $A$</strong>）。</p>\n<ul>\n<li><em>例如：</em> 机器狗的策略是“闻到食物，就前进”。它执行了“前进”的动作。</li>\n</ul>\n<h4 id=\"步骤-3：反馈与奖励\"><a href=\"#步骤-3：反馈与奖励\" class=\"headerlink\" title=\"步骤 3：反馈与奖励\"></a>步骤 3：反馈与奖励</h4><p>机器狗执行动作后，环境发生变化，并返回反馈：</p>\n<ul>\n<li><p><strong>新状态 $S’$：</strong> 机器狗移动到了 $(6, 5)$ 位置。</p>\n</li>\n<li><p><strong>奖励 $R$：</strong></p>\n<ul>\n<li><p>如果它吃到了食物：$+100$ (奖励)</p>\n</li>\n<li><p>如果它撞到了墙：$-10$ (惩罚)</p>\n</li>\n<li><p>如果它踩到了地雷：$-1000$ (巨大惩罚)</p>\n</li>\n<li><p>如果只是普通移动：$-1$ (微小惩罚)</p>\n</li>\n</ul>\n</li>\n</ul>\n<h4 id=\"步骤-4：更新策略\"><a href=\"#步骤-4：更新策略\" class=\"headerlink\" title=\"步骤 4：更新策略\"></a>步骤 4：更新策略</h4><p>机器狗利用这个反馈（奖励 $R$）来<strong>评估</strong>它刚才的行动好不好，并<strong>调整它的策略 $\\pi$</strong>。</p>\n<ul>\n<li><p><strong>如果 $R$ 为正：</strong> 它知道这个行动是好的，下次在类似状态下会倾向于重复这个行动。</p>\n</li>\n<li><p><strong>如果 $R$ 为负：</strong> 它知道这个行动是坏的，下次在类似状态下会避免这个行动。</p>\n</li>\n</ul>\n<p>这个循环会重复数百万次，机器狗从随机的试错开始，逐步搭建一套最优策略，即：如何避开地雷，并以最快的速度找到最多的食物。</p>\n<hr>\n<h3 id=\"III-深度学习-Deep-Learning-DL\"><a href=\"#III-深度学习-Deep-Learning-DL\" class=\"headerlink\" title=\"III 深度学习 (Deep Learning,DL)\"></a>III 深度学习 (Deep Learning,DL)</h3><p>深度学习属于机器学习的其中一种，是实现机器学习的一种技术。它特指使用一种名为<strong>深度神经网络 (Deep Neural Networks, DNN)</strong> 的特定模型结构来完成学习任务。</p>\n<h5 id=\"说文解字\"><a href=\"#说文解字\" class=\"headerlink\" title=\"说文解字\"></a>说文解字</h5><p>“深”，意为深度，有点像是层级化的特征学习</p>\n<ul>\n<li><p><strong>传统 ML：</strong> 高度依赖人类专家手动设计特征。例如，要识别一张图片中的人脸，你可能需要手动编写代码来检测“眼睛的形状”、“鼻子的比例”、“肤色分布”等特征。</p>\n</li>\n<li><p><strong>深度学习：</strong> 实现了自动化的特征学习。您只需将原始数据（如图像的原始像素）喂给模型，模型会自动在它的“深度”结构中学习到最优特征。</p>\n</li>\n</ul>\n<p>这种叫做<strong>层级化特征学习</strong></p>\n<h5 id=\"举个栗子\"><a href=\"#举个栗子\" class=\"headerlink\" title=\"举个栗子\"></a>举个栗子</h5><p>以图像识别的CNN为例:</p>\n<ul>\n<li><p><strong>Layer 1 (浅层):</strong> 神经网络的第一层会自动学习到最基础的特征，如<code>边缘</code>、<code>角落</code>、简单的<code>颜色块</code>。</p>\n</li>\n<li><p><strong>Layer 2 (中层):</strong> 这一层会组合第一层的简单特征，自动学习到更复杂的形状和纹理，如<code>圆形</code>、<code>网格状</code>、<code>毛发纹理</code>。</p>\n</li>\n<li><p><strong>Layer 3 (深层):</strong> 这一层会组合中层的形状，自动学习到物体的部件，如<code>眼睛</code>、<code>鼻子</code>、<code>汽车轮胎</code>。</p>\n</li>\n<li><p><strong>Output Layer (顶层):</strong> 最终，顶层会组合这些部件，做出最终的分类判断：“这是一张人脸”或“这是一辆汽车”</p>\n</li>\n</ul>\n<p><strong>深度</strong> 指的就是这种特征抽象的层级数量。因为模型会自动学习这些特征，所以它能发现人类工程师难以想到的更优、更抽象的东西。</p>\n<h5 id=\"构成\"><a href=\"#构成\" class=\"headerlink\" title=\"构成\"></a>构成</h5><p>一个<strong>深度神经网络</strong> 由三个部分组成：</p>\n<ol>\n<li><p><strong>输入层 (Input Layer):</strong> 接收原始数据（如图像像素、词向量）。</p>\n</li>\n<li><p><strong>隐藏层 (Hidden Layers):</strong> 这是模型的核心。DNN 至少有两个或更多的隐藏层（通常是几十到几百层）。每一层都由许多<strong>神经元</strong> 组成，每个神经元都会对其输入进行<strong>加权求和</strong>并应用<strong>激活函数</strong>来引入非线性。</p>\n</li>\n<li><p><strong>输出层 (Output Layer):</strong> 生成最终的预测结果（如分类的概率）。</p>\n</li>\n</ol>\n<h5 id=\"主要架构\"><a href=\"#主要架构\" class=\"headerlink\" title=\"主要架构\"></a>主要架构</h5><table>\n<thead>\n<tr>\n<th><strong>架构</strong></th>\n<th><strong>全称</strong></th>\n<th><strong>核心机制</strong></th>\n<th><strong>擅长领域</strong></th>\n</tr>\n</thead>\n<tbody><tr>\n<td><strong>CNN</strong></td>\n<td><strong>卷积神经网络</strong><br>(Convolutional Neural Network)</td>\n<td><strong>卷积核 (Filters)</strong> 与 <strong>参数共享</strong>。</td>\n<td><strong>网格状数据（如图像）</strong>：图像识别、医学影像分析、目标检测。</td>\n</tr>\n<tr>\n<td><strong>RNN</strong></td>\n<td><strong>循环神经网络</strong><br>(Recurrent Neural Network)</td>\n<td><strong>隐藏状态 (Hidden State)</strong> 的循环，用于处理序列。</td>\n<td><strong>序列数据（如文本、时间序列）</strong>：自然语言处理、语音识别。</td>\n</tr>\n<tr>\n<td><strong>LSTM</strong></td>\n<td><strong>长短期记忆网络</strong><br>(Long Short-Term Memory)</td>\n<td>RNN 的变体，使用“门控”机制来解决 RNN 的  <strong>长距离依赖（遗忘</strong>问题。</td>\n<td>复杂的序列任务。</td>\n</tr>\n<tr>\n<td><strong>Transformer</strong></td>\n<td>(无特定全称)</td>\n<td><strong>自注意力机制 (Self-Attention)</strong>。</td>\n<td><strong>现代 NLP 的基石</strong>：GPT-4、BERT 等大型语言模型，以及机器翻译。</td>\n</tr>\n</tbody></table>\n<blockquote style=\"border-left: 4px solid #ff6b6b; background: #ffe0e0; padding: 15px; margin: 15px 0;\">\n以上内容看看得了\n</blockquote>\n\n<p>看不懂是正常的，我们来举个栗子</p>\n<p>让我们把<strong>深度神经网络 (DNN)</strong> 想象为一家公司</p>\n<hr>\n<h3 id=\"第一部分：DNN-的结构-—-公司的层级\"><a href=\"#第一部分：DNN-的结构-—-公司的层级\" class=\"headerlink\" title=\"第一部分：DNN 的结构 — 公司的层级\"></a>第一部分：DNN 的结构 — 公司的层级</h3><h4 id=\"1-输入层-—-前台接待员\"><a href=\"#1-输入层-—-前台接待员\" class=\"headerlink\" title=\"1. 输入层 — 前台接待员\"></a>1. 输入层 — 前台接待员</h4><p>这是公司的前台。当客户（数据）上门时，前台接待员（输入神经元）负责接收最原始、最琐碎的信息。</p>\n<ul>\n<li><p><strong>事件：</strong> 客户给了一张图片。</p>\n</li>\n<li><p><strong>接待员的工作：</strong> 他们不会思考，只是把图片拆解成最基本的信息（比如，每个像素点的颜色值）。</p>\n<ul>\n<li><p>“接待员 1：左上角像素，红色值 255。”</p>\n</li>\n<li><p>“接待员 2：左上角像素，绿色值 100。”</p>\n</li>\n<li><p>…</p>\n</li>\n</ul>\n</li>\n<li><p>输入层只负责<strong>接收原始数据</strong>，并将其传递给下一层。</p>\n</li>\n</ul>\n<h4 id=\"2-隐藏层-—-工作团队\"><a href=\"#2-隐藏层-—-工作团队\" class=\"headerlink\" title=\"2. 隐藏层 — 工作团队\"></a>2. 隐藏层 — 工作团队</h4><p>深度一词的由来。想象每一家公司有很多部门。</p>\n<ul>\n<li><p>假设每一层都是一个部门。</p>\n</li>\n<li><p><strong>工作流程：</strong></p>\n<ul>\n<li><p><strong>层级 1 (部门A)：</strong> 他们从所有“接待员”那里拿到原始像素数据。他们的工作是<strong>识别最简单的模式</strong>。</p>\n<ul>\n<li><p>员工 A：“我发现了一些横向边缘。”</p>\n</li>\n<li><p>员工 B：”我发现了一些垂直线条。”</p>\n</li>\n<li><p>员工 C：“我发现了一块毛茸茸的纹理。”</p>\n</li>\n</ul>\n</li>\n<li><p><strong>层级 2 (部门B)：</strong> 他们不看原始数据，只看部门A的报告。他们的工作是<strong>组合简单模式，形成复杂形状</strong>。</p>\n<ul>\n<li><p>员工 X：”我把<code>边缘 A</code>和<code>纹理 C</code>组合起来，这看起来像一个<code>耳朵</code>的轮廓。”</p>\n</li>\n<li><p>员工 Y：“我把<code>线条 B</code>和另一条线组合，这像<code>胡须</code>。”</p>\n</li>\n</ul>\n</li>\n<li><p><strong>隐藏层 3 (部门C)：</strong> 他们继续组合先前部门的所有报告，形成更复杂的概念。</p>\n<ul>\n<li>员工 P：”我拿到了<code>耳朵</code>、<code>胡须</code>和<code>眼睛</code>的报告，我认为这构成了一张<code>动物的脸</code>。”</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<p><strong>…… 以此类推</strong></p>\n<h4 id=\"3-权重—-经理的偏好\"><a href=\"#3-权重—-经理的偏好\" class=\"headerlink\" title=\"3. 权重— 经理的偏好\"></a>3. 权重— 经理的偏好</h4><p>每个经理在看下属的报告时，都有自己的<strong>偏好（权重）</strong>。</p>\n<ul>\n<li><p>在部门A的经理看来：</p>\n<ul>\n<li><p>下属 A (边缘) 的报告<strong>非常重要</strong> (权重 &#x3D; 0.9)。</p>\n</li>\n<li><p>下属 B (线条) 的报告<strong>不太重要</strong> (权重 &#x3D; 0.1)。</p>\n</li>\n<li><p>下属 C (纹理) 的报告<strong>中等重要</strong> (权重 &#x3D; 0.5)。</p>\n</li>\n</ul>\n</li>\n<li><p>经理会把所有报告的<strong>重要性</strong>加权求和，形成自己的最终判断。</p>\n</li>\n</ul>\n<h4 id=\"4-输出层-—-老板\"><a href=\"#4-输出层-—-老板\" class=\"headerlink\" title=\"4. 输出层 — 老板\"></a>4. 输出层 — 老板</h4><p>这是一家公司的最高层</p>\n<ul>\n<li><p>老板不看任何琐碎细节，只看各部门的最终报告。</p>\n</li>\n<li><p><strong>决策：</strong></p>\n<ul>\n<li><p>A 报告：“我 95% 确定这是一张‘动物的脸’。”</p>\n</li>\n<li><p>B 报告：“我 80% 确定这是‘猫的身体’。”</p>\n</li>\n<li><p>X 报告：“我20%确定是‘狗的身体’。”</p>\n</li>\n</ul>\n</li>\n<li><p>老板综合所有最高层的信息，做出最终的、唯一的决策：“<strong>我宣布，这是猫</strong>。”</p>\n</li>\n</ul>\n<h3 id=\"第二部分：反向传播-—-秋后算账\"><a href=\"#第二部分：反向传播-—-秋后算账\" class=\"headerlink\" title=\"第二部分：反向传播 — 秋后算账\"></a>第二部分：反向传播 — 秋后算账</h3><p>这时候，身为正常人的你下楼一看，糟糕了：</p>\n<ul>\n<li><p>老板：“这是猫！”</p>\n</li>\n<li><p>你：“？？？这不是狗吗？”</p>\n</li>\n</ul>\n<p>现在，公司必须从这个巨大的错误中学习。这就是<strong>反向传播 (Backpropagation)</strong> 的开始，它是一个<strong>追责</strong>和<strong>纠正</strong>的过程。</p>\n<p>生气的你冲到老板面前，一招大荒囚天指技惊四座。</p>\n<p>“你个蠢货，那是只狗！”</p>\n<h5 id=\"反向追责-Backward-Pass\"><a href=\"#反向追责-Backward-Pass\" class=\"headerlink\" title=\"反向追责 (Backward Pass)\"></a>反向追责 (Backward Pass)</h5><p>这个“追责”的过程是<strong>从老板开始，一层一层往下</strong>的：</p>\n<ul>\n<li><p><strong>第 1 站：老板 (输出层)</strong></p>\n<ul>\n<li><p><strong>你问老板：</strong> “你为什么判断是猫？”</p>\n</li>\n<li><p><strong>老板回答：</strong> “因为我的 A 报告 (动物的脸) 和 B 报告 (猫的身体) 都给了充足的论证。我的偏好是更相信 B(猫的身体)。”</p>\n</li>\n<li><p><strong>你的指示 (梯度)：</strong> “你（老板）的 <strong>判断</strong> 错了！下次 B (猫的身体) 报告时，你<strong>必须降低对它的信任度</strong> (降低权重)。同时，X (狗的身体) 的报告，你<strong>必须提高信任度</strong> (提高权重)。”</p>\n</li>\n</ul>\n</li>\n<li><p><strong>第 2 站：部门经理 (隐藏层 N)</strong></p>\n<ul>\n<li><p><strong>老板跑去问经理：</strong> “你为什么说那是‘猫的身体’？害我被骂！”</p>\n</li>\n<li><p><strong>经理回答：</strong> “因为我的员工的分析，让我更偏向于相信是猫的身体。”</p>\n</li>\n<li><p><strong>总教练指示 (梯度)：</strong> “你<strong>判断</strong> 也错了！下次报告时，你<strong>必须降低对它的信任度</strong>。同时，你要更关注狗爪子的报告！”</p>\n</li>\n</ul>\n<p><strong>…… 以此类推，直至最底层</strong></p>\n</li>\n</ul>\n<h4 id=\"3-链式法则-Chain-Rule\"><a href=\"#3-链式法则-Chain-Rule\" class=\"headerlink\" title=\"3. 链式法则 (Chain Rule)\"></a>3. 链式法则 (Chain Rule)</h4><p>你注意到了吗？<strong>错误的“责任”从顶层传递到了底层。</strong></p>\n<ul>\n<li><p>老板的错误，导致了对经理的“指责”。</p>\n</li>\n<li><p>经理的错误，导致了对员工的“指责”。</p>\n</li>\n<li><p>…</p>\n</li>\n<li><p>这个<strong>指责</strong>的<strong>具体数值（你应该调整多少？）</strong>，在数学上就是<strong>梯度 (Gradient)</strong>。</p>\n</li>\n<li><p>这种<strong>逐层反向传递责任</strong>的数学工具，就是<strong>链式法则 (Chain Rule)</strong>。</p>\n</li>\n</ul>\n<h4 id=\"4-全员调整-Weight-Update\"><a href=\"#4-全员调整-Weight-Update\" class=\"headerlink\" title=\"4. 全员调整 (Weight Update)\"></a>4. 全员调整 (Weight Update)</h4><p>经过这一次秋后算账，公司里的<strong>每一个经理，一直到底层员工（所有神经元）</strong>，都收到了一个具体的“调整指令”：</p>\n<blockquote>\n<p>“你之前对下属 X 的报告‘偏好’（权重）太高了，下次把它调低 0.05%。”<br>“你之前对下属 Y 的报告‘偏好’太低了，下次把它调高 0.02%。”</p>\n</blockquote>\n<p><strong>这个过程（决策 -&gt; 犯错 -&gt; 反向追责 -&gt; 全员微调）会重复数百万次。</strong></p>\n<p>最终，这家公司的所有经理都学会了一套极其复杂且精妙的“偏好”（权重），使得他们在下次看到一张“狗”的图片时，能从前台开始，一路正确地传递信息，最终让老板做出正确的决策：“这是狗！”</p>\n<hr>\n<h3 id=\"IV-注意力的革命\"><a href=\"#IV-注意力的革命\" class=\"headerlink\" title=\"IV 注意力的革命\"></a>IV 注意力的革命</h3><p>在 GPT 出现之前，处理序列数据（如文本、语音）的主流模型是 <strong>RNN (循环神经网络)</strong> 及其变体 <strong>LSTM</strong>。</p>\n<p>RNN 的设计很直观：它像人一样，一个词一个词地阅读。它有一个“记忆单元”（Hidden State），在阅读句子:’The cat sat on the floor.’时，在读完“The cat”后，会把’The cat’的信息编码到记忆里，再去读下一个词‘sat’。</p>\n<p>但这种设计存在两个致命问题。<strong>首先是长距离依赖和梯度消失</strong>：当句子很长时（“我昨天…（省略50个词）…那只猫”），到处理“猫”时，关于“昨天”的信息（梯度）在“记忆”中已经极其微弱，模型“忘记”了。<strong>其次是串行计算瓶颈</strong>：你必须处理完 <code>word[n]</code> 才能处理 <code>word[n+1]</code>。这在 GPU 时代是灾难性的，因为 GPU 最擅长的是<strong>并行计算</strong>（同时处理 1000 个 <code>word</code>），而 RNN 的设计使其无法利用这一点。</p>\n<p>直到 2017 年，一篇论文<a href=\"https://proceedings.neurips.cc/paper_files/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf\">《Attention Is All You Need》</a>彻底改变了这一切。<strong>Transformer</strong> 模型登场，它做的第一件事就是：<strong>彻底抛弃 RNN 的“循环”结构</strong>。</p>\n<p>Transformer 的核心是<strong>自注意力机制 (Self-Attention)</strong>。它的核心思想是：一个句子中的词，其含义不是孤立的，而是由它和句子中所有其他词的关系共同决定的。</p>\n<blockquote>\n<p>例子：“The <strong>animal</strong> didn’t cross the street because <strong>it</strong> was too tired.”</p>\n</blockquote>\n<p>当模型处理 “it” 时，”it” 指的是 “animal” 还是 “street”？RNN 必须依赖其摇摇欲坠的“短期记忆”。而 Self-Attention 允许 “it” <em>直接“看”向</em> 句子中的所有其他词，并计算一个“注意力得分”。它会发现 “it” 和 “animal” 的关联性远高于 “street”。</p>\n<p>那么，Self-Attention 在技术上是如何做到这一点的呢？它为句子中的 每个词 都生成三个不同的向量：</p>\n<ul>\n<li><p><strong>Query (Q) 向量：</strong> 代表当前词作为“查询者”的身份。可以理解为：“<strong>我</strong> (it) 是谁？我正在寻找和我相关的东西。”</p>\n</li>\n<li><p><strong>Key (K) 向量：</strong> 代表该词可被“索引”的标签。可以理解为：“我是“animal”，一个可以被指代的名词。”</p>\n</li>\n<li><p><strong>Value (V) 向量：</strong> 代表该词的“真正含义”或“内容”。</p>\n</li>\n</ul>\n<p>整个过程如下（以‘it’为例）：</p>\n<p><strong>首先是打分(Scoring)</strong>：拿 “it” 的 <strong>Q 向量</strong>，去和 <strong>句子中所有词</strong>（包括 “it” 自己）的 <strong>K</strong> 向量进行<strong>点积</strong> (Dot-Product)。这个点积的结果，就是<strong>相关性得分</strong>。（如果 “it” 的 Q 和 “animal” 的 K 很接近，得分就高）。</p>\n<p><strong>接着是归一化(Softmax)</strong>：将这些原始得分通过一个 Softmax 函数，将其转换为总和为 1 的“注意力权重”（例如：{ “The”: 0.05, “animal”: <strong>0.85</strong>, …, “it”: 0.05, …}）。</p>\n<p><strong>最后是加权求和(Weighted Sum)</strong>：用这些<strong>注意力权重</strong>，去对 句子中所有词 的 <strong>V</strong> 向量进行加权求和。</p>\n<p><code>Output_for_it = (0.05 * V_The) + (0.85 * V_animal) + ...</code></p>\n<p>最终的结果是： “it” 的原始 V 向量（它自己的含义）被“注入”了 85% 的 “animal” 的 V 向量（含义）。模型在这一层就明确知道了 “it” 指向 “animal”。</p>\n<p>Transformer 的革命性在于两个方面。<strong>第一是并行化</strong>：整个 Q-K-V 计算是纯粹的矩阵乘法。GPU 可以 <em>同时</em> 计算句子中所有词的 Q&#x2F;K&#x2F;V 和注意力得分。这充分运用了设备的算力，使得训练千亿（甚至万亿）参数的巨型模型（LLM）成为可能。<strong>第二是全局依赖</strong>：任何两个词（无论相隔多远）的“距离”都为 1。模型可以轻易捕捉长距离依赖，彻底解决了 RNN 的“遗忘”问题。</p>\n<hr>\n<p>东拼西凑的一个月，终于完成了🙌</p>\n"},{"title":"Hello World","top_img":false,"_content":"Welcome to [Hexo](https://hexo.io/)! This is your very first post. Check [documentation](https://hexo.io/docs/) for more info. If you get any problems when using Hexo, you can find the answer in [troubleshooting](https://hexo.io/docs/troubleshooting.html) or you can ask me on [GitHub](https://github.com/hexojs/hexo/issues).\n\n## Quick Start\n\n### Create a new post\n\n``` bash\n$ hexo new \"My New Post\"\n```\n\nMore info: [Writing](https://hexo.io/docs/writing.html)\n\n### Run server\n\n``` bash\n$ hexo server\n```\n\nMore info: [Server](https://hexo.io/docs/server.html)\n\n### Generate static files\n\n``` bash\n$ hexo generate\n```\n\nMore info: [Generating](https://hexo.io/docs/generating.html)\n\n### Deploy to remote sites\n\n``` bash\n$ hexo deploy\n```\n\nMore info: [Deployment](https://hexo.io/docs/one-command-deployment.html)\n","source":"_posts/hello-world.md","raw":"---\ntitle: Hello World\ntop_img: false\n---\nWelcome to [Hexo](https://hexo.io/)! This is your very first post. Check [documentation](https://hexo.io/docs/) for more info. If you get any problems when using Hexo, you can find the answer in [troubleshooting](https://hexo.io/docs/troubleshooting.html) or you can ask me on [GitHub](https://github.com/hexojs/hexo/issues).\n\n## Quick Start\n\n### Create a new post\n\n``` bash\n$ hexo new \"My New Post\"\n```\n\nMore info: [Writing](https://hexo.io/docs/writing.html)\n\n### Run server\n\n``` bash\n$ hexo server\n```\n\nMore info: [Server](https://hexo.io/docs/server.html)\n\n### Generate static files\n\n``` bash\n$ hexo generate\n```\n\nMore info: [Generating](https://hexo.io/docs/generating.html)\n\n### Deploy to remote sites\n\n``` bash\n$ hexo deploy\n```\n\nMore info: [Deployment](https://hexo.io/docs/one-command-deployment.html)\n","slug":"hello-world","published":1,"date":"2025-11-26T12:51:21.743Z","updated":"2025-11-26T13:42:00.477Z","comments":1,"layout":"post","photos":[],"_id":"cuidUD8V6OMm2H9HlLVaEVoml","content":"<p>Welcome to <a href=\"https://hexo.io/\">Hexo</a>! This is your very first post. Check <a href=\"https://hexo.io/docs/\">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href=\"https://hexo.io/docs/troubleshooting.html\">troubleshooting</a> or you can ask me on <a href=\"https://github.com/hexojs/hexo/issues\">GitHub</a>.</p>\n<h2 id=\"Quick-Start\"><a href=\"#Quick-Start\" class=\"headerlink\" title=\"Quick Start\"></a>Quick Start</h2><h3 id=\"Create-a-new-post\"><a href=\"#Create-a-new-post\" class=\"headerlink\" title=\"Create a new post\"></a>Create a new post</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ hexo new <span class=\"string\">&quot;My New Post&quot;</span></span><br></pre></td></tr></table></figure>\n\n<p>More info: <a href=\"https://hexo.io/docs/writing.html\">Writing</a></p>\n<h3 id=\"Run-server\"><a href=\"#Run-server\" class=\"headerlink\" title=\"Run server\"></a>Run server</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ hexo server</span><br></pre></td></tr></table></figure>\n\n<p>More info: <a href=\"https://hexo.io/docs/server.html\">Server</a></p>\n<h3 id=\"Generate-static-files\"><a href=\"#Generate-static-files\" class=\"headerlink\" title=\"Generate static files\"></a>Generate static files</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ hexo generate</span><br></pre></td></tr></table></figure>\n\n<p>More info: <a href=\"https://hexo.io/docs/generating.html\">Generating</a></p>\n<h3 id=\"Deploy-to-remote-sites\"><a href=\"#Deploy-to-remote-sites\" class=\"headerlink\" title=\"Deploy to remote sites\"></a>Deploy to remote sites</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ hexo deploy</span><br></pre></td></tr></table></figure>\n\n<p>More info: <a href=\"https://hexo.io/docs/one-command-deployment.html\">Deployment</a></p>\n","cover":false,"excerpt":"","more":"<p>Welcome to <a href=\"https://hexo.io/\">Hexo</a>! This is your very first post. Check <a href=\"https://hexo.io/docs/\">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href=\"https://hexo.io/docs/troubleshooting.html\">troubleshooting</a> or you can ask me on <a href=\"https://github.com/hexojs/hexo/issues\">GitHub</a>.</p>\n<h2 id=\"Quick-Start\"><a href=\"#Quick-Start\" class=\"headerlink\" title=\"Quick Start\"></a>Quick Start</h2><h3 id=\"Create-a-new-post\"><a href=\"#Create-a-new-post\" class=\"headerlink\" title=\"Create a new post\"></a>Create a new post</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ hexo new <span class=\"string\">&quot;My New Post&quot;</span></span><br></pre></td></tr></table></figure>\n\n<p>More info: <a href=\"https://hexo.io/docs/writing.html\">Writing</a></p>\n<h3 id=\"Run-server\"><a href=\"#Run-server\" class=\"headerlink\" title=\"Run server\"></a>Run server</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ hexo server</span><br></pre></td></tr></table></figure>\n\n<p>More info: <a href=\"https://hexo.io/docs/server.html\">Server</a></p>\n<h3 id=\"Generate-static-files\"><a href=\"#Generate-static-files\" class=\"headerlink\" title=\"Generate static files\"></a>Generate static files</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ hexo generate</span><br></pre></td></tr></table></figure>\n\n<p>More info: <a href=\"https://hexo.io/docs/generating.html\">Generating</a></p>\n<h3 id=\"Deploy-to-remote-sites\"><a href=\"#Deploy-to-remote-sites\" class=\"headerlink\" title=\"Deploy to remote sites\"></a>Deploy to remote sites</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ hexo deploy</span><br></pre></td></tr></table></figure>\n\n<p>More info: <a href=\"https://hexo.io/docs/one-command-deployment.html\">Deployment</a></p>\n"},{"title":"浅谈解锁bootloader与背后的原理","published":1,"description":"讲讲我们俗称\"解bl\"的背后原理","image":"","draft":false,"lang":"","top_img":false,"_content":"\n## Boot Rom\n\n![高通平台启动流程](https://cdn.jsdelivr.net/gh/Cooper1896/MyPic/68b1859c50416_1756464540.webp)\n\n<center>高通平台启动流程</center>\n\n根据流程图可以看见，在设备通电后，会首先运行PBL(Primary Boot Loader)。此时CPU会从固定地址(如ROM)执行Boot Rom代码[^1]，初始化最低级的硬件(如时钟,CPU核心等)。之后他会加载SBL(Secondary Boot Loader)到SRAM，并使用Root of trust公钥来验证SBL的签名。\n\n---\n\n## PBL(XBL或者SBL)\n\n这部分便是今天要讲的重点——Bootloader。他主要的流程如下：\n\n```\n读取Boot Mode->\n初始化启动接口(UFS,USB,eMMC,NAND)->\n读取下一阶段镜像->\n验证数字签名(RSA+SHA-256)->\n├─ 验证通过 → 加载 SBL 并跳转 \n└─ 验证失败 → 进入 Download Mode（刷机接口）\n```\n\n显而易见，PBL的目标是最大化保护设备的安全，以下简单讲几个有关的安全机制:\n\n- 签名验证(**Signature Verification**)\n  \n  - 让所有要启动的 Next-stage Bootloader (SBL/XBL) 都必须经过OEM Key的签名验证\n\n- 防回滚(**Rollback Protection**)\n  \n  - 防止刷入低于eFuse记录版本的固件\n    这也是为什么，即使你有官方签名的旧版本固件，也无法手动刷入。这是因为其版本号低于eFuse中记录的版本，PBL拒绝了该镜像的加载\n\n- 安全模式入口(EDL/Download Mode)限制\n  \n  - 大多OEM厂商都会限制安全模式入口。限制后，新版设备可能需要配合授权服务器（如 Mi Auth、Samsung KNOX）才能刷机，PBL 会要求 PC 工具和 OEM 服务器握手，验证授权 Token。\n  - 这也是为什么售后能帮你刷机降级。员工会使用公司提供的PC工具，验证其员工身份，得到授权后可以进入该模式进行刷机。但由于内部内鬼等原因，时不时会有内部Token放出来出售(点名表扬小米😅)\n\n你会发现，在流程中，他会验证镜像是否经过OEM/厂家的签名认证。\n\n这意味着——无论你使用什么刷机工具(Fastboot、MiFlash等)去刷入固件，最终能否启动，取决于PBL是否认可该镜像的签名。\n\n这也是为什么你要在解锁Bootloader后，才能刷入第三方ROM。\n\n### PBL与Bootloader锁\n\nBootloader的锁定状态是由eFuse/OTP(One-Time Programmable Memory)记录，在PBL启动时会读取这些硬件熔丝位(Fuse Bits)\n\n在寄存器中一般会记录一下信息:\n\n- `BOOT_UNLOCK`:表示当前解锁状态(0 = Locked, 1 = Unlocked)\n- `OEM_KEY_HASH`:厂商公钥的哈希值，用于签名验证\n- `ANTI-ROLLBACK_VER`:防回滚版本号。用于验证镜像版本，确保镜像版本 ≥ eFuse版本，防止降级到存在漏洞的固件。\n\n#### 解锁Bootloader流程\n\n以 Android + Qualcomm SoC 为例：\n\n1. 用户通过 `fastboot oem unlock` 发送解锁命令。\n2. Fastboot 模式下的 **Secondary Bootloader（SBL/XBL）** 会请求用户确认（擦除数据）。\n3. SBL/XBL 向 **Qualcomm Secure Execution Environment（QSEE, TrustZone）** 发送解锁请求。\n4. QSEE 调用 **PBL 对接的安全熔丝编程接口**（OEM 控制）烧录 `BOOT_UNLOCK=1`。\n5. 解锁完成， PBL 在启动链中会跳过 OEM Key 验证，或者采用开发者密钥（用于允许第三方镜像）。\n\n:::note\nPBL 自身不会被修改，但它的行为会因熔丝位（Fuse Bit）的状态而改变。\n:::\n\n---\n\n## 熔断机制\n\n个人觉得熔断机制挺有趣的，简单讲讲:\n\n> 在硅片集成电路内部，设计了由薄金属或多晶硅工艺实现的特殊可控连线。这条连线在出厂时是导通的，芯片运行时可通过高电压/电流或激光能量将其永久断开（或改变其物理状态），从而记录一个“1”或“0”的状态。\n\n基于其是在物理层面的熔断，因此无法恢复。\n比如**Samsung Knox**\n\n### Samsung Knox\n\n#### 流程\n\n以Bootloader解锁为例:\n\n1. 用户在 **Download Mode** 下选择 “OEM Unlock” 并确认\n\n2. 当前运行在 SBL（或 ABL）阶段的 Bootloader 向 TrustZone Secure Monitor 发起 **SMC（Secure Monitor Call）** 请求：\n   \n   ```c\n   `smc_call(SMC_CMD_BLOW_FUSE, KNOX_WARRANTY_BIT_ID);`\n   ```\n\n3. TrustZone 内的安全固件（TZSW）通过 **eFuse Controller** 选中对应的熔丝行列地址\n\n4. 硬件打开 **VPP 高压电源轨**（通常在芯片设计时是隔离状态，只在安全状态下可用，防止自己电自己）\n\n5. 在一个很短的时间内向该熔丝单元施加大电流/高压\n\n6. 熔丝链路永久断开（熔断），逻辑状态从 0 → 1\n\n7. 把新状态Latch到一个只读寄存器（Boot ROM 在每次启动时读取）\n\n恭喜你！你的手机将会....\n- Samsung Pay/Samsung Pass 永久不可用\n- 安全文件夹功能无法使用\n- 保修失效\n  ...\n\n\n:::note\n理论上可以烧写另一个位表示重新锁定（部分 SoC 采用双位方案 LOCK/UNLOCK），但是我不懂捏\n:::\n\n:::important\n如果你打算购入Samsung的二手机，需要注意这一点，以免一失足成千古恨。\n:::\n\nend~😌\n\n[^1]: 这段Boot Rom代码写死在SoC内部的Mask Rom里，无法更改。\n\n","source":"_posts/unlocked_bl_sh.md","raw":"---\ntitle: 浅谈解锁bootloader与背后的原理\npublished: 2025-08-29\ndescription: '讲讲我们俗称\"解bl\"的背后原理'\nimage: ''\ntags: [Bootloader/解锁]\ncategory: '杂谈'\ndraft: false \nlang: ''\ntop_img: false\n---\n\n## Boot Rom\n\n![高通平台启动流程](https://cdn.jsdelivr.net/gh/Cooper1896/MyPic/68b1859c50416_1756464540.webp)\n\n<center>高通平台启动流程</center>\n\n根据流程图可以看见，在设备通电后，会首先运行PBL(Primary Boot Loader)。此时CPU会从固定地址(如ROM)执行Boot Rom代码[^1]，初始化最低级的硬件(如时钟,CPU核心等)。之后他会加载SBL(Secondary Boot Loader)到SRAM，并使用Root of trust公钥来验证SBL的签名。\n\n---\n\n## PBL(XBL或者SBL)\n\n这部分便是今天要讲的重点——Bootloader。他主要的流程如下：\n\n```\n读取Boot Mode->\n初始化启动接口(UFS,USB,eMMC,NAND)->\n读取下一阶段镜像->\n验证数字签名(RSA+SHA-256)->\n├─ 验证通过 → 加载 SBL 并跳转 \n└─ 验证失败 → 进入 Download Mode（刷机接口）\n```\n\n显而易见，PBL的目标是最大化保护设备的安全，以下简单讲几个有关的安全机制:\n\n- 签名验证(**Signature Verification**)\n  \n  - 让所有要启动的 Next-stage Bootloader (SBL/XBL) 都必须经过OEM Key的签名验证\n\n- 防回滚(**Rollback Protection**)\n  \n  - 防止刷入低于eFuse记录版本的固件\n    这也是为什么，即使你有官方签名的旧版本固件，也无法手动刷入。这是因为其版本号低于eFuse中记录的版本，PBL拒绝了该镜像的加载\n\n- 安全模式入口(EDL/Download Mode)限制\n  \n  - 大多OEM厂商都会限制安全模式入口。限制后，新版设备可能需要配合授权服务器（如 Mi Auth、Samsung KNOX）才能刷机，PBL 会要求 PC 工具和 OEM 服务器握手，验证授权 Token。\n  - 这也是为什么售后能帮你刷机降级。员工会使用公司提供的PC工具，验证其员工身份，得到授权后可以进入该模式进行刷机。但由于内部内鬼等原因，时不时会有内部Token放出来出售(点名表扬小米😅)\n\n你会发现，在流程中，他会验证镜像是否经过OEM/厂家的签名认证。\n\n这意味着——无论你使用什么刷机工具(Fastboot、MiFlash等)去刷入固件，最终能否启动，取决于PBL是否认可该镜像的签名。\n\n这也是为什么你要在解锁Bootloader后，才能刷入第三方ROM。\n\n### PBL与Bootloader锁\n\nBootloader的锁定状态是由eFuse/OTP(One-Time Programmable Memory)记录，在PBL启动时会读取这些硬件熔丝位(Fuse Bits)\n\n在寄存器中一般会记录一下信息:\n\n- `BOOT_UNLOCK`:表示当前解锁状态(0 = Locked, 1 = Unlocked)\n- `OEM_KEY_HASH`:厂商公钥的哈希值，用于签名验证\n- `ANTI-ROLLBACK_VER`:防回滚版本号。用于验证镜像版本，确保镜像版本 ≥ eFuse版本，防止降级到存在漏洞的固件。\n\n#### 解锁Bootloader流程\n\n以 Android + Qualcomm SoC 为例：\n\n1. 用户通过 `fastboot oem unlock` 发送解锁命令。\n2. Fastboot 模式下的 **Secondary Bootloader（SBL/XBL）** 会请求用户确认（擦除数据）。\n3. SBL/XBL 向 **Qualcomm Secure Execution Environment（QSEE, TrustZone）** 发送解锁请求。\n4. QSEE 调用 **PBL 对接的安全熔丝编程接口**（OEM 控制）烧录 `BOOT_UNLOCK=1`。\n5. 解锁完成， PBL 在启动链中会跳过 OEM Key 验证，或者采用开发者密钥（用于允许第三方镜像）。\n\n:::note\nPBL 自身不会被修改，但它的行为会因熔丝位（Fuse Bit）的状态而改变。\n:::\n\n---\n\n## 熔断机制\n\n个人觉得熔断机制挺有趣的，简单讲讲:\n\n> 在硅片集成电路内部，设计了由薄金属或多晶硅工艺实现的特殊可控连线。这条连线在出厂时是导通的，芯片运行时可通过高电压/电流或激光能量将其永久断开（或改变其物理状态），从而记录一个“1”或“0”的状态。\n\n基于其是在物理层面的熔断，因此无法恢复。\n比如**Samsung Knox**\n\n### Samsung Knox\n\n#### 流程\n\n以Bootloader解锁为例:\n\n1. 用户在 **Download Mode** 下选择 “OEM Unlock” 并确认\n\n2. 当前运行在 SBL（或 ABL）阶段的 Bootloader 向 TrustZone Secure Monitor 发起 **SMC（Secure Monitor Call）** 请求：\n   \n   ```c\n   `smc_call(SMC_CMD_BLOW_FUSE, KNOX_WARRANTY_BIT_ID);`\n   ```\n\n3. TrustZone 内的安全固件（TZSW）通过 **eFuse Controller** 选中对应的熔丝行列地址\n\n4. 硬件打开 **VPP 高压电源轨**（通常在芯片设计时是隔离状态，只在安全状态下可用，防止自己电自己）\n\n5. 在一个很短的时间内向该熔丝单元施加大电流/高压\n\n6. 熔丝链路永久断开（熔断），逻辑状态从 0 → 1\n\n7. 把新状态Latch到一个只读寄存器（Boot ROM 在每次启动时读取）\n\n恭喜你！你的手机将会....\n- Samsung Pay/Samsung Pass 永久不可用\n- 安全文件夹功能无法使用\n- 保修失效\n  ...\n\n\n:::note\n理论上可以烧写另一个位表示重新锁定（部分 SoC 采用双位方案 LOCK/UNLOCK），但是我不懂捏\n:::\n\n:::important\n如果你打算购入Samsung的二手机，需要注意这一点，以免一失足成千古恨。\n:::\n\nend~😌\n\n[^1]: 这段Boot Rom代码写死在SoC内部的Mask Rom里，无法更改。\n\n","slug":"unlocked_bl_sh","date":"2025-11-26T12:54:25.161Z","updated":"2025-11-26T13:25:55.684Z","comments":1,"layout":"post","photos":[],"_id":"cuid-38_HDRioCInDnQAZUhrS","content":"<h2 id=\"Boot-Rom\"><a href=\"#Boot-Rom\" class=\"headerlink\" title=\"Boot Rom\"></a>Boot Rom</h2><p><img src= \"data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7\" onerror=\"this.onerror=null,this.src=&quot;/img/404.jpg&quot;\" data-lazy-src=\"https://cdn.jsdelivr.net/gh/Cooper1896/MyPic/68b1859c50416_1756464540.webp\" alt=\"高通平台启动流程\"></p>\n<center>高通平台启动流程</center>\n\n<p>根据流程图可以看见，在设备通电后，会首先运行PBL(Primary Boot Loader)。此时CPU会从固定地址(如ROM)执行Boot Rom代码[^1]，初始化最低级的硬件(如时钟,CPU核心等)。之后他会加载SBL(Secondary Boot Loader)到SRAM，并使用Root of trust公钥来验证SBL的签名。</p>\n<hr>\n<h2 id=\"PBL-XBL或者SBL\"><a href=\"#PBL-XBL或者SBL\" class=\"headerlink\" title=\"PBL(XBL或者SBL)\"></a>PBL(XBL或者SBL)</h2><p>这部分便是今天要讲的重点——Bootloader。他主要的流程如下：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">读取Boot Mode-&gt;</span><br><span class=\"line\">初始化启动接口(UFS,USB,eMMC,NAND)-&gt;</span><br><span class=\"line\">读取下一阶段镜像-&gt;</span><br><span class=\"line\">验证数字签名(RSA+SHA-256)-&gt;</span><br><span class=\"line\">├─ 验证通过 → 加载 SBL 并跳转 </span><br><span class=\"line\">└─ 验证失败 → 进入 Download Mode（刷机接口）</span><br></pre></td></tr></table></figure>\n\n<p>显而易见，PBL的目标是最大化保护设备的安全，以下简单讲几个有关的安全机制:</p>\n<ul>\n<li><p>签名验证(<strong>Signature Verification</strong>)</p>\n<ul>\n<li>让所有要启动的 Next-stage Bootloader (SBL&#x2F;XBL) 都必须经过OEM Key的签名验证</li>\n</ul>\n</li>\n<li><p>防回滚(<strong>Rollback Protection</strong>)</p>\n<ul>\n<li>防止刷入低于eFuse记录版本的固件<br>这也是为什么，即使你有官方签名的旧版本固件，也无法手动刷入。这是因为其版本号低于eFuse中记录的版本，PBL拒绝了该镜像的加载</li>\n</ul>\n</li>\n<li><p>安全模式入口(EDL&#x2F;Download Mode)限制</p>\n<ul>\n<li>大多OEM厂商都会限制安全模式入口。限制后，新版设备可能需要配合授权服务器（如 Mi Auth、Samsung KNOX）才能刷机，PBL 会要求 PC 工具和 OEM 服务器握手，验证授权 Token。</li>\n<li>这也是为什么售后能帮你刷机降级。员工会使用公司提供的PC工具，验证其员工身份，得到授权后可以进入该模式进行刷机。但由于内部内鬼等原因，时不时会有内部Token放出来出售(点名表扬小米😅)</li>\n</ul>\n</li>\n</ul>\n<p>你会发现，在流程中，他会验证镜像是否经过OEM&#x2F;厂家的签名认证。</p>\n<p>这意味着——无论你使用什么刷机工具(Fastboot、MiFlash等)去刷入固件，最终能否启动，取决于PBL是否认可该镜像的签名。</p>\n<p>这也是为什么你要在解锁Bootloader后，才能刷入第三方ROM。</p>\n<h3 id=\"PBL与Bootloader锁\"><a href=\"#PBL与Bootloader锁\" class=\"headerlink\" title=\"PBL与Bootloader锁\"></a>PBL与Bootloader锁</h3><p>Bootloader的锁定状态是由eFuse&#x2F;OTP(One-Time Programmable Memory)记录，在PBL启动时会读取这些硬件熔丝位(Fuse Bits)</p>\n<p>在寄存器中一般会记录一下信息:</p>\n<ul>\n<li><code>BOOT_UNLOCK</code>:表示当前解锁状态(0 &#x3D; Locked, 1 &#x3D; Unlocked)</li>\n<li><code>OEM_KEY_HASH</code>:厂商公钥的哈希值，用于签名验证</li>\n<li><code>ANTI-ROLLBACK_VER</code>:防回滚版本号。用于验证镜像版本，确保镜像版本 ≥ eFuse版本，防止降级到存在漏洞的固件。</li>\n</ul>\n<h4 id=\"解锁Bootloader流程\"><a href=\"#解锁Bootloader流程\" class=\"headerlink\" title=\"解锁Bootloader流程\"></a>解锁Bootloader流程</h4><p>以 Android + Qualcomm SoC 为例：</p>\n<ol>\n<li>用户通过 <code>fastboot oem unlock</code> 发送解锁命令。</li>\n<li>Fastboot 模式下的 <strong>Secondary Bootloader（SBL&#x2F;XBL）</strong> 会请求用户确认（擦除数据）。</li>\n<li>SBL&#x2F;XBL 向 <strong>Qualcomm Secure Execution Environment（QSEE, TrustZone）</strong> 发送解锁请求。</li>\n<li>QSEE 调用 <strong>PBL 对接的安全熔丝编程接口</strong>（OEM 控制）烧录 <code>BOOT_UNLOCK=1</code>。</li>\n<li>解锁完成， PBL 在启动链中会跳过 OEM Key 验证，或者采用开发者密钥（用于允许第三方镜像）。</li>\n</ol>\n<p>:::note<br>PBL 自身不会被修改，但它的行为会因熔丝位（Fuse Bit）的状态而改变。<br>:::</p>\n<hr>\n<h2 id=\"熔断机制\"><a href=\"#熔断机制\" class=\"headerlink\" title=\"熔断机制\"></a>熔断机制</h2><p>个人觉得熔断机制挺有趣的，简单讲讲:</p>\n<blockquote>\n<p>在硅片集成电路内部，设计了由薄金属或多晶硅工艺实现的特殊可控连线。这条连线在出厂时是导通的，芯片运行时可通过高电压&#x2F;电流或激光能量将其永久断开（或改变其物理状态），从而记录一个“1”或“0”的状态。</p>\n</blockquote>\n<p>基于其是在物理层面的熔断，因此无法恢复。<br>比如<strong>Samsung Knox</strong></p>\n<h3 id=\"Samsung-Knox\"><a href=\"#Samsung-Knox\" class=\"headerlink\" title=\"Samsung Knox\"></a>Samsung Knox</h3><h4 id=\"流程\"><a href=\"#流程\" class=\"headerlink\" title=\"流程\"></a>流程</h4><p>以Bootloader解锁为例:</p>\n<ol>\n<li><p>用户在 <strong>Download Mode</strong> 下选择 “OEM Unlock” 并确认</p>\n</li>\n<li><p>当前运行在 SBL（或 ABL）阶段的 Bootloader 向 TrustZone Secure Monitor 发起 <strong>SMC（Secure Monitor Call）</strong> 请求：</p>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">`smc_call(SMC_CMD_BLOW_FUSE, KNOX_WARRANTY_BIT_ID);`</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>TrustZone 内的安全固件（TZSW）通过 <strong>eFuse Controller</strong> 选中对应的熔丝行列地址</p>\n</li>\n<li><p>硬件打开 <strong>VPP 高压电源轨</strong>（通常在芯片设计时是隔离状态，只在安全状态下可用，防止自己电自己）</p>\n</li>\n<li><p>在一个很短的时间内向该熔丝单元施加大电流&#x2F;高压</p>\n</li>\n<li><p>熔丝链路永久断开（熔断），逻辑状态从 0 → 1</p>\n</li>\n<li><p>把新状态Latch到一个只读寄存器（Boot ROM 在每次启动时读取）</p>\n</li>\n</ol>\n<p>恭喜你！你的手机将会….</p>\n<ul>\n<li>Samsung Pay&#x2F;Samsung Pass 永久不可用</li>\n<li>安全文件夹功能无法使用</li>\n<li>保修失效<br>…</li>\n</ul>\n<p>:::note<br>理论上可以烧写另一个位表示重新锁定（部分 SoC 采用双位方案 LOCK&#x2F;UNLOCK），但是我不懂捏<br>:::</p>\n<p>:::important<br>如果你打算购入Samsung的二手机，需要注意这一点，以免一失足成千古恨。<br>:::</p>\n<p>end~😌</p>\n<p>[^1]: 这段Boot Rom代码写死在SoC内部的Mask Rom里，无法更改。</p>\n","cover":false,"excerpt":"","more":"<h2 id=\"Boot-Rom\"><a href=\"#Boot-Rom\" class=\"headerlink\" title=\"Boot Rom\"></a>Boot Rom</h2><p><img src=\"https://cdn.jsdelivr.net/gh/Cooper1896/MyPic/68b1859c50416_1756464540.webp\" alt=\"高通平台启动流程\"></p>\n<center>高通平台启动流程</center>\n\n<p>根据流程图可以看见，在设备通电后，会首先运行PBL(Primary Boot Loader)。此时CPU会从固定地址(如ROM)执行Boot Rom代码[^1]，初始化最低级的硬件(如时钟,CPU核心等)。之后他会加载SBL(Secondary Boot Loader)到SRAM，并使用Root of trust公钥来验证SBL的签名。</p>\n<hr>\n<h2 id=\"PBL-XBL或者SBL\"><a href=\"#PBL-XBL或者SBL\" class=\"headerlink\" title=\"PBL(XBL或者SBL)\"></a>PBL(XBL或者SBL)</h2><p>这部分便是今天要讲的重点——Bootloader。他主要的流程如下：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">读取Boot Mode-&gt;</span><br><span class=\"line\">初始化启动接口(UFS,USB,eMMC,NAND)-&gt;</span><br><span class=\"line\">读取下一阶段镜像-&gt;</span><br><span class=\"line\">验证数字签名(RSA+SHA-256)-&gt;</span><br><span class=\"line\">├─ 验证通过 → 加载 SBL 并跳转 </span><br><span class=\"line\">└─ 验证失败 → 进入 Download Mode（刷机接口）</span><br></pre></td></tr></table></figure>\n\n<p>显而易见，PBL的目标是最大化保护设备的安全，以下简单讲几个有关的安全机制:</p>\n<ul>\n<li><p>签名验证(<strong>Signature Verification</strong>)</p>\n<ul>\n<li>让所有要启动的 Next-stage Bootloader (SBL&#x2F;XBL) 都必须经过OEM Key的签名验证</li>\n</ul>\n</li>\n<li><p>防回滚(<strong>Rollback Protection</strong>)</p>\n<ul>\n<li>防止刷入低于eFuse记录版本的固件<br>这也是为什么，即使你有官方签名的旧版本固件，也无法手动刷入。这是因为其版本号低于eFuse中记录的版本，PBL拒绝了该镜像的加载</li>\n</ul>\n</li>\n<li><p>安全模式入口(EDL&#x2F;Download Mode)限制</p>\n<ul>\n<li>大多OEM厂商都会限制安全模式入口。限制后，新版设备可能需要配合授权服务器（如 Mi Auth、Samsung KNOX）才能刷机，PBL 会要求 PC 工具和 OEM 服务器握手，验证授权 Token。</li>\n<li>这也是为什么售后能帮你刷机降级。员工会使用公司提供的PC工具，验证其员工身份，得到授权后可以进入该模式进行刷机。但由于内部内鬼等原因，时不时会有内部Token放出来出售(点名表扬小米😅)</li>\n</ul>\n</li>\n</ul>\n<p>你会发现，在流程中，他会验证镜像是否经过OEM&#x2F;厂家的签名认证。</p>\n<p>这意味着——无论你使用什么刷机工具(Fastboot、MiFlash等)去刷入固件，最终能否启动，取决于PBL是否认可该镜像的签名。</p>\n<p>这也是为什么你要在解锁Bootloader后，才能刷入第三方ROM。</p>\n<h3 id=\"PBL与Bootloader锁\"><a href=\"#PBL与Bootloader锁\" class=\"headerlink\" title=\"PBL与Bootloader锁\"></a>PBL与Bootloader锁</h3><p>Bootloader的锁定状态是由eFuse&#x2F;OTP(One-Time Programmable Memory)记录，在PBL启动时会读取这些硬件熔丝位(Fuse Bits)</p>\n<p>在寄存器中一般会记录一下信息:</p>\n<ul>\n<li><code>BOOT_UNLOCK</code>:表示当前解锁状态(0 &#x3D; Locked, 1 &#x3D; Unlocked)</li>\n<li><code>OEM_KEY_HASH</code>:厂商公钥的哈希值，用于签名验证</li>\n<li><code>ANTI-ROLLBACK_VER</code>:防回滚版本号。用于验证镜像版本，确保镜像版本 ≥ eFuse版本，防止降级到存在漏洞的固件。</li>\n</ul>\n<h4 id=\"解锁Bootloader流程\"><a href=\"#解锁Bootloader流程\" class=\"headerlink\" title=\"解锁Bootloader流程\"></a>解锁Bootloader流程</h4><p>以 Android + Qualcomm SoC 为例：</p>\n<ol>\n<li>用户通过 <code>fastboot oem unlock</code> 发送解锁命令。</li>\n<li>Fastboot 模式下的 <strong>Secondary Bootloader（SBL&#x2F;XBL）</strong> 会请求用户确认（擦除数据）。</li>\n<li>SBL&#x2F;XBL 向 <strong>Qualcomm Secure Execution Environment（QSEE, TrustZone）</strong> 发送解锁请求。</li>\n<li>QSEE 调用 <strong>PBL 对接的安全熔丝编程接口</strong>（OEM 控制）烧录 <code>BOOT_UNLOCK=1</code>。</li>\n<li>解锁完成， PBL 在启动链中会跳过 OEM Key 验证，或者采用开发者密钥（用于允许第三方镜像）。</li>\n</ol>\n<p>:::note<br>PBL 自身不会被修改，但它的行为会因熔丝位（Fuse Bit）的状态而改变。<br>:::</p>\n<hr>\n<h2 id=\"熔断机制\"><a href=\"#熔断机制\" class=\"headerlink\" title=\"熔断机制\"></a>熔断机制</h2><p>个人觉得熔断机制挺有趣的，简单讲讲:</p>\n<blockquote>\n<p>在硅片集成电路内部，设计了由薄金属或多晶硅工艺实现的特殊可控连线。这条连线在出厂时是导通的，芯片运行时可通过高电压&#x2F;电流或激光能量将其永久断开（或改变其物理状态），从而记录一个“1”或“0”的状态。</p>\n</blockquote>\n<p>基于其是在物理层面的熔断，因此无法恢复。<br>比如<strong>Samsung Knox</strong></p>\n<h3 id=\"Samsung-Knox\"><a href=\"#Samsung-Knox\" class=\"headerlink\" title=\"Samsung Knox\"></a>Samsung Knox</h3><h4 id=\"流程\"><a href=\"#流程\" class=\"headerlink\" title=\"流程\"></a>流程</h4><p>以Bootloader解锁为例:</p>\n<ol>\n<li><p>用户在 <strong>Download Mode</strong> 下选择 “OEM Unlock” 并确认</p>\n</li>\n<li><p>当前运行在 SBL（或 ABL）阶段的 Bootloader 向 TrustZone Secure Monitor 发起 <strong>SMC（Secure Monitor Call）</strong> 请求：</p>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">`smc_call(SMC_CMD_BLOW_FUSE, KNOX_WARRANTY_BIT_ID);`</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>TrustZone 内的安全固件（TZSW）通过 <strong>eFuse Controller</strong> 选中对应的熔丝行列地址</p>\n</li>\n<li><p>硬件打开 <strong>VPP 高压电源轨</strong>（通常在芯片设计时是隔离状态，只在安全状态下可用，防止自己电自己）</p>\n</li>\n<li><p>在一个很短的时间内向该熔丝单元施加大电流&#x2F;高压</p>\n</li>\n<li><p>熔丝链路永久断开（熔断），逻辑状态从 0 → 1</p>\n</li>\n<li><p>把新状态Latch到一个只读寄存器（Boot ROM 在每次启动时读取）</p>\n</li>\n</ol>\n<p>恭喜你！你的手机将会….</p>\n<ul>\n<li>Samsung Pay&#x2F;Samsung Pass 永久不可用</li>\n<li>安全文件夹功能无法使用</li>\n<li>保修失效<br>…</li>\n</ul>\n<p>:::note<br>理论上可以烧写另一个位表示重新锁定（部分 SoC 采用双位方案 LOCK&#x2F;UNLOCK），但是我不懂捏<br>:::</p>\n<p>:::important<br>如果你打算购入Samsung的二手机，需要注意这一点，以免一失足成千古恨。<br>:::</p>\n<p>end~😌</p>\n<p>[^1]: 这段Boot Rom代码写死在SoC内部的Mask Rom里，无法更改。</p>\n"}],"PostAsset":[],"PostCategory":[{"post_id":"cuid-38_HDRioCInDnQAZUhrS","category_id":"cuidHqSnrXVN1uv0E5aTAgzI7","_id":"cuid3cDWiFxtSANYI2pAIbc4J"},{"post_id":"cuidcxfp-1aqJKjmYT4mj67Aa","category_id":"cuidHqSnrXVN1uv0E5aTAgzI7","_id":"cuid5Rbq3k43t04ZVYOFATp8C"}],"PostTag":[{"post_id":"cuidcxfp-1aqJKjmYT4mj67Aa","tag_id":"cuidyb_61H4edvnRbnpYMJCzt","_id":"cuidbq7pcHOjrNR0LSR5hdabh"},{"post_id":"cuidodTpyy0S0uEWKx9bPDVhe","tag_id":"cuid2YMXvireLE42TR2jbzG9g","_id":"cuid2QPiFLjP81wlN3QvfDZ_I"},{"post_id":"cuid-38_HDRioCInDnQAZUhrS","tag_id":"cuiddjarD2ZrMjJvUReyDFqPm","_id":"cuidKXMGrpQQ7BWB-DaAIi9pZ"}],"Tag":[{"name":"分享/博客","_id":"cuidyb_61H4edvnRbnpYMJCzt"},{"name":"AI/Artificial Intelligence","_id":"cuid2YMXvireLE42TR2jbzG9g"},{"name":"Bootloader/解锁","_id":"cuiddjarD2ZrMjJvUReyDFqPm"}]}}