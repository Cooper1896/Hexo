<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>浅谈解锁bootloader与背后的原理</title>
      <link href="/2025/11/26/unlocked_bl_sh/"/>
      <url>/2025/11/26/unlocked_bl_sh/</url>
      
        <content type="html"><![CDATA[<h2 id="Boot-Rom"><a href="#Boot-Rom" class="headerlink" title="Boot Rom"></a>Boot Rom</h2><p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.jsdelivr.net/gh/Cooper1896/MyPic/68b1859c50416_1756464540.webp" alt="高通平台启动流程"></p><center>高通平台启动流程</center><p>根据流程图可以看见，在设备通电后，会首先运行PBL(Primary Boot Loader)。此时CPU会从固定地址(如ROM)执行Boot Rom代码[^1]，初始化最低级的硬件(如时钟,CPU核心等)。之后他会加载SBL(Secondary Boot Loader)到SRAM，并使用Root of trust公钥来验证SBL的签名。</p><hr><h2 id="PBL-XBL或者SBL"><a href="#PBL-XBL或者SBL" class="headerlink" title="PBL(XBL或者SBL)"></a>PBL(XBL或者SBL)</h2><p>这部分便是今天要讲的重点——Bootloader。他主要的流程如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">读取Boot Mode-&gt;</span><br><span class="line">初始化启动接口(UFS,USB,eMMC,NAND)-&gt;</span><br><span class="line">读取下一阶段镜像-&gt;</span><br><span class="line">验证数字签名(RSA+SHA-256)-&gt;</span><br><span class="line">├─ 验证通过 → 加载 SBL 并跳转 </span><br><span class="line">└─ 验证失败 → 进入 Download Mode（刷机接口）</span><br></pre></td></tr></table></figure><p>显而易见，PBL的目标是最大化保护设备的安全，以下简单讲几个有关的安全机制:</p><ul><li><p>签名验证(<strong>Signature Verification</strong>)</p><ul><li>让所有要启动的 Next-stage Bootloader (SBL&#x2F;XBL) 都必须经过OEM Key的签名验证</li></ul></li><li><p>防回滚(<strong>Rollback Protection</strong>)</p><ul><li>防止刷入低于eFuse记录版本的固件<br>这也是为什么，即使你有官方签名的旧版本固件，也无法手动刷入。这是因为其版本号低于eFuse中记录的版本，PBL拒绝了该镜像的加载</li></ul></li><li><p>安全模式入口(EDL&#x2F;Download Mode)限制</p><ul><li>大多OEM厂商都会限制安全模式入口。限制后，新版设备可能需要配合授权服务器（如 Mi Auth、Samsung KNOX）才能刷机，PBL 会要求 PC 工具和 OEM 服务器握手，验证授权 Token。</li><li>这也是为什么售后能帮你刷机降级。员工会使用公司提供的PC工具，验证其员工身份，得到授权后可以进入该模式进行刷机。但由于内部内鬼等原因，时不时会有内部Token放出来出售(点名表扬小米😅)</li></ul></li></ul><p>你会发现，在流程中，他会验证镜像是否经过OEM&#x2F;厂家的签名认证。</p><p>这意味着——无论你使用什么刷机工具(Fastboot、MiFlash等)去刷入固件，最终能否启动，取决于PBL是否认可该镜像的签名。</p><p>这也是为什么你要在解锁Bootloader后，才能刷入第三方ROM。</p><h3 id="PBL与Bootloader锁"><a href="#PBL与Bootloader锁" class="headerlink" title="PBL与Bootloader锁"></a>PBL与Bootloader锁</h3><p>Bootloader的锁定状态是由eFuse&#x2F;OTP(One-Time Programmable Memory)记录，在PBL启动时会读取这些硬件熔丝位(Fuse Bits)</p><p>在寄存器中一般会记录一下信息:</p><ul><li><code>BOOT_UNLOCK</code>:表示当前解锁状态(0 &#x3D; Locked, 1 &#x3D; Unlocked)</li><li><code>OEM_KEY_HASH</code>:厂商公钥的哈希值，用于签名验证</li><li><code>ANTI-ROLLBACK_VER</code>:防回滚版本号。用于验证镜像版本，确保镜像版本 ≥ eFuse版本，防止降级到存在漏洞的固件。</li></ul><h4 id="解锁Bootloader流程"><a href="#解锁Bootloader流程" class="headerlink" title="解锁Bootloader流程"></a>解锁Bootloader流程</h4><p>以 Android + Qualcomm SoC 为例：</p><ol><li>用户通过 <code>fastboot oem unlock</code> 发送解锁命令。</li><li>Fastboot 模式下的 <strong>Secondary Bootloader（SBL&#x2F;XBL）</strong> 会请求用户确认（擦除数据）。</li><li>SBL&#x2F;XBL 向 <strong>Qualcomm Secure Execution Environment（QSEE, TrustZone）</strong> 发送解锁请求。</li><li>QSEE 调用 <strong>PBL 对接的安全熔丝编程接口</strong>（OEM 控制）烧录 <code>BOOT_UNLOCK=1</code>。</li><li>解锁完成， PBL 在启动链中会跳过 OEM Key 验证，或者采用开发者密钥（用于允许第三方镜像）。</li></ol><p>:::note<br>PBL 自身不会被修改，但它的行为会因熔丝位（Fuse Bit）的状态而改变。<br>:::</p><hr><h2 id="熔断机制"><a href="#熔断机制" class="headerlink" title="熔断机制"></a>熔断机制</h2><p>个人觉得熔断机制挺有趣的，简单讲讲:</p><blockquote><p>在硅片集成电路内部，设计了由薄金属或多晶硅工艺实现的特殊可控连线。这条连线在出厂时是导通的，芯片运行时可通过高电压&#x2F;电流或激光能量将其永久断开（或改变其物理状态），从而记录一个“1”或“0”的状态。</p></blockquote><p>基于其是在物理层面的熔断，因此无法恢复。<br>比如<strong>Samsung Knox</strong></p><h3 id="Samsung-Knox"><a href="#Samsung-Knox" class="headerlink" title="Samsung Knox"></a>Samsung Knox</h3><h4 id="流程"><a href="#流程" class="headerlink" title="流程"></a>流程</h4><p>以Bootloader解锁为例:</p><ol><li><p>用户在 <strong>Download Mode</strong> 下选择 “OEM Unlock” 并确认</p></li><li><p>当前运行在 SBL（或 ABL）阶段的 Bootloader 向 TrustZone Secure Monitor 发起 <strong>SMC（Secure Monitor Call）</strong> 请求：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">`smc_call(SMC_CMD_BLOW_FUSE, KNOX_WARRANTY_BIT_ID);`</span><br></pre></td></tr></table></figure></li><li><p>TrustZone 内的安全固件（TZSW）通过 <strong>eFuse Controller</strong> 选中对应的熔丝行列地址</p></li><li><p>硬件打开 <strong>VPP 高压电源轨</strong>（通常在芯片设计时是隔离状态，只在安全状态下可用，防止自己电自己）</p></li><li><p>在一个很短的时间内向该熔丝单元施加大电流&#x2F;高压</p></li><li><p>熔丝链路永久断开（熔断），逻辑状态从 0 → 1</p></li><li><p>把新状态Latch到一个只读寄存器（Boot ROM 在每次启动时读取）</p></li></ol><p>恭喜你！你的手机将会….</p><ul><li>Samsung Pay&#x2F;Samsung Pass 永久不可用</li><li>安全文件夹功能无法使用</li><li>保修失效<br>…</li></ul><p>:::note<br>理论上可以烧写另一个位表示重新锁定（部分 SoC 采用双位方案 LOCK&#x2F;UNLOCK），但是我不懂捏<br>:::</p><p>:::important<br>如果你打算购入Samsung的二手机，需要注意这一点，以免一失足成千古恨。<br>:::</p><p>end~😌</p><p>[^1]: 这段Boot Rom代码写死在SoC内部的Mask Rom里，无法更改。</p>]]></content>
      
      
      <categories>
          
          <category> 杂谈 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Bootloader/解锁 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Fuwari部署Twikoo过程分享</title>
      <link href="/2025/11/26/Twikko/"/>
      <url>/2025/11/26/Twikko/</url>
      
        <content type="html"><![CDATA[<p>Twikoo — “一个简洁、安全、免费的静态网站评论系统”</p><hr><p>本站原本使用Giscus的评论功能</p><p>但考虑到必须要Github账户的局限性</p><p>为了更方便评论，我决定放弃前者，毅然加入更权威的代表—‘Twikoo’</p><p>本文参考官方教程，也可以按照官方的来，大差不差~</p><h2 id="搭建后端"><a href="#搭建后端" class="headerlink" title="搭建后端"></a>搭建后端</h2><p>首先，你需要注册一个<a href="https://account.mongodb.com/account/login">MongoDB</a>账号以获取一个免费的数据库</p><div calss='anzhiyu-tag-link'><a class="tag-Link" target="_blank" href="/%3Chttps:/twikoo.js.org/mongodb-atlas">    <div class="tag-link-tips">引用站外地址</div>    <div class="tag-link-bottom">        <div class="tag-link-left" style="background-image: url(/img/twikoo-logo.png>)">          <i class="anzhiyufont anzhiyu-icon-link" style="display: none"></i>        </div>        <div class="tag-link-right">            <div class="tag-link-title">MongoDB Atlas | Twikoo 文档</div>            <div class="tag-link-sitename">一个简洁、安全、免费的静态网站评论系统</div>        </div>        <i class="anzhiyufont anzhiyu-icon-angle-right"></i>    </div>    </a></div><p>区域选择: Region优先选择离主机近的站点，一般默认的就是。如果使用云主机就按其地理位置为准。<br>设置好后，你将会得到类似的代码：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mongodb+srv://&lt;db_username&gt;:&lt;db_password&gt;@cluster0.xxx.mongodb.net/?retryWrites......Cluster0</span><br></pre></td></tr></table></figure><div class="note danger flat"><p>请牢记在 Password Authentication 下设置数据库用户名和密码!!!</p></div><h2 id="部署数据库"><a href="#部署数据库" class="headerlink" title="部署数据库"></a>部署数据库</h2><p>使用你的Github账户来登录Vercel</p><div calss='anzhiyu-tag-link'><a class="tag-Link" target="_blank" href="/%3Chttps:/vercel.com">    <div class="tag-link-tips">引用站外地址</div>    <div class="tag-link-bottom">        <div class="tag-link-left" style="background-image: url(/images/link-default.png>)">          <i class="anzhiyufont anzhiyu-icon-link" style="display: none"></i>        </div>        <div class="tag-link-right">            <div class="tag-link-title">Dashboard</div>            <div class="tag-link-sitename">Vercel Dashboard</div>        </div>        <i class="anzhiyufont anzhiyu-icon-angle-right"></i>    </div>    </a></div><p>再点击下面的链接来快速部署</p><p><div calss='anzhiyu-tag-link'><a class="tag-Link" target="_blank" href="/%3Ca%20href=https:/vercel.com/new/clone?repository-url=https:/github.com/imaegoo/twikoo/tree/main/src/server/vercel-min&teamSlug=brizens-projects">    <div class="tag-link-tips">引用站外地址</div>    <div class="tag-link-bottom">        <div class="tag-link-left" style="background-image: url(https://assets.vercel.com/image/upload/front/import/og.png>https://vercel.com/new/clone?repository-url=https%3A%2F%2Fgithub.com%2Fimaegoo%2Ftwikoo%2Ftree%2Fmain%2Fsrc%2Fserver%2Fvercel-min&amp;teamSlug=brizens-projects)">          <i class="anzhiyufont anzhiyu-icon-link" style="display: none"></i>        </div>        <div class="tag-link-right">            <div class="tag-link-title">New Project – Vercel</div>            <div class="tag-link-sitename"></div>        </div>        <i class="anzhiyufont anzhiyu-icon-angle-right"></i>    </div>    </a></div></p><p><code>Git Providers</code>选择<code>Github</code>，<code>Git Scope</code>选择自己的账户，<code>Private Repository Name</code>为你的库命名。</p><p>若是一切顺利，你会看见这样的画面<br><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.jsdelivr.net/gh/Cooper1896/MyPic/68ac9f5575e4b_1756143445.webp"></p><blockquote><p>这时你还不会有Domain位址</p></blockquote><hr><p>选择<code>Settings</code> - <code>Environment Variables</code>,填写以下变量：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Key:MONGODB_URI</span><br><span class="line">Value:mongodb+srv://&lt;db_username&gt;......&lt;此处需要更改为你上面获取到的链接字符&gt;</span><br></pre></td></tr></table></figure><p>随后点save</p><p>此时再选择<code>Deployments</code>,点击任意一个项目后面的三个点，再选择<code>Redeploy</code>，再选择下方的<code>Redeploy</code></p><p>这时回到<code>Overview</code>,会发现<code>Domain</code>处已分配了一个域名,复制下该域名。</p><h2 id="参数设置"><a href="#参数设置" class="headerlink" title="参数设置"></a>参数设置</h2><p>可以跟随其他大大的教程设置本地文件，伟大无需多言</p><div calss='anzhiyu-tag-link'><a class="tag-Link" target="_blank" href="/%3Chttps:/blog.qqquq.com/posts/fuwari-twikoo-comments/">    <div class="tag-link-tips">引用站外地址</div>    <div class="tag-link-bottom">        <div class="tag-link-left" style="background-image: url(https://blog.qqquq.com/favicon/favicon-light-32.png>)">          <i class="anzhiyufont anzhiyu-icon-link" style="display: none"></i>        </div>        <div class="tag-link-right">            <div class="tag-link-title">给你的 Fuwari 接入 Twikoo 评论 - 咸鱼小窝</div>            <div class="tag-link-sitename">Fuwari 博客接入 Twikoo 评论</div>        </div>        <i class="anzhiyufont anzhiyu-icon-angle-right"></i>    </div>    </a></div><p>其中，请将上面复制的域名复制到<code>envID</code>,并将<username>,<password>修改成你设置的账号和密码。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">export const commentConfig: CommentConfig = &#123;</span><br><span class="line">  twikoo: &#123;</span><br><span class="line">    envId: &#x27;这里替换为你的 envId&#x27;,</span><br><span class="line">  &#125;,</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>最后在终端输入<code>pnpm dev</code>即可本地预览，enjoy!</p>]]></content>
      
      
      <categories>
          
          <category> 杂谈 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 分享/博客 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hello World</title>
      <link href="/2025/11/26/hello-world/"/>
      <url>/2025/11/26/hello-world/</url>
      
        <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">&quot;My New Post&quot;</span></span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>AI</title>
      <link href="/2025/10/24/Artificial%20Intelligence/"/>
      <url>/2025/10/24/Artificial%20Intelligence/</url>
      
        <content type="html"><![CDATA[<p>想了很久，终于有时间来讲讲AI了，些许错误，多多包容</p><hr><h3 id="I-人工智能-Artificial-Intelligence-AI"><a href="#I-人工智能-Artificial-Intelligence-AI" class="headerlink" title="I. 人工智能 (Artificial Intelligence,AI)"></a>I. 人工智能 (Artificial Intelligence,AI)</h3><p>大家都听过的词语，依照维基百科的解释:  <a href="https://www.wikiwand.com/en/articles/Artificial_intelligence.com">人工智能（AI）</a>是指计算系统执行通常与人类智能相关任务的能力，例如学习、推理、解决问题、感知和决策。</p><p>而AI分为 <strong>强AI</strong> 和 <strong>弱AI</strong>：</p><h5 id="弱AI-ANI-Artificial-Narrow-Intelligence）"><a href="#弱AI-ANI-Artificial-Narrow-Intelligence）" class="headerlink" title="弱AI(ANI - Artificial Narrow Intelligence）"></a><strong>弱AI(ANI - Artificial Narrow Intelligence）</strong></h5><p>被设计用来 <strong><strong>解决特定的任务</strong></strong>（如下棋、人脸识别、写代码）。如AlphaGo, Copilot, Siri 均属此类。</p><h5 id="强-AI-AGI-Artificial-General-Intelligence"><a href="#强-AI-AGI-Artificial-General-Intelligence" class="headerlink" title="强 AI (AGI - Artificial General Intelligence):"></a><strong>强 AI (AGI - Artificial General Intelligence):</strong></h5><p>理论上的“通用人工智能”，拥有与人类同等或超越人类的、跨领域的思考和学习能力。类似于天网、终结者的存在，或者说目标，目前尚未实现。</p><p>随着AI的不断发展，也发展出了不同的发展方向，主要是:<strong>机器学习（ML）与专家系统（Expert Systems）</strong></p><hr><h4 id="专家系统"><a href="#专家系统" class="headerlink" title="专家系统"></a><strong>专家系统</strong></h4><p>专家系统是人工智能发展早期出现的一种 <strong>方法</strong>，它属于基于规则的 AI，与现代的机器学习驱动的 AI 有着十分鲜明对比。</p><h6 id="核心思想与定义"><a href="#核心思想与定义" class="headerlink" title="核心思想与定义"></a><strong>核心思想与定义</strong></h6><p>专家系统旨在模拟人类领域专家（如医生、金融分析师）的决策能力和推理过程，通过将人类的专业知识进行形式化编码，来解决复杂、专业性的问题。本质上是一个由程序员编写的，十分庞大，嵌套极深的 <code>if-else</code> 抉择树。</p><h6 id="结构"><a href="#结构" class="headerlink" title="结构"></a>结构</h6><p>一个典型的专家系统由三个关键组成部分构成：</p><h6 id="1-知识库-Knowledge-Base"><a href="#1-知识库-Knowledge-Base" class="headerlink" title="1. 知识库 (Knowledge Base)"></a><strong>1. 知识库 (Knowledge Base)</strong></h6><p>这是专家系统的信息来源，存储了领域专家的所有专业知识。这些知识通常以两种形式存在：</p><ul><li><p><strong>事实 (Facts):</strong> 关于领域的基本信息（例如：“水在100°C 沸腾”）。</p></li><li><p><strong>规则 (Rules):</strong> <strong>条件-行动 (IF-THEN)</strong> 语句，代表专家的经验和推理逻辑。</p><ul><li><em>示例规则：</em> <code>IF (病人有发烧) AND (病人有咳嗽) THEN (推断患有呼吸道感染)</code></li></ul></li></ul><h5 id="2-推理机-Inference-Engine"><a href="#2-推理机-Inference-Engine" class="headerlink" title="2. 推理机 (Inference Engine)"></a><strong>2. 推理机 (Inference Engine)</strong></h5><p>顾名思义，它负责根据用户输入的信息和知识库中的规则进行逻辑推理，得出结论。主要的推理方法有两种：</p><ul><li><p><strong>正向链 (Forward Chaining):</strong> <strong>数据驱动</strong>。从已知事实开始，不断应用规则，直到达到目标或所有规则都被应用。</p><ul><li><em>逻辑：</em> 如果 $A$ 且 $B$ 为真，而我们知道 $A$ 和 $B$ 是真，则 $C$ 为真。</li></ul></li><li><p><strong>反向链 (Backward Chaining):</strong> <strong>目标驱动</strong>。从目标（假设的结论）开始，向后寻找支持该结论的必要事实或子目标。</p><ul><li><em>逻辑：</em> 要证明 $C$，需要 $A$ 和 $B$。那么，先证明 $A$，再证明 $B$。</li></ul></li></ul><h5 id="3-用户界面-User-Interface"><a href="#3-用户界面-User-Interface" class="headerlink" title="3. 用户界面 (User Interface)"></a><strong>3. 用户界面 (User Interface)</strong></h5><p>用于与用户交互,来接收你输入资讯的地方</p><p>相当直观的一种结构，但是简单的代价是会有两个限制和问题：</p><ul><li><p><strong>极其脆弱</strong>：遇到规则之外的情况就崩溃。因此，相关模型多用于特定的领域，如医疗，金融等..</p></li><li><p><strong>无法学习</strong>:你必须手动更新模型的规则以及知识库，维护的成本也大大增加</p></li></ul><hr><h3 id="II-机器学习-Machine-Learning-ML"><a href="#II-机器学习-Machine-Learning-ML" class="headerlink" title="II. 机器学习 (Machine Learning, ML)"></a>II. 机器学习 (Machine Learning, ML)</h3><p>ML 的本质在于，它不再要求开发者为机器硬编码规则，而是让机器从海量数据中<strong>自动学习</strong>（或“拟合”）出最优的映射函数 $f$。</p><h5 id="一-严谨的定义与三要素-T-E-P"><a href="#一-严谨的定义与三要素-T-E-P" class="headerlink" title="一. 严谨的定义与三要素 (T, E, P)"></a>一. 严谨的定义与三要素 (T, E, P)</h5><p>机器学习最被认可的定义来自于计算机科学家 Tom M. Mitchell。他指出，一个程序从经验中学习，必须满足三个要素：</p><table><thead><tr><th><strong>要素</strong></th><th><strong>解释</strong></th><th><strong>案例：垃圾邮件过滤器</strong></th></tr></thead><tbody><tr><td><strong>任务 ($T$ - Task)</strong></td><td>机器需要完成的具体工作，通常是预测或推断。</td><td><strong>分类任务</strong>：将邮件内容 $X$ 分类到 $Y&#x3D;{\text{“垃圾邮件”}, \text{“非垃圾邮件”}}$。</td></tr><tr><td><strong>经验 ($E$ - Experience)</strong></td><td>模型用于学习的观测数据。</td><td><strong>数据集</strong>：100 万封邮件，其中每封邮件都已人工标注了正确的标签。</td></tr><tr><td><strong>性能度量 ($P$ - Performance)</strong></td><td>量化模型表现的指标，衡量其预测结果与真实标签的匹配程度。</td><td><strong>准确率 (Accuracy)</strong>：模型正确分类的邮件占总邮件数的百分比。</td></tr></tbody></table><p>这也是机器学习与专家系统的最大不同。专家系统是输入<code>数据</code>+<code>规则</code>，输出<code>答案</code>；而机器学习则是输入<code>数据</code>+<code>答案</code>，输出<code>规则</code>。</p><h5 id="二-特征工程-Feature-Engineering"><a href="#二-特征工程-Feature-Engineering" class="headerlink" title="二. 特征工程 (Feature Engineering)"></a>二. 特征工程 (Feature Engineering)</h5><p>这是将原始数据（如图像像素、原始文本）转换成算法可以理解的、具有信息价值的特征向量的过程，或许能称为“学习”？</p><ol><li>优化与统计</li></ol><p>机器学习的过程，在数学上被定义为一个<strong>最优化问题</strong>。 (读M2震怒 。学习的目标是找到一组最优参数 $\theta$，使得模型的<strong>损失函数 ($L$)</strong> 最小化。损失函数度量了模型预测 $\hat{Y}$ 与真实值 $Y$ 之间的差异：</p><p>$$f^* &#x3D; \underset{f}{\operatorname{argmin}} L(f(X), Y)$$</p><ul><li><p>$f$: 代表模型（如神经网络、决策树）。</p></li><li><p>$L(f(X), Y)$: <strong>损失函数</strong>，用于度量模型的预测 $f(X)$ 与真实标签 $Y$ 之间的差异。最小化损失是学习的驱动力。</p></li><li><p>$\operatorname{argmin}$: <strong>最优化操作</strong>，寻找使损失函数 $L$ 达到最小值的模型参数集 $\theta$。</p></li></ul><ol start="2"><li>核心算法：梯度下降 (Gradient Descent)</li></ol><p>大多数 ML 模型（尤其是深度学习）使用梯度下降 (Gradient Descent)及其变种（如 SGD, Adam）来执行优化。大概就是一种数学的计算方式，我不会。</p><blockquote style="border-left: 4px solid #ff6b6b; background: #ffe0e0; padding: 15px; margin: 15px 0;">看看得了</blockquote><p><strong>举个栗子</strong></p><p>例子1：银行贷款违约风险预测</p><table><thead><tr><th><strong>原始特征 (Raw Data)</strong></th><th><strong>领域知识应用（工程操作）</strong></th><th><strong>构造的新特征 (Engineered Feature)</strong></th><th><strong>价值</strong></th></tr></thead><tbody><tr><td><code>年龄</code></td><td>分箱（Binning）</td><td><code>年龄段</code> (例如：[18-25], [26-40], [41-60]…)</td><td>将连续变量转化为离散变量，捕捉不同年龄段客户的风险特性。</td></tr><tr><td><code>信用卡额度</code>、<code>已用额度</code></td><td>运算&#x2F;比率</td><td><code>使用率</code> ($\text{已用额度} &#x2F; \text{总额度}$)</td><td>这是比两个独立数值更有力的违约风险信号。高使用率通常意味着高风险。</td></tr><tr><td><code>过去 12 个月的交易笔数</code></td><td>统计</td><td><code>最近 3 个月的平均交易额增长率</code></td><td>捕捉客户近期消费行为的趋势变化，而非简单的总量。</td></tr><tr><td><code>居住城市</code> (类别)</td><td>编码</td><td><code>城市风险评分</code> (基于该城市历史违约率)</td><td>将高维度的类别特征转化为具有预测意义的数值特征。</td></tr></tbody></table><p>案例 2：情绪分析</p><p>客户评论：“这个应用太卡了，但设计很漂亮。”</p><table><thead><tr><th><strong>原始特征</strong></th><th><strong>领域知识应用（工程操作）</strong></th><th><strong>构造的新特征</strong></th><th><strong>价值</strong></th></tr></thead><tbody><tr><td>原始句子</td><td><strong>词袋模型 (Bag-of-Words)</strong> 或 <strong>TF-IDF</strong></td><td><code>“卡”的频率</code>, <code>“漂亮”的权重</code></td><td>将不定长的文本转化为固定长度的数值向量。</td></tr><tr><td>词语</td><td><strong>N-gram 构造</strong></td><td><code>“太卡了”</code> (三元词组)</td><td>捕捉词语的局部顺序和语义，“太卡了”比单独的“卡”更有负面情感。</td></tr><tr><td>情感词典</td><td><strong>计数</strong></td><td><code>负面词汇数量</code>, <code>正面词汇数量</code></td><td>捕捉评论的<strong>情感极性</strong>和<strong>强度</strong>。</td></tr><tr><td>连词</td><td><strong>结构分析</strong></td><td><code>是否存在转折连词 (“但”, “可是”)</code></td><td>“卡但漂亮”表示复杂情绪，模型应区别于“卡且丑陋”。</td></tr></tbody></table><h5 id="三、-机器学习的主要任务类型"><a href="#三、-机器学习的主要任务类型" class="headerlink" title="三、 机器学习的主要任务类型"></a>三、 机器学习的主要任务类型</h5><p>机器学习任务通常根据训练数据的性质和模型目标被划分为三大类：</p><h6 id="1-监督学习-Supervised-Learning"><a href="#1-监督学习-Supervised-Learning" class="headerlink" title="1. 监督学习 (Supervised Learning)"></a>1. 监督学习 (Supervised Learning)</h6><p>监督学习是目前应用最广泛的 ML 类型，类似于有老师手把手教你，即训练数据中的每一个输入 $X$ 都对应一个已知的、正确的输出标签 $Y$。这类算法的目的是学习和逼近输入 $X$ 到输出 $Y$ 的映射函数 $f$，使得对于任何新的输入 $X_{\text{new}}$，模型能够准确预测其对应的 $\hat{Y}_{\text{new}}$。</p><blockquote style="border-left: 4px solid #4dabf7; background: #e7f5ff; padding: 15px; margin: 15px 0;">金融预测： 输入经济指标和历史数据，输出连续的未来某商品价格。<p>住房预测： 输入房屋面积、地理位置等，输出具体的房价数值。</p></blockquote><h6 id="2-无监督学习-Unsupervised-Learning"><a href="#2-无监督学习-Unsupervised-Learning" class="headerlink" title="2.无监督学习 (Unsupervised Learning)"></a>2.无监督学习 (Unsupervised Learning)</h6><p>无监督学习就像是让学生自主探索。模型接收的训练数据<strong>只有输入 $X$</strong>，没有标签 $Y$。在此类算法中，模型必须自主地探索数据，找出隐藏在数据中的统计结构、分布等。它不进行预测，而是进行描述和组织。</p><blockquote style="border-left: 4px solid #4dabf7; background: #e7f5ff; padding: 15px; margin: 15px 0;">购物分析：发现“如果客户购买了牛奶 (A)，那么他们有 80% 的概率也会购买面包 (B)”。</blockquote><h6 id="3-强化学习-Reinforcement-Learning-RL"><a href="#3-强化学习-Reinforcement-Learning-RL" class="headerlink" title="3.强化学习 (Reinforcement Learning, RL)"></a>3.<a href="https://www.wikiwand.com/en/articles/Reinforcement_learning">强化学习 (Reinforcement Learning, RL)</a></h6><p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://assets.wikiwand.com/_next/image?url=https://upload.wikimedia.org/wikipedia/commons/thumb/1/1b/Reinforcement_learning_diagram.svg/1100px-Reinforcement_learning_diagram.svg.png&w=828&q=70" alt="https:&#x2F;&#x2F;assets.wikiwand.com&#x2F;_next&#x2F;image?url&#x3D;https:&#x2F;&#x2F;upload.wikimedia.org&#x2F;wikipedia&#x2F;commons&#x2F;thumb&#x2F;1&#x2F;1b&#x2F;Reinforcement_learning_diagram.svg&#x2F;1100px-Reinforcement_learning_diagram.svg.png&amp;w&#x3D;828&amp;q&#x3D;70"></p><p>强化学习与前两者完全不同，它是一种<strong>基于试错 (Trial-and-Error)</strong> 的学习方法，灵感来源于心理学中的行为主义。</p><p>如果你想让你家的狗学会坐下或叼飞盘，你不会像人类一样让它看书，而是使用<strong>奖励</strong>和<strong>惩罚</strong>来塑造它的行为，这也是强化学习的逻辑。训练机器狗的过程是一个永不停止的、基于<strong>马尔可夫决策过程 (MDP)</strong> 的循环：</p><h4 id="步骤-1：观察"><a href="#步骤-1：观察" class="headerlink" title="步骤 1：观察"></a>步骤 1：观察</h4><p>机器狗环顾四周，确定它在哪里（<strong>状态 $S$</strong>）。</p><ul><li><em>例如：</em> 机器狗知道它在 $(5, 5)$ 位置，并且闻到了前方有食物的气味。</li></ul><h4 id="步骤-2：行动"><a href="#步骤-2：行动" class="headerlink" title="步骤 2：行动"></a>步骤 2：行动</h4><p>机器狗根据它<strong>当前的策略 $\pi$</strong>（行为准则），决定下一步做什么（<strong>行动 $A$</strong>）。</p><ul><li><em>例如：</em> 机器狗的策略是“闻到食物，就前进”。它执行了“前进”的动作。</li></ul><h4 id="步骤-3：反馈与奖励"><a href="#步骤-3：反馈与奖励" class="headerlink" title="步骤 3：反馈与奖励"></a>步骤 3：反馈与奖励</h4><p>机器狗执行动作后，环境发生变化，并返回反馈：</p><ul><li><p><strong>新状态 $S’$：</strong> 机器狗移动到了 $(6, 5)$ 位置。</p></li><li><p><strong>奖励 $R$：</strong></p><ul><li><p>如果它吃到了食物：$+100$ (奖励)</p></li><li><p>如果它撞到了墙：$-10$ (惩罚)</p></li><li><p>如果它踩到了地雷：$-1000$ (巨大惩罚)</p></li><li><p>如果只是普通移动：$-1$ (微小惩罚)</p></li></ul></li></ul><h4 id="步骤-4：更新策略"><a href="#步骤-4：更新策略" class="headerlink" title="步骤 4：更新策略"></a>步骤 4：更新策略</h4><p>机器狗利用这个反馈（奖励 $R$）来<strong>评估</strong>它刚才的行动好不好，并<strong>调整它的策略 $\pi$</strong>。</p><ul><li><p><strong>如果 $R$ 为正：</strong> 它知道这个行动是好的，下次在类似状态下会倾向于重复这个行动。</p></li><li><p><strong>如果 $R$ 为负：</strong> 它知道这个行动是坏的，下次在类似状态下会避免这个行动。</p></li></ul><p>这个循环会重复数百万次，机器狗从随机的试错开始，逐步搭建一套最优策略，即：如何避开地雷，并以最快的速度找到最多的食物。</p><hr><h3 id="III-深度学习-Deep-Learning-DL"><a href="#III-深度学习-Deep-Learning-DL" class="headerlink" title="III 深度学习 (Deep Learning,DL)"></a>III 深度学习 (Deep Learning,DL)</h3><p>深度学习属于机器学习的其中一种，是实现机器学习的一种技术。它特指使用一种名为<strong>深度神经网络 (Deep Neural Networks, DNN)</strong> 的特定模型结构来完成学习任务。</p><h5 id="说文解字"><a href="#说文解字" class="headerlink" title="说文解字"></a>说文解字</h5><p>“深”，意为深度，有点像是层级化的特征学习</p><ul><li><p><strong>传统 ML：</strong> 高度依赖人类专家手动设计特征。例如，要识别一张图片中的人脸，你可能需要手动编写代码来检测“眼睛的形状”、“鼻子的比例”、“肤色分布”等特征。</p></li><li><p><strong>深度学习：</strong> 实现了自动化的特征学习。您只需将原始数据（如图像的原始像素）喂给模型，模型会自动在它的“深度”结构中学习到最优特征。</p></li></ul><p>这种叫做<strong>层级化特征学习</strong></p><h5 id="举个栗子"><a href="#举个栗子" class="headerlink" title="举个栗子"></a>举个栗子</h5><p>以图像识别的CNN为例:</p><ul><li><p><strong>Layer 1 (浅层):</strong> 神经网络的第一层会自动学习到最基础的特征，如<code>边缘</code>、<code>角落</code>、简单的<code>颜色块</code>。</p></li><li><p><strong>Layer 2 (中层):</strong> 这一层会组合第一层的简单特征，自动学习到更复杂的形状和纹理，如<code>圆形</code>、<code>网格状</code>、<code>毛发纹理</code>。</p></li><li><p><strong>Layer 3 (深层):</strong> 这一层会组合中层的形状，自动学习到物体的部件，如<code>眼睛</code>、<code>鼻子</code>、<code>汽车轮胎</code>。</p></li><li><p><strong>Output Layer (顶层):</strong> 最终，顶层会组合这些部件，做出最终的分类判断：“这是一张人脸”或“这是一辆汽车”</p></li></ul><p><strong>深度</strong> 指的就是这种特征抽象的层级数量。因为模型会自动学习这些特征，所以它能发现人类工程师难以想到的更优、更抽象的东西。</p><h5 id="构成"><a href="#构成" class="headerlink" title="构成"></a>构成</h5><p>一个<strong>深度神经网络</strong> 由三个部分组成：</p><ol><li><p><strong>输入层 (Input Layer):</strong> 接收原始数据（如图像像素、词向量）。</p></li><li><p><strong>隐藏层 (Hidden Layers):</strong> 这是模型的核心。DNN 至少有两个或更多的隐藏层（通常是几十到几百层）。每一层都由许多<strong>神经元</strong> 组成，每个神经元都会对其输入进行<strong>加权求和</strong>并应用<strong>激活函数</strong>来引入非线性。</p></li><li><p><strong>输出层 (Output Layer):</strong> 生成最终的预测结果（如分类的概率）。</p></li></ol><h5 id="主要架构"><a href="#主要架构" class="headerlink" title="主要架构"></a>主要架构</h5><table><thead><tr><th><strong>架构</strong></th><th><strong>全称</strong></th><th><strong>核心机制</strong></th><th><strong>擅长领域</strong></th></tr></thead><tbody><tr><td><strong>CNN</strong></td><td><strong>卷积神经网络</strong><br>(Convolutional Neural Network)</td><td><strong>卷积核 (Filters)</strong> 与 <strong>参数共享</strong>。</td><td><strong>网格状数据（如图像）</strong>：图像识别、医学影像分析、目标检测。</td></tr><tr><td><strong>RNN</strong></td><td><strong>循环神经网络</strong><br>(Recurrent Neural Network)</td><td><strong>隐藏状态 (Hidden State)</strong> 的循环，用于处理序列。</td><td><strong>序列数据（如文本、时间序列）</strong>：自然语言处理、语音识别。</td></tr><tr><td><strong>LSTM</strong></td><td><strong>长短期记忆网络</strong><br>(Long Short-Term Memory)</td><td>RNN 的变体，使用“门控”机制来解决 RNN 的  <strong>长距离依赖（遗忘</strong>问题。</td><td>复杂的序列任务。</td></tr><tr><td><strong>Transformer</strong></td><td>(无特定全称)</td><td><strong>自注意力机制 (Self-Attention)</strong>。</td><td><strong>现代 NLP 的基石</strong>：GPT-4、BERT 等大型语言模型，以及机器翻译。</td></tr></tbody></table><blockquote style="border-left: 4px solid #ff6b6b; background: #ffe0e0; padding: 15px; margin: 15px 0;">以上内容看看得了</blockquote><p>看不懂是正常的，我们来举个栗子</p><p>让我们把<strong>深度神经网络 (DNN)</strong> 想象为一家公司</p><hr><h3 id="第一部分：DNN-的结构-—-公司的层级"><a href="#第一部分：DNN-的结构-—-公司的层级" class="headerlink" title="第一部分：DNN 的结构 — 公司的层级"></a>第一部分：DNN 的结构 — 公司的层级</h3><h4 id="1-输入层-—-前台接待员"><a href="#1-输入层-—-前台接待员" class="headerlink" title="1. 输入层 — 前台接待员"></a>1. 输入层 — 前台接待员</h4><p>这是公司的前台。当客户（数据）上门时，前台接待员（输入神经元）负责接收最原始、最琐碎的信息。</p><ul><li><p><strong>事件：</strong> 客户给了一张图片。</p></li><li><p><strong>接待员的工作：</strong> 他们不会思考，只是把图片拆解成最基本的信息（比如，每个像素点的颜色值）。</p><ul><li><p>“接待员 1：左上角像素，红色值 255。”</p></li><li><p>“接待员 2：左上角像素，绿色值 100。”</p></li><li><p>…</p></li></ul></li><li><p>输入层只负责<strong>接收原始数据</strong>，并将其传递给下一层。</p></li></ul><h4 id="2-隐藏层-—-工作团队"><a href="#2-隐藏层-—-工作团队" class="headerlink" title="2. 隐藏层 — 工作团队"></a>2. 隐藏层 — 工作团队</h4><p>深度一词的由来。想象每一家公司有很多部门。</p><ul><li><p>假设每一层都是一个部门。</p></li><li><p><strong>工作流程：</strong></p><ul><li><p><strong>层级 1 (部门A)：</strong> 他们从所有“接待员”那里拿到原始像素数据。他们的工作是<strong>识别最简单的模式</strong>。</p><ul><li><p>员工 A：“我发现了一些横向边缘。”</p></li><li><p>员工 B：”我发现了一些垂直线条。”</p></li><li><p>员工 C：“我发现了一块毛茸茸的纹理。”</p></li></ul></li><li><p><strong>层级 2 (部门B)：</strong> 他们不看原始数据，只看部门A的报告。他们的工作是<strong>组合简单模式，形成复杂形状</strong>。</p><ul><li><p>员工 X：”我把<code>边缘 A</code>和<code>纹理 C</code>组合起来，这看起来像一个<code>耳朵</code>的轮廓。”</p></li><li><p>员工 Y：“我把<code>线条 B</code>和另一条线组合，这像<code>胡须</code>。”</p></li></ul></li><li><p><strong>隐藏层 3 (部门C)：</strong> 他们继续组合先前部门的所有报告，形成更复杂的概念。</p><ul><li>员工 P：”我拿到了<code>耳朵</code>、<code>胡须</code>和<code>眼睛</code>的报告，我认为这构成了一张<code>动物的脸</code>。”</li></ul></li></ul></li></ul><p><strong>…… 以此类推</strong></p><h4 id="3-权重—-经理的偏好"><a href="#3-权重—-经理的偏好" class="headerlink" title="3. 权重— 经理的偏好"></a>3. 权重— 经理的偏好</h4><p>每个经理在看下属的报告时，都有自己的<strong>偏好（权重）</strong>。</p><ul><li><p>在部门A的经理看来：</p><ul><li><p>下属 A (边缘) 的报告<strong>非常重要</strong> (权重 &#x3D; 0.9)。</p></li><li><p>下属 B (线条) 的报告<strong>不太重要</strong> (权重 &#x3D; 0.1)。</p></li><li><p>下属 C (纹理) 的报告<strong>中等重要</strong> (权重 &#x3D; 0.5)。</p></li></ul></li><li><p>经理会把所有报告的<strong>重要性</strong>加权求和，形成自己的最终判断。</p></li></ul><h4 id="4-输出层-—-老板"><a href="#4-输出层-—-老板" class="headerlink" title="4. 输出层 — 老板"></a>4. 输出层 — 老板</h4><p>这是一家公司的最高层</p><ul><li><p>老板不看任何琐碎细节，只看各部门的最终报告。</p></li><li><p><strong>决策：</strong></p><ul><li><p>A 报告：“我 95% 确定这是一张‘动物的脸’。”</p></li><li><p>B 报告：“我 80% 确定这是‘猫的身体’。”</p></li><li><p>X 报告：“我20%确定是‘狗的身体’。”</p></li></ul></li><li><p>老板综合所有最高层的信息，做出最终的、唯一的决策：“<strong>我宣布，这是猫</strong>。”</p></li></ul><h3 id="第二部分：反向传播-—-秋后算账"><a href="#第二部分：反向传播-—-秋后算账" class="headerlink" title="第二部分：反向传播 — 秋后算账"></a>第二部分：反向传播 — 秋后算账</h3><p>这时候，身为正常人的你下楼一看，糟糕了：</p><ul><li><p>老板：“这是猫！”</p></li><li><p>你：“？？？这不是狗吗？”</p></li></ul><p>现在，公司必须从这个巨大的错误中学习。这就是<strong>反向传播 (Backpropagation)</strong> 的开始，它是一个<strong>追责</strong>和<strong>纠正</strong>的过程。</p><p>生气的你冲到老板面前，一招大荒囚天指技惊四座。</p><p>“你个蠢货，那是只狗！”</p><h5 id="反向追责-Backward-Pass"><a href="#反向追责-Backward-Pass" class="headerlink" title="反向追责 (Backward Pass)"></a>反向追责 (Backward Pass)</h5><p>这个“追责”的过程是<strong>从老板开始，一层一层往下</strong>的：</p><ul><li><p><strong>第 1 站：老板 (输出层)</strong></p><ul><li><p><strong>你问老板：</strong> “你为什么判断是猫？”</p></li><li><p><strong>老板回答：</strong> “因为我的 A 报告 (动物的脸) 和 B 报告 (猫的身体) 都给了充足的论证。我的偏好是更相信 B(猫的身体)。”</p></li><li><p><strong>你的指示 (梯度)：</strong> “你（老板）的 <strong>判断</strong> 错了！下次 B (猫的身体) 报告时，你<strong>必须降低对它的信任度</strong> (降低权重)。同时，X (狗的身体) 的报告，你<strong>必须提高信任度</strong> (提高权重)。”</p></li></ul></li><li><p><strong>第 2 站：部门经理 (隐藏层 N)</strong></p><ul><li><p><strong>老板跑去问经理：</strong> “你为什么说那是‘猫的身体’？害我被骂！”</p></li><li><p><strong>经理回答：</strong> “因为我的员工的分析，让我更偏向于相信是猫的身体。”</p></li><li><p><strong>总教练指示 (梯度)：</strong> “你<strong>判断</strong> 也错了！下次报告时，你<strong>必须降低对它的信任度</strong>。同时，你要更关注狗爪子的报告！”</p></li></ul><p><strong>…… 以此类推，直至最底层</strong></p></li></ul><h4 id="3-链式法则-Chain-Rule"><a href="#3-链式法则-Chain-Rule" class="headerlink" title="3. 链式法则 (Chain Rule)"></a>3. 链式法则 (Chain Rule)</h4><p>你注意到了吗？<strong>错误的“责任”从顶层传递到了底层。</strong></p><ul><li><p>老板的错误，导致了对经理的“指责”。</p></li><li><p>经理的错误，导致了对员工的“指责”。</p></li><li><p>…</p></li><li><p>这个<strong>指责</strong>的<strong>具体数值（你应该调整多少？）</strong>，在数学上就是<strong>梯度 (Gradient)</strong>。</p></li><li><p>这种<strong>逐层反向传递责任</strong>的数学工具，就是<strong>链式法则 (Chain Rule)</strong>。</p></li></ul><h4 id="4-全员调整-Weight-Update"><a href="#4-全员调整-Weight-Update" class="headerlink" title="4. 全员调整 (Weight Update)"></a>4. 全员调整 (Weight Update)</h4><p>经过这一次秋后算账，公司里的<strong>每一个经理，一直到底层员工（所有神经元）</strong>，都收到了一个具体的“调整指令”：</p><blockquote><p>“你之前对下属 X 的报告‘偏好’（权重）太高了，下次把它调低 0.05%。”<br>“你之前对下属 Y 的报告‘偏好’太低了，下次把它调高 0.02%。”</p></blockquote><p><strong>这个过程（决策 -&gt; 犯错 -&gt; 反向追责 -&gt; 全员微调）会重复数百万次。</strong></p><p>最终，这家公司的所有经理都学会了一套极其复杂且精妙的“偏好”（权重），使得他们在下次看到一张“狗”的图片时，能从前台开始，一路正确地传递信息，最终让老板做出正确的决策：“这是狗！”</p><hr><h3 id="IV-注意力的革命"><a href="#IV-注意力的革命" class="headerlink" title="IV 注意力的革命"></a>IV 注意力的革命</h3><p>在 GPT 出现之前，处理序列数据（如文本、语音）的主流模型是 <strong>RNN (循环神经网络)</strong> 及其变体 <strong>LSTM</strong>。</p><p>RNN 的设计很直观：它像人一样，一个词一个词地阅读。它有一个“记忆单元”（Hidden State），在阅读句子:’The cat sat on the floor.’时，在读完“The cat”后，会把’The cat’的信息编码到记忆里，再去读下一个词‘sat’。</p><p>但这种设计存在两个致命问题。<strong>首先是长距离依赖和梯度消失</strong>：当句子很长时（“我昨天…（省略50个词）…那只猫”），到处理“猫”时，关于“昨天”的信息（梯度）在“记忆”中已经极其微弱，模型“忘记”了。<strong>其次是串行计算瓶颈</strong>：你必须处理完 <code>word[n]</code> 才能处理 <code>word[n+1]</code>。这在 GPU 时代是灾难性的，因为 GPU 最擅长的是<strong>并行计算</strong>（同时处理 1000 个 <code>word</code>），而 RNN 的设计使其无法利用这一点。</p><p>直到 2017 年，一篇论文<a href="https://proceedings.neurips.cc/paper_files/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf">《Attention Is All You Need》</a>彻底改变了这一切。<strong>Transformer</strong> 模型登场，它做的第一件事就是：<strong>彻底抛弃 RNN 的“循环”结构</strong>。</p><p>Transformer 的核心是<strong>自注意力机制 (Self-Attention)</strong>。它的核心思想是：一个句子中的词，其含义不是孤立的，而是由它和句子中所有其他词的关系共同决定的。</p><blockquote><p>例子：“The <strong>animal</strong> didn’t cross the street because <strong>it</strong> was too tired.”</p></blockquote><p>当模型处理 “it” 时，”it” 指的是 “animal” 还是 “street”？RNN 必须依赖其摇摇欲坠的“短期记忆”。而 Self-Attention 允许 “it” <em>直接“看”向</em> 句子中的所有其他词，并计算一个“注意力得分”。它会发现 “it” 和 “animal” 的关联性远高于 “street”。</p><p>那么，Self-Attention 在技术上是如何做到这一点的呢？它为句子中的 每个词 都生成三个不同的向量：</p><ul><li><p><strong>Query (Q) 向量：</strong> 代表当前词作为“查询者”的身份。可以理解为：“<strong>我</strong> (it) 是谁？我正在寻找和我相关的东西。”</p></li><li><p><strong>Key (K) 向量：</strong> 代表该词可被“索引”的标签。可以理解为：“我是“animal”，一个可以被指代的名词。”</p></li><li><p><strong>Value (V) 向量：</strong> 代表该词的“真正含义”或“内容”。</p></li></ul><p>整个过程如下（以‘it’为例）：</p><p><strong>首先是打分(Scoring)</strong>：拿 “it” 的 <strong>Q 向量</strong>，去和 <strong>句子中所有词</strong>（包括 “it” 自己）的 <strong>K</strong> 向量进行<strong>点积</strong> (Dot-Product)。这个点积的结果，就是<strong>相关性得分</strong>。（如果 “it” 的 Q 和 “animal” 的 K 很接近，得分就高）。</p><p><strong>接着是归一化(Softmax)</strong>：将这些原始得分通过一个 Softmax 函数，将其转换为总和为 1 的“注意力权重”（例如：{ “The”: 0.05, “animal”: <strong>0.85</strong>, …, “it”: 0.05, …}）。</p><p><strong>最后是加权求和(Weighted Sum)</strong>：用这些<strong>注意力权重</strong>，去对 句子中所有词 的 <strong>V</strong> 向量进行加权求和。</p><p><code>Output_for_it = (0.05 * V_The) + (0.85 * V_animal) + ...</code></p><p>最终的结果是： “it” 的原始 V 向量（它自己的含义）被“注入”了 85% 的 “animal” 的 V 向量（含义）。模型在这一层就明确知道了 “it” 指向 “animal”。</p><p>Transformer 的革命性在于两个方面。<strong>第一是并行化</strong>：整个 Q-K-V 计算是纯粹的矩阵乘法。GPU 可以 <em>同时</em> 计算句子中所有词的 Q&#x2F;K&#x2F;V 和注意力得分。这充分运用了设备的算力，使得训练千亿（甚至万亿）参数的巨型模型（LLM）成为可能。<strong>第二是全局依赖</strong>：任何两个词（无论相隔多远）的“距离”都为 1。模型可以轻易捕捉长距离依赖，彻底解决了 RNN 的“遗忘”问题。</p><hr><p>东拼西凑的一个月，终于完成了🙌</p>]]></content>
      
      
      
        <tags>
            
            <tag> AI/Artificial Intelligence </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
